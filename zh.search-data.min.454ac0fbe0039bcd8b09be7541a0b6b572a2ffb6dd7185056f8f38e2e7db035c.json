[{"id":0,"href":"/zh/docs/Other/","title":"Other","section":"介绍","content":"Notes of Other\n"},{"id":1,"href":"/zh/docs/Digtal/","title":"Physical Design","section":"介绍","content":"Notes of Physical Design\n"},{"id":2,"href":"/zh/docs/Digtal/Routing/global-router/congestion/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%A2%84%E8%B7%AF%E7%94%B1%E6%8B%A5%E5%A1%9E%E9%A2%84%E6%B5%8B%E7%A0%94%E7%A9%B6/","title":"bs24","section":"Physical Design","content":"基于图神经网络的EDA预路由拥塞预测研究\n课题描述:\n​\t近年来随着数字芯片使用越来越小的工艺制程和芯片内包含越来越多的逻辑单元，使其设计更新迭代优化的难度越来越大。由于数字后端中的布局(Placement)布线(路由, Route)流程属于是NP-Hard的算法优化问题，EDA(Electronic Design Automation)工具在这一阶段往往及其费时，导致更长的物理设计周期。\n​\t在数字电路优化过程中，布线拥塞是用于物理设计过程迭代优化的重要指标。某些区域的布线密度过高，导致无法继续进行有效的布线，进而导致时序与设计规则违例等问题。为此，许多现代综合与布局工具利用拥塞数据，以尽量减少最终物理设计中的拥塞影响。通过布线的拥塞数据，布局布线工具将相应地优化相关的可移动单元位置，以减少线长度、拥塞和违例，进行迭代，直到收敛，从而产生更优的布线结果。精确的拥塞预测在电路布线中起着至关重要的作用，不幸的是，直到设计周期的后期，也就是缓慢的布局和布线流程，精确的拥塞结果才被准确地知道。\n​\t这启发我们设计一个跨设计阶段(Cross-stage)的拥塞预测方法，在设计初期进行布局布线优化，从而加速优化迭代流程。多个先前的工作尝试在利用布局数据预测详细路由(Detail Route)拥塞，以优化放置解决方案的可达性，如：RUDY、GTL、POLAR 2.0等。这些基于专家经验的方法往往预测精度较低。近年来，随着图神经网络(Graph Neural Network, GNN)在学习图结构和挖掘图信息方面展示出了卓越的效果。由于电路结构可以自然地表示为图，图神经网络在电子设计自动化领域受到了越来越多的关注。GNN 模型可以端到端的方式学习全局指标而无需额外的特征工程比传统深度学习方法更高的准确度。\n​\t因此，本课题将设计实现基于图神经网络的EDA预路由拥塞预测任务，给定电路布局结果，或仅仅根据电路网表内容，实现对布线后的拥塞结果预测。\n内容\n学习DeepLearning框架(Pytorch/Tensorflow)的使用, 环境的搭建, 图神经网络模型(GNN, Graph Neural Network)的搭建，综述调研 学习并掌握一款工具的使用(OpenROAD(推荐)/Candance/Innovus). 并且利用工具获取相关数据集 学习与复现相关论文，基于所学内容设计基于GNN的预路由拥塞预测架构, 实现拥塞预测. 设计创新点, 改进模型性能, 实现结果分析, 结果可视化, 模型对比实验(精度/推理速度/内存占用等), 消融实验等. 参考资料以及说明\n图神经网络相关算法详述及实现:一个GNN教程\nRUDY：Fast and Accurate Routing Demand Estimation for Efficient Routability-driven Placement ：一个基于布局结果的快速路由拥塞估计器\nGTL:Detecting tangled logic structures in VLSI netlists: 一种基于图结构直接从网表中估计拥塞的方法\nPOLAR 2.0: An effective routability-driven placer：一个基于拥塞预测与可达性的布局工具\n华南理工大学图书馆数据库：可免费下载各大国内外期刊文章\nGoogle Scholar: 一个学术论文搜索引擎\nConnected Papers | Find and explore academic papers: 一个基于图相关性论文搜索引擎\nAwesome AI for EDA：EDA研究中现有AI方向的高质量高影响力论文列表网站\n基于图神经网络的电子设计自动化技术研究进展：一篇关于GNN在EDA方面应用的综述文章\nCongestionNet: Routing Congestion Prediction Using Deep Graph Neural Networks ：一种基于GNN和综合后网表数据预测路由拥塞的方法\nGeneralizable Cross-Graph Embedding for GNN-based Congestion Prediction:一种基于GNN和综合后网表数据预测路由拥塞的方法\nPin Accessibility and Routing Congestion Aware DRC Hotspot Prediction using Graph Neural Network and U-Net :一种基于GNN和CNN和布线数据预测DRV的方法\nLHNN | Proceedings of the 59th ACM/IEEE Design Automation Conference:一种基于GNN和布线数据预测拥塞的方法\nThe OpenROAD Project：一个开源RTL-to-GDS项目， 特点: 开源软件, 易于安装与使用, 内置可以直接使用的开源PDK.\nOpenCores：一个开源数字网关IP核的参考社区，可提取HDL文件使用数字后端设计工具实现自定义数据提取\nISPD 2011 Routability-driven Placement Contest and Benchmark Suite：ISPD举办的布局器比赛，内有数据集可参考\nDAC 2012 Routability-Driven Placement Contest一个DAC举办的布局器比赛，内有数据集可参考\n基于项目”chacha“的拥塞示例数据\nEDA三巨头整套虚拟机:太大了无法上传，需要的话发邮箱到：icpengxuan@mail.scut.edu.cn\nAnwar-Said/Circuit-Completion-Using-GNNs: Source code and datasets for Circuit Design Completion using GNNs paper:一个开源代码\nycchen218/EDA-Congestion-Prediction: This is a deep-learning based model for Electronic Design Automation(EDA), predicting the congestion location.：一个开源代码\nCircuitNet: 一个开源数据集，内置开源代码\nAccurate Prediction of Detailed Routing Congestion using Supervised Data Learning：一篇相关论文。。。\n相关知识与术语:\n图神经网络(GNN)：一种基于具有不规则结构图结构的深度学习模型。最基础的图卷积模型是GCN(相当于图结构的CNN)。\n数字后端: 以前端综合后的网表(.v文件)、工艺库PDK和一些约束文件(如.sdc文件等)作为输入, 经过布图、布局、时钟树综合、布线与验证后输出可用于流片的.gds(Graphic Data System)版图文件的流程\n布局：确定电路中各个组件在芯片中的物理位置。由于在布线之前无法准确评估放置解决方案的质量，导致设计流程中的反馈循环很长，因此现代布局需要在早期阶段减少布线拥塞(Congestion)并提高可达性(Routability)\n预路由(pre-routing): 布线阶段前的数字设计阶段。\n拥塞：在芯片设计或者FPGA设计中，硬件资源可分为逻辑资源和布线资源，当设计工程较大或较复杂时，可能逻辑资源仍然在合理范围内，但是布线资源却超出固有资源或者较为不合理。这时候可能会产生congestion（拥塞）问题，也就是布线资源紧张导致的。\n拥塞图(congestion map): 版图中使用网格(grid)用于标识路由需求超过路由容量的区域。布局工具(Placer)将相应地优化相关的可移动单元位置，以减少线长度和拥塞，并迭代地重复上述循环，直到收敛，从而产生放置解\nRUDY (Rectangular Uniform wire DensitY): 是基于布局结果的快速路由拥塞估计器。它假设网线在其包围框内均匀分布。速度快但是精度低。\nDRVs (design rule violations) :设计规则违规。这些违规是指在集成电路的版图设计过程中，经过DRC(Design Rule Check)违反了特定的设计规则而导致的潜在问题。设计规则是由代工厂针对特定工艺制定的一系列强制性要求，它们综合考虑了电学性能和可靠性限制，并按照芯片加工过程所需的一系列限制来制定。\nshift-left: 指的是将测试和验证活动提前到开发周期的更早阶段，以便更早地发现和修复缺陷。EDA的一大研究方向就是cross-stage prediction：通过早期流程数据对预测后期结果数据，减少工作迭代次数， 实现效率提升。\nG-cells ：是电路上放置单元的矩形单元。是总体布线过程中的基本布线单元\nG-nets：表示引脚之间以G-cells为路径单元的连线\n"},{"id":3,"href":"/zh/docs/Digtal/flow/notebak/EDA+GNN/","title":"eda+gnn","section":"Physical Design","content":" Survey # Background \u0026amp; Intro # 只有在物理验证和签名(sign off)以及测试期间，才能衡量设计在功率、性能和面积 (PPA) 方面的质量。通常需要在中间步骤中进行纠正修改，这会导致设计的多次迭代。因此，在设计的早期阶段对 PPA 的估计将减少所需的迭代次数，增加设计的可靠性，同时深入研究flow，并最终提高结果质量 (QoR)\nNP-complete # EDA 工具通常面临 NP-complete 问题，机器学习 (ML) 方法可以更好更快地解决这些问题\nNP问题是一类可以通过非确定性图灵机( Non-deterministic Turing Machine)在多项式时间(Polynomial time)内解决的决策问题集合。\nNP问题中最困难的问题称之为NP完全问题(NP-complete)\nML # ML 已集成到 EDA 中，尤其是逻辑综合、布局、布线、测试和验证 [23] ML 用于预测传统方法的最佳配置。其次，ML 学习模型的特征及其性能来预测看不见的设计的行为，而无需运行昂贵的综合步骤。此外，在优化 PPA 的同时，可以通过 ML 进行设计空间探索。最后，强化学习 (RL) 探索设计空间、学习策略并执行转换，以通过“人工智能辅助设计流程”获得展望未来的最佳设计。 在 EDA 中使用 ML 的一个促成因素是 EDA 工具在设计过程中生成的大量数据。 欧几里得数据\nEDA # flow # 逻辑综合 # 逻辑综合将 HDL 中的 RTL 块映射到从给定技术库中选择的门组合，同时针对不同目标优化设计。通常，这种优化涉及时序收敛、面积和功耗之间的权衡。\n描述硬件设计的 RTL 模块被映射到技术库中的逻辑单元。此映射必须满足时序约束，以在所需时钟速率下运行，同时考虑面积和功耗。因此，综合是一个可以应用 ML 的复杂优化问题。例如，提供更早的 QoR 预测以避免耗时的合成步骤的多次运行\nD-SAGE [55]\n物理综合 # 主要步骤\n布局规划 # 在芯片布局规划中，网表的主要块和较大块被放置在二维网格上，以实现最佳 PPA，同时遵守设计规则。这可以表示为马尔可夫过程，可以使用 RL 来解决。\n（Edge-GNN）[44]。在 [44] 中，将 GNN 合并到 RL 框架中以对过程的不同状态进行编码，预测拥塞、密度和线路长度的奖励标签，并推广到未见的网表。它计算整个网表的节点和边缘嵌入。此 RL 代理提供与人类设计师相当或更好的结果，但需要数小时而不是数月。\n布局 # 设计门被映射到芯片布局的确切位置。设计越大，这个过程就越复杂。放置期间的错误决定会增加芯片面积，但也会降低芯片性能，如果导线长度高于可用布线资源，甚至会使其不适合制造。通常，需要多次放置迭代，这是耗时且计算效率低下的。因此，布局被视为一个约束优化问题。正在探索 ML，尤其是 GNN，以简化此步骤\n[61] 中提供预置网络和路径长度估计。为此，他们将网表转换为有向图，其中网络代表节点，边在两个方向上连接网络。单元数、扇入、扇出大小和面积用作特征节点。使用聚类和分区结果定义边缘特征。节点的真实标签是放置后作为边界框的半周线长度获得的净长度。\n在 [38、39] 中，GraphSAGE 被用来构建 PL-GNN\n[2] 中介绍了将 EDA 中的 PPA 优化任务映射到 RL 问题的概念验证框架。这个 RL 框架使用 GraphSAGE 和无监督训练来学习可以推广到看不见的网表的节点和边缘嵌入。 GCN 是一个关键组件，因为它提取 RL 代理所需的本地和全局信息。作为研究案例，分析了 2-D 放置期间的线长度优化。\n​ 在 [1] 中，自主 RL 代理以归纳方式找到最佳放置参数。网表被映射为有向图，节点和边特征是手工制作的与放置相关的属性。 GraphSAGE 学习网表嵌入并有助于推广到新设计。\n时钟插入 # 布线 # 在 [29] 中，GAT 仅使用在物理设计后获得的特定技术门级网表来预测路由拥塞值。为此，将网表构建为无向图，其中每个门都是一个节点，边定义为通过网络连接的门之间的连接。特征节点是 50 维向量，包含有关单元类型、大小、引脚数和逻辑描述的信息。为了获得节点的真实标签，拥塞图被分成网格，每个网格的拥塞值被作为放置在该网格中的单元格的标签。 [29] 中提出的称为 CongestionNet 的架构不超过遵循公式 4 的八层 GAT。节点嵌入用于预测局部拥塞值。使用 GAT 可以提高预测质量，对于超过 100 万个单元的电路，推理时间约为 19 秒。“单V100 GPU上训练为60小时”\n在 [37] 中，提出了一个端到端框架，使用基于 GNN 的长短期记忆 (LSTM) 架构来预测端口路由 TNS\n[9] 中，提出了两个 RL 框架来优化布局（DeepPlace）和布局布线一起优化（DeepPR）\n验证和签收 # 制造 # 制造、封装和最终测试\n挑战 # (1) 它依赖于硬件设计人员的专业知识来选择合适的 EDA 工具配置，\n(2) RTL 的设计空间探索，逻辑综合和物理综合是手动的，因此是有限且耗时的，\n(3) 设计中的更正将重新初始化流程，\n(4) 没有早期分析或结果的可预测性\nGraphs # 处理图结构数据的方法 # 传统浅嵌入方法 # 旨在将节点信息分解为低维嵌入向量，考虑图中节点的位置和邻域的结构[17]。最著名的图嵌入技术之一是 Random Walk [36]。在这种技术中，给定图中的起点，随机选择一个相邻点。作为第二步，再次选择随机选择的点的邻居。这是以递归方式完成的。这会生成一个随机的点序列，即随机游走。 DeepWalk [45] 和 Node2vec [16] 是众所周知的基于随机游走的图嵌入方法。\n缺点 # 他们的编码器将重要信息从图中映射到嵌入空间，优化每个节点的唯一嵌入向量。这在大图中的计算/统计上可能是昂贵的。\n它们是转导的，即它们只能为训练期间看到的节点生成嵌入。这是一个主要缺点，因为该模型无法推广到看不见的节点。\n他们没有考虑在编码过程中可以提供宝贵信息的节点特征。\n其他神经网络 (NN)缺点 # 例如 CNN，如果不将其结构映射到固定大小的向量格式，就无法直接对图形数据进行操作。首先，图没有固定的局部性或滑动窗口概念来执行卷积操作。其次，图没有固定的节点顺序。作用在图上的操作应该对节点排序或排列保持不变。\nGNN # 由于考虑了特征和拓扑信息，GNN 已被证明优于其他 ML 模型\n[14] 中引入了一种称为 GNN\n直接在图上运行的神经网络框架\nGNN 由置换不变函数和置换等变函数组成，因此也可以在节点粒度上运行。?\nGNN 旨在学习每个节点的嵌入向量\n消息传递策略已被 GNN 的新颖架构继承\nGNN # 两篇开创性论文 [25, 41] 强调了 EDA 任务和 GNN 之间的重要联系。 [41] 中的研究首次认识到 GNN 在 EDA 中的巨大潜力。他们表示，图形结构是表示布尔函数、网表和布局的最直观方式，这些是 EDA 流程的主要关注点。他们将 GNN 视为 EDA 改进 QoR 并取代使用的传统浅层方法或数学优化技术的机会\nGNNs for the Digital EDA Flow # 类型 # Recurrent Graph Neural Networks（RecGNNs） # 通过假设节点与其邻居交换信息直到达到稳定点来循环处理节点信息\nConvolutional Graph Neural Networks # 卷积图神经网络 (ConvGNN) 旨在通过堆叠多个图卷积层来学习嵌入向量。与共享权重的 RecGNN 不同，ConvGNN 每层使用不同的权重。 ConvGNN 是 CNN 对图形数据的泛化，分为光谱和空间方法 [60]：\nGCN属于这种\nGraph Autoencoders（GAE） # 图自动编码器 (GAE) [60] 属于无监督框架家族，因为训练数据没有真实标签。因此，计算的损失取决于整个图的拓扑信息，包括节点和边缘特征[58]。\n用于两种类型的任务：基于图的表示学习和图生成\n[28] 中提出的最常用的 GAE 之一中，GCN 被用作编码器来提取图嵌入。\nSpatial-Temporal Graph Neural Networks (STGNN) # 许多实际应用中，输入图的结构会随时间发生变化，即矩阵 A 和 X 沿时间轴变化。使用时空图的一个例子是计算机视觉领域的动作识别问题[63]。\nGNN 的设计流程 # Graph Definition # 定义每个节点或边缘的特征向量。\nTask Definition # 基于要解决的问题，定义任务的粒度和监督设置。 GNN 的任务分为三个级别：节点级别、边级别和图级别\n我们以不同的方式训练模型：监督，如果所有节点都被标记；半监督，如果只知道一些标签；和无监督的，当没有标签可用时 [60]。\n目标任务和监督设置共同决定了训练期间要使用的损失函数。例如，节点级监督回归任务需要均方误差 (MSE) 函数作为训练集中所有节点的损失函数。在节点级半监督分类任务的情况下，交叉熵损失可用于少数提供的标记节点。？\nModel Definition # 在 [72] 中，GNN 模型被定义为堆叠计算模块的概要\n三种不同类型的模块：传播、采样和池化。\n传播模块在保留特征和拓扑信息的节点之间传播和聚合信息。由残差神经网络（ResNets）[21] 激发的跳跃连接机制也被认为是一个传播模块。\n采样：在 GNN 中，一个节点的信息被聚合到其上一层邻居的信息中。因此，深度 GNN 会导致需要考虑和聚合的邻居呈指数增长。采样模块减轻了邻居爆炸。采样粒度可以是节点、层和子采样级别。在节点级别，通过考虑每个节点的固定数量的邻居来限制邻域大小。在层级，每层只考虑固定数量的节点进行聚合。最后，子图级采样将邻域搜索限制为采样子图[72]。 池化：池化层驱动的池化模块在减小图的大小的同时获得更一般的特征。 定向池化，也称为读出或全局池化，它对节点特征应用节点操作以获得图级表示；和分层池化，它遵循分层模式并按层学习图表示[72]。\nGNN优点 # 基于 GNN 的架构优于其他模型和解决方案。上面列出的工作将他们的结果与浅层 ML、深度学习方法或特定任务的基线进行了比较。毫无疑问，GNN 的优越性是由于对拓扑和特征信息的考虑，这是以构建训练数据集的更大努力和更高的训练时间为代价的\nML对比 # shallow ML # [42] 中，基于 GNN 的模型解决方案优于用于二元分类的经典 ML 技术，例如线性回归器 (LR)、支持向量机 (SVM)、随机森林和 MLP。与商业工业工具相比，它在不丢失故障覆盖率的情况下，插入的测试点减少了 11%，测试模式帐户减少了 6%。 GNN-RE [4] 中，将基于 GNN 的模型与使用每个节点相同特征向量的监督分类任务的 SVM 进行比较。但是，根据定义，SVM 只考虑单个节点的特征，不能访问邻居节点的特征。 SVM 的训练时间几乎是 GNN-RE [4] 的 10 倍。然而，分类指标清楚地表明了 GNN 的优越性。 ParaGraph [46] 与 XGBoost [6] 和 LR 模型以及普通 GraphSAGE 进行了比较。预测准确率平均为 77%，比 XGBoost 好 110%，比 GraphSAGE 好 7%。 deep ML # D-SAGE [55] 与 MLP 和 vanilla GraphSAGE 进行了比较。**基于 GNN 的模型优于 MLP，强调结构信息与操作映射的相关性。**此外，由于边缘方向信息，D-SAGE [55] 相对于 GraphSAGE 获得了 17% 的相对增益。 定制的 ABGNN [22] 在输入和输出边界分类任务方面都优于普通 GraphSAGE、GAT 和图同构网络 (GIN) [62]，同时推理时间分别减少了 19.8% 和 18.0%。与使用电平相关衰减和 (LDDS)-存在向量 (EV) 来表示电路拓扑 [11] 的 NN 相比，ABGNN [22] 的性能也更高且运行时间更低 [49] 中，Circuit Designer [59] 与非基于图的 RL 架构进行了比较。不同的实验表明了 GCN-RL 的优越性，它在非基于图的 RL 永远不会收敛的情况下收敛，即使有非常多的模拟步骤。 Circuit Designer [59] 的成功也归功于考虑线性晶体管参数的明确特征向量 Compared to task-specific baselines. # GNN 的优势与两个因素有关：定义明确的初始特征和图学习能力 [39]。**定义明确的特征捕捉任务的基本特征，并为图学习提供宝贵的信息。 GNN 捕获特征和拓扑信息。**这与仅考虑图形连通性的方法相比，它具有明显的优势。\n在 PL-GNN [39] 中，与层次相关的特征用于学习哪些节点相似，而与记忆相关的特征有助于平衡关键路径。 PL-GNN [39] 优于基于模块化的聚类，后者仅使用连接信息\nCongestionNet [29] 的先验拥塞估计性能优于基线方法 29%，而对于较低层的拥塞估计则优于 75%。尽管如此，CongestionNet [29] 训练需要在单个 GPU 上进行 60 小时。在推理期间，130 万个单元的运行时间减少到 19 秒，少于基线方法的运行时间。\nEdge-GNN [44] 与开源全局布局工具 RePLAce3 [8] 和使用行业标准 EDA 工具的手动布局的结果进行了比较。在训练超过 10000 个芯片 loorplans 之后，Edge-GNN [44] 优于这两种方法，平均给出更低或相当的最差负松弛、总面积、功率和拥塞\nModels Depth # GNN 模型的层数是一个超参数。添加过多的层会使输出嵌入变得平滑并降低端到端任务的准确性。因此，更深层次的模型需要更大的数据集 [64]。！\nChallenges # 鲁棒性 # 可解释性 # 预训练 # 复杂图类型 # GNNs in EDA Challenges # 从 EDA 的角度来看，在将 GNN 应用于设计流程时，尤其是图形的可扩展性和多样性 [41] 时，先前的挑战会加剧。在 EDA 中，输入图代表不同抽象级别的电路网表，通常具有非常大的尺寸。大图会导致巨大的稀疏邻接矩阵和非常大的节点列表，其计算耗时且计算量大。！\n与简单的无向图或有向图相比，EDA 对象在直觉上更类似于复杂的图类型。直观地，电路网表是有向超图或异构图，为了与这些图类型相结合，应该制定新的 GNN 架构，如 [22, 55] 中所做的那样。为 EDA 对象定制 GNN 架构并提高其处理复杂图形类型的性能仍然是一个开放的研究课题。\n数据生成仍然是一个开放的挑战\nFuture Work # Exploiting Transfer Learning # ​ CongestionNet [29] 等应用程序与技术无关，即它们根据所使用的技术构建具有特征向量和标签的数据集。对于针对新工艺技术的实验，应重新构建数据集并重新训练模型。我们期望未来的 EDA 应用程序评估 GNN 的迁移学习技术的使用，例如 [19、32、44、59] 中已经完成的。例如，GCN-RL Circuit Designer [59] 受益于 RL 的可转移性，并利用它在 5 个不同的技术节点和拓扑之间进行知识转移。\nExploiting Feature Information # GNN 的一个成功因素是定义明确的特征向量。因此，我们相信未来的研究将评估不同的特征节点，以提高当前解决方案对更先进技术和复杂任务的可扩展性和泛化性。\n例如，当前的 Circuit Designer 实施仅使用线性晶体管参数作为特征。未来的工作应该涵盖非线性特征以支持非线性组件类型。\n在 [29] 中，进行了消融研究以确定特征对 CongestionNet 预测的重要性。因此，与cell类型或功能相关的特征比与cell几何形状相关的特征更重要。因此，未来的工作建议包括新的特征，如引脚和边缘类型。\n此外，他们建议使用有向图或超图而不是无向图。\nEnlarging Datasets # 开源工具 # 1https://github.com/The-OpenROAD-Project\n2https://github.com/ALIGN-analoglayout/ALIGN-public\nOpenROAD 和 ALIGN 都没有开始探索 GNN 的使用\n参考 # 【阅读】A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN综述翻译_ppaml-CSDN博客\n"},{"id":4,"href":"/zh/docs/Digtal/flow/EDA4PR/","title":"EDA4PR","section":"Physical Design","content":" 研究背景 # **典型的芯片设计流程是先做前端、后端设计，再去验证性能、功耗和面积。**但由于流程太长，在前端设计的时候，无法保证后端设计的效果，所以很多时候需要进行跨环节建模，在早期设计环节预测后续环节的求解质量，这当中就很适合AI算法来进行辅助。\n除了建模之外，另外一个关键问题是优化。EDA中经常要求解各种各样的组合优化问题。这些问题往往是 NP难题，比如经典的旅行商问题。传统上，我们会通过一些启发探索的方法来求解。但随着规模不断增大、设计约束越来越多，这种探索往往遇到效率瓶颈，所以我们需要通过机器学习技术进行辅助，寻找有效策略，提高效率。\n难点 # 大图\u0026ndash;\u0026gt; 数据集\u0026ndash;\u0026gt; 泛化能力\u0026ndash;\u0026gt; 非DAG? route: 3D，45°，30° 先进的工艺：7nm 很多Placer and Router还是有很多人工定义的超参数？（不general） 现在真的还有必要把Router分成Global 和Detail 吗？ GR: total maze routing GR: Consider timing and power consumption 研究方向 # Cross-Stage Prediction # routing congestion prediction # background # Routing congestion can overwhelm routing resources and lead to low cell utilization and routing detours\ncongestion is not known accurately until late in the design cycle, after placement and routing.\nMany modern placement and synthesis tools leverage congestion estimation in their cost analysis in order to minimize the effects of congestion in the final physical design\nIt is known that the total net length can be a good proxy for congestion\nA simple approximation for congestion prediction is to use the size of the local neighborhood\n和fan-in, fan-out强相关\nPrecise congestion prediction from a placement solution plays a crucial role in circuit placement\nMultiple previous works have attempted to predict detailed routing congestion in the placement step in an effort to optimize routability of the placement solution: RUDY, POLAR 2.0. All these techniques are implemented in the placement step and need the position information of cells .\nTo avoid the high computation cost of placement, it is more useful to be able to predict congestion in the logic synthesis phase.\ncongestion prediction problem can be frame as node regression problem\nwith the growth of circuit scale and complexity, time consumption tends to be unacceptable when utilizing a global router in the placement cycle to obtain the congestion map.\nCurrent machine learning models commonly follow a two-phase workflow. First, based on domain knowledge, human experts generate various local features on the circuit using predefined functions on netlist. Then, based on the generated features, a specific model, e.g. convolution neural network (CNN) model is designed to predict either the routing demand map or the congestion map\nthe emergence of Graph Neural Network (GNN) triggered applications of undirected homogeneous graphs models on routing congestion prediction, since a VLSI circuit can be naturally represented by a graph\nRouteNet-DRC Hotspot Prediction-ICCAD-2018-CNN # background:\nEvery chip design project must complete routing without design rule violation before tapeout. However, this basic requirement is often difficult to be satisfied especially when routability is not adequately considered in early design stages.\nIn light of this fact, routability prediction has received serious attention in both academic research and industrial tool development. Moreover, routability is widely recognized as a main objective for cell placement\nCNN and Transfer Learning\nCNN learns more abstract patterns from images Our RouteNet transfers such state-of-the-art ability in image pattern recognition to circuits for capturing the patterns about routability. RouteNet predicts routability based on a pretrained ResNet architecture Fully Convolutional Network (FCN): outputs an image with size equal to or smaller than input. many FCNs have both deep and shallow paths in one network. RUDY(Rectangular Uniform wire DensitY)\n它被用作我们RouteNet的输入特征，因为它与路由拥塞部分相关，获取速度快，可以直接表示为与RouteNet相吻合的图像 challenge of macros\nThe orange circles in Figure 3 indicate a strong tendency for hotspots to aggregate at the small gap between neighboring macros Blue dashed circles indicate the remaining sparsely distributed hotspots 有macro，线性程度低 task:\npredict overall routability (DRC count), 分类任务，预测总的#DRV predict DRC hotspot locations.DRC hotspots mean the specific locations with high density of DRVs. like an end-to-end object detection task, which is more difficult to solve. GCell内#DRV超过设定值则为DRC hotspot contribution:\nmixed-size macros first systematic study on CNN-based routability prediction high accuracy and high speed flow:\nmodel\n#DRV prediction\nResNet18-based\npreprocess\nResNet是一个固定输入（224*224）的模型，为了使用知识迁移，将输入 通过插值的方法变成 。具体怎么插？\nhotspot prediction\ndata:\ndataset:\nISPD 2015 benchmarks\ndifferent placement made by “obstacle-aware macro placement\u0026quot; algorithm [5].\neach floorplan is placed and routed by Cadence Encounter v14.20 [2]\nexperiment:\nwe compare the TPR of all methods under the same FPR (error under 1%)\nCongestionNet-predict congestion hotspots-IFIP-2019-GNN(GAT)-nvidia # a graph-based deep learning method for predicting routing congestion hotspots from a netlist before placement. Predict the detail routed lower metal layer congestion values\nwhy low layer? 因为较低金属层上的拥塞主要是由局部逻辑结构驱动的，而不是由无关逻辑簇之间的较长互连驱动的，后者往往在较高金属层上运行. predicting lower metal layer congestion is not only more important for the underlying task of identifying congested logic structures, but also simplifies the task for our graph based network\ncontribution:\n阶段早,只使用网表 由于该模型仅基于网表的逻辑结构而不是任何特定的单元布局进行预测，因此它消除了基于布局的方法中存在的次优布局的伪影 can be done without any physical information GNN, 快 the first work exploring the use of graph based deep learning for physical design problems 数据:\nroughly 5000 distinct cell types\nwe project our per cell predictions back onto their respective 2D grid (using the final ground truth physical placement) and average all cells within each grid cell to come up with a predicted value that can be compared to the original ground truth grid value.\n模型参数:\nan 8 layer Graph Attention Network (GAT) with size 16 intermediate (or hidden) state\n无向图, each node corresponds to a cell\n节点特征: length 50 for each cell type and each cell’s logic description as well as the pin count and cell size of that cell\n实验:\nreport correlation values using the Kendall ranking coefficient\n实际效果可视化\n对比实验\n消融实验\ncell type or function is an essential part of our predictions.\ncell type 不是没起作用吗\n缺点:\nmodel needs to be retrained for every new process technology, since the embeddings are over cell types specific to a process technology. it occasionally over predicts congestion in areas of low to moderate congestion, such as in most failing parts of Partition A due to the graph based nature of the model, it sometimes makes overly soft decision boundaries the CongestionNet uses informative cell attributes (cell size and pin count) alone as the input to the GAT and does not use any embedding encoding the netlist structure 可改进的点:\n-Congestion prediction + embedding + matrix factorization + partition-arXiv-2021-GNN(Sage)- # background\npredicting cell congestion due to improper logic combination can reduce the burden of subsequent physical implementations. previous work: require informative cell features Although the global routing result provides a good estimation of routing congestion [6], [19], an awareness of high congestion areas at an early design stage is of great importance to provide fast feedback and shorten design cycles Multiple works have attempted to predict detailed routing congestion in the placement step in an effort to optimize routability of the placement solution task\nduring the logic synthesis stage\n到底是什么时候的congestion数据? Routing后的真实值还是预测plcament后的congestion RUDY预测值? 应该是Global Routing后的:强调了congestion value = wiring demand/routing capacity\ncontrbution\ndata\nDAC2012 contest benchmark\nhttp://archive.sigda.org/dac2012/contest/dac2012_contest.html\nOpenROAD dataset\nplace via DREAMPLACE\nMacros and terminals are removed from the graph\nNets with degree more than 10 are excluded from the final graph as they introduce cliques too large to work with efficiently.\nnode features (pin number, cell size) , This follows the flow of CongestionNet\nflow:\ncongestion value for each grid cell computed as the wiring demand divided by the routing capacity , The output along the z-axis is reduced by a max function,\nOur focus is on predicting congestion due to local logic structure, which manifests itself on lower metal layers. Therefore, we use congestion labels from the lower half of the metal layers to train and evaluate the model\n推理的时候取所有cell的预测平均值\nprinciple\n提出相连越近的节点相似度越高,\n提出structural node similarity\nSub-graph partition ? METIS? ClusterGCN?\nMatrix Factorization ?\nmodel\nThe key difference between this approach and CongestionNet lies in embedding pipeline\ngraph is undirected complete circuit is too large for direct matrix factorization and must be partitioned into clusters, use METIS partitioning tool in ClusterGCN\nSub-graph partition: clusters of ≈ 5000 nodes each\nMatrix Factorization ?\nexperiment\nthree metrics of correlation to measure performance: Pearson, Spearman, Kendall\nBefore evaluation, both the prediction and the label have some (very low) noise added to them.\nPGNN-DRVs prediction+Pin Proximity Graph-ICCAD-2022-GNN+UNet(CNN)-Korea # background\n(1) pin accessibility and (2) routing congestion are two major causes of DRVs (design rule violations)\nParticularly, the complex design rules put so much burden on physical design, demanding lots of iterations on the time-consuming process of cell placement and net routing to clean up all DRVs (design rule violations) before tapping out . Thus, at the placement stage, if we were able to identify, with high confidence, DRC (design rule check) hotspots that would be likely to occur at the routing stage, we can pay more attention\nshortcoming of image based:\nlocal pin accessibility cannot be accurately modeled by pin pattern image alone\nusing high-resolution pin pattern images incur significant additional run-time as well as memory overhead to the prediction models\nto optimize the placement before routing.\ntask\na novel ML based DRC hotspot prediction technique,\nGNN is used to embed pin accessibility information, U-net is used to extract routing congestion information from grid-based features placement 分割为grid, 长宽=G-Cell DRVs are extracted as the ground-truth after detailed routing contribution\nGNN model, base pin proximity graph model\nPGNN can adopt pin proximity graph as well as grid-based feature map as input feature\nPin Proximity Graph :\n无向图， 同构图 U-Net:\nfeatrue:\n整体模型:\n数据集:\n以后也可以这么做, 同一个benchmark不同的config参数就有不同的数据\nexperiment\nNangate 15nm library\n9 groups are used for training and the remaining 1 group for test. K折验证\npositive 和 negative是什么意思?\n可视化:\n消融实验:\n以后也可以这样用特征消融?\n对比实验(F1-score):\n注意不需要GR!\nGR-Cong is obtained from ICC2 after global routing stage, and grids with high routing congestion are classified as DRC hotspot. 商用\nRouteNet和J-Net都是相关的学术工作\n时间对比:\nLHNN-CongestionPrediction-DAC-2022-GNN-CUHK+Huawei+YiboLin # background\n图的节点的设置很新颖 with the growth of circuit scale and complexity, time consumption tends to be unacceptable when utilizing a global router in the placement cycle to obtain the congestion map. due to the need for the \u0026ldquo;shift-left\u0026rdquo; in circuit design, researchers begin to seek alternative solutions in machine learning [4] [5] to achieve accurate and fast congestion map prediction task\ntwo related tasks, routing demand regression and congestion classification data\nregard each G-cell as a node and add an edge between two nodes if the respective two G-cells are adjacent.\nhypergraphs and heterogeneous graph , 两种节点：G-cell和G-net\nfeature：\nISPD 2011 [16] and DAC 2012 [17] contest benchmarks ,\nmodel\n他这里说congestion map是一个二值化(0/1?)的数据集， 所以是分类任务, 但是为了利用数据，同时防止routing demand的信息丢失， 还设置了一个预测routing demand的任务？\nexperiment\n15benchmarks: 10 for training and 5 for testing\nrun DREAMPlace [18] on each of the designs to generate placement solutions\nNCTU-GR 2.0 [2] to attain horizontal/vertical routing demand maps , and set the congestion maps as a binary indicator according to whether the horizontal/vertical routing demand of the G-cell exceeds the circuit’s capacity\n对比实验：\n可视化：\n消融实验：\n-NN Robustness improve-arXiv-2024- -UC- # background:\n最近的工作已经证明神经网络通常是容易受到精心选择的输入小扰动的影响 Our definition of imperceptibility is characterized by a guarantee that a perturbation to a layout will not alter its global routing recent work [10, 18] has demonstrated that image classifiers can be fooled by small, carefully chosen perturbations of their input task\ndesign two efficient methods for finding perturbations that demonstrate brittleness of recently proposed congestion predictors one potential approach to address the issues by modifying the training procedure to promote robustness contribution\nPainting on PIacement-predict the routing congestion-ACM-2019-GAN-\n-DRC Hotspot Prediction-ISCAS-2021-CNN\n-Routing Congestion Prediction-ASPDAC-2020-GAN\nslice FPGACong_ASPDAC20 (yibolin.com) -predict #DRV, a macro placer-DATE-2019-CNN\nTiming Prediction # Pre-Routing Timing Prediction # background # relate work # TimingGCN-STA prediction-DAC-2022-GNN\nthe first work！ opensource still relies on local net/cell delay prediction as auxiliary tasks no optimization, not fit the real-world scenario where timing optimization is taken into account PreRoutGNN-STA prediction-AAAI-2024-GNN\nopensource [Multimodal Fusion-Restructure tolerant+CNN+Endpoint-wise Masking4Layout -DAC-2023-GNN+CNN-7nm RISCV](D:\\MyNotes\\EDA\\Timing\\Multimodal Fusion-Pre Route Timing Prediction-DAC-2023-GNN-7nm RISCV.pdf)\nslice\nRestructure：预测终点的延时，但是Timing Opt会改变网表结构(end point不变）。对一个Pre-routing任务来说，输入的网表和最终的网表不一样\nnetlist restructuring causes a mismatch between local input features and ground-truth features in the restructured sub-regions\nAs a result, prior local-view models can only be trained on the unchanged regions in a semi-supervised manner.\nIn other words, the better the models fit on labeled (unreplaced) net/cell delays, the worse they fit on replaced regions and eventually on endpoint arrival time\n数据集：基本信息和Timing优化导致的网表变化\naverage 40% nets and 21% cells are replaced during timing optimization timing optimization brings an average change of 59.6% to net delays and 33.3% to cell delays 为什么用layout信息：Since most timing optimization techniques include gate insertion or gate sizing, placement should reserve space for subsequent timing optimization. In other words, the timing optimizer’s efficacy is tied closely to global layout information. The layout information plays a dominant role in determining the timing optimizer’s impact since most optimization techniques need space to be applied\n整体模型\n组成：GNN+CNN+Endpoint-wise Masking\nNetlist(GNN): 和 TimingGCN-STA prediction-DAC-2022-GNN很像(没发现不同)\nLayout(CNN+Endpoint-wise Masking)\n三个特征：cell density, rectangular uniform wire density (RUDY), and macro cells region\nEndpoint-wise Masking\n对比实验：\nrun time实验\nother # Ahead RC network-STA prediction-DAC-2022-?\nTSteiner-STA prediction and refinement\u0026amp;steiner point refinement-DAC-2023-GNN-Yibo Lin\nDoomed Run Prediction-TNS prediction-ACM-2021-GNN+RNN\nnot DL # The two-stage approaches [2], [3] first predict localnet/cell delays and then apply PERT traversals [5] to evaluate the global timing metrics, i.e., endpoint arrival time.\nOptimization # Timing # TSteiner - Steiner Points Opt-DAC-2023-GNN-CUHK\nbackground\n对于multi-pin net需要构建steiner tree来进行routing，故steiner tree中steiner points也会影响routing\nFLUTE[ 3]是常用的生成steiner tree的算法。在生成steiner tree后，我们可以通过近一步优化steiner point来优化timing\nthe previous early-stage timing optimization works only focus on improving early timing metrics. 提出了诸如net加权和可微分时间目标等策略来优化时间, only focus on improving pre-routing timing metrics, which may have a considerable gap to signoff timing performance. 斯坦那点更加靠近布线阶段(和布线更加相关)\nall the aforementioned works are not directly targeted at sign-off timing performance due to its high acquisition cost\n任务:\nIn this paper, we focus on explicit sign-off timing optimization at the pre-routing stage to reduce the turnaround time\noptimization framework is built to adjust Steiner point positions for better sign-off timing performance iteratively\nThe most popular Steiner minimum tree construction algorithms aim to minimize wirelength. Moreover, the Steiner point refinement is introduced to update the generated Steiner point positions for specific objectives, e.g., sign-off timing performance, while maintaining the two-pin net connections\n启发:\nwe surprisingly find that the signoff timing performance could be significantly affected even by a random disturbance on Steiner point positions, as shown in Fig. 2.\nNevertheless, the impact of random moving is considerately unstable, and its average performance is slight (with a ratio close to 1.0). 所以启发找到一个好的方法来更新斯坦纳点来降低TNS\n在最广泛使用的技术节点中，与路径长度最相关的定时度量——净延迟，并不能解释大部分的整体定时性能. 这里用的初始化斯泰纳树的方法的优化目标都是路径长度最短\ncontribution:\nfirst earlystage timing optimization framework via Steiner point refinement GNN TSteiner framework is fully automated with an adaptive stepsize scheme and the auto-convergence scheme improves 11.2% and 7.1% on average (up to 45.8% and 43.9%) for WNS and TNS 模型:\nSteiner tree construction decomposes each multi-pin net into a set of two-pin nets via additional Steiner points before global routing to reduce the problem complexity\nThe proposed framework can be divided into two stages, sign-off timing gradient generation (Section III-A) and concurrent Steiner point refinement (Section III-B)\n和TimingGCN相比就是多了Steiner 节点, 然后吧第一部分的的node embedding部分加上了steiner的部分\n实际是: 优化的指标, WNS和TNS的加权\n根据优化指标对斯泰纳点坐标参数做梯度下降\n相比简单的梯度下降，只是减小了对不同benchmark的手动学习率微调\n数据\n实验\nMarco Placement # -marco placement-nature-2021-RL+GNN-google\nPlacement # -Pin Accessibility+DRV prediction-DAC-2019-CNN-NTU # background:\nStandard cells on the lower metal layers severely suffer from low routability due to high pin density, low pin accessibility, and limited routing resources.\nIt can be observed that the access points of pin B are blocked by the metal 2 (M2) routing segments routed from Pin A and Pin C, so an M2 short design rule violation (DRV) will be induced when dropping a via12 on Pin B. pin accessibility is not only determined by cell layout design but also strongly affected by adjacent cells\n对于传统方法，两个缺点：\nCell libraries provided by foundries should not be considerably redesigned because the optimized cell performance and manufacturability may be highly sensitive to cell layouts Deterministic approaches based on human knowledge have been shown to be less effective in advanced nodes for optimization problems such as DRV prediction and minimization because of the extremely high complexity through the overall design flow It can be observed that most of the congested regions in the layout do not have DRVs, while some regions with DRVs are not so congested. 但是我感觉还是有相关性的。他是想说明congestion出现的地方不一定有DRV，但是没congestion的地方可能因为poor pin accessibility导致DRV\n也是说明：congestion出现的地方不一定有DRV，但是没congestion的地方可能因为poor pin accessibility导致DRV the two M2 shorts occur at the locations having the same pin pattern in the top cell-row and mid cell-row task:\nDRV prediction, 二分类\npin accessibility optimization, 给一个合法化后的布局结构，通过算法进行减少bad pin accessibility的detailed placement\n其实也是一个预测模型，一个优化模型\ncontribution:\nfirst work to apply pin pattern as the input features of DRV prediction models. flow:\nmodel:\nPPR\u0026amp;DFPPR:\nModel-guided Detailed Placement :\nDynamic Programming-based Placement Blockage Insertion\n还会改方向？ Cell Displacement Refinement\ndata:\nBoth the width and height of each pixel are set as the minimum spacing of the M1 layer in order to prevent a pixel from being occupied by two different pins.\n没看见关于benchmark的描述\nexperiment:\nshortcoming:\nflow need routed designs to train, time The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries 对于VLSI，一行一行，一对一对进行，很慢？ -Pin Accessibility+activ-ISPD-2020- -NTU+Synopsys # background:\nWith the development of advanced process nodes of semiconductor, the problem ofpin accesshas become one of the major factors to impact the occurrences of design rule violations (DRVs) due to complex design rules and limited routing resource\nsupervised learning approaches extract the labels of training data by generating a great number of routed designs in advance, giving rise to large effort on training data preparation. the pre-trained model could hardly predict unseen data\nUnlike most of existing studies that aim at design-specific training, we propose a library-based model which can be applied to all designs referencing to the same standard cell library set.\nDue to the shrinking of modern process nodes of semiconductor, the pin access problem of standard cells has become more harder to be coped with, especially on the lower metal layers.\n在这种placement下，Metal1 pin A/B由于各自左右两边在Metal2有pin，而且只能在黄色track下横向绕线，（Metal1不能绕线？），那么Pin A/B通过Via12后必定会短路\n19年工作[5]的两个缺点\nflow need routed designs to train, time The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries contribution:\nfirst work of cell library-basedpin accessibility prediction (PAP), which can be applied to predict other designs referencing to the same cell library set applies active learning to train a PAP model the proposed cell library-based PAP model can be trained at the earlier stage in a process development flow: once the cell libraries are provided. Placement Optimization with Deep Reinforcement Learning- -ISPD-2020-RL+GNN-Google # PL GNN-Affinity Aware for ICC2- ISPD-2021-GNN-Atlanta # background:\nPlacement is one of the most crucial problems, placement directly impacts the final quality of a full-chip design\nmultiple placement iterations to optimize key metrics(WL, timing), which is time-consuming and computationally inefficient, VLSI\nthe logical affinity among design instancesdominates the quality of the placement\nlogical affinity 源于这篇文章？\nperforming placement guidance requires in-depth design-specific knowledge,which is only achievable by experienced designers who knows the underlying data flows in Register-Transistor Level (RTL) well\nK-means基础：\ntask:\n基于网表数据，和floorplan结果（marco已经放好） placement guidance(grouping information) for commercial placers ICC2, by generating cell clusters based on logical affinity and manually defined attributes of design instances our framework will determine the cell clusters in an unsupervised manner which serve as placement guidance in order to guide commercial placers to optimize the key metrics such as wirelength, power, and timing by placing cells with a common cluster together flow:\nTwo stages:\nGNN do unsupervised node representation learning, (it is generalizable to any design)\nweighted K-means clustering algorithm [3] to group instances into different clusters。To find the optimal number of groups for clustering, we introduce the Silhouette score [19] and perform sweeping experiments to find the sweet spot\nK-means算法的基本思想是：通过迭代的方式，将数据划分为K个不同的簇，并使得每个数据点与其所属簇的质心（或称为中心点、均值点）之间的距离之和最小。\ndata\ntwo multi-core CPU designs：\nnf\ndesign hierarchy : 根据网表层级. top/inst1/sky130_INV/A. (同时zero-padding)\nlogical affinity of memory macros ：logical levels to memory macros 𝑀 as features. because the logic to memory paths are often the critical timing paths\nef:\nmodel\nGraphSAGE-based， two layers\nLoss Function:\nSilhouette score\n用于评估分类结果，扫描分类数目，选择最高的分的\nexperiment:\nenv:\n2.40𝐺𝐻𝑍 CPU NVIDIA RTX 2070 16𝐺𝐵 memory. PyTorch Geometric setting:\nthe placement of memory macros is achieved manually based on design manuals provided by the design-house Adam result\nLouvain：比较实验对比模型\nQuestion:\nbenchmark少\n扫描到的就适用所有？\n开环？\n-Innovus PPA placement optimize-Neurips-2021-RL # contribution:\n-GP Routability Opt-DAC-2021-FCN-CUHK(SitingLiu BeiYu)+Yibo Lin # background\nflow\nthree input features are extracted from the cell placement solution Through the inference of the pre-trained routability prediction model, we get the predicted congestion map. take mean squared Frobenius norm of this congestion map as the congestion penalty data\nmodel\nRouting # global routing # backeground # gr\ndrc\nPROS-Routability Optimization-ICCAD-2020-FCN-CNHK+Cadence # background\ntask\ncongestion predictor and parameter optimizer only the data from the placement it can optimize the cost parameters before the first routing iteration of GR and thus can give a better GR solution with less congestion. contribution\nwith negligible runtime overhead plug-in can be embedded into the state-of-the-art commercial EDA tool (Cadence Innovus v20.1) model\ndata\n19 different industrial designs\n通过不同的placement参数和旋转（CNN原理），一共有1664 design cases in total.\nFeature Extraction\nHorizontal/Vertical track capacity map\nCell density map\nFlip-flop cell density map\nFixed cell density map\nCell pin density map\nPin accessibility map\nHorizontal/Vertical net density map\nSmall/Large-net RUDY map\nPin RUDY map\na combination of cell pin density map and large-net RUDY map\nLabel Generation\nPROS does not need very detailed congestion map\ntwo-step smoothening process to convert raw data to desirable congestion labels\nhelp to make the prediction task easier\nif there are at least six congested G-cells out of the eight in the surrounding of a center G-cell д, д will be labeled as congested\n优化原理\n这两个值在cadence怎么改的? cadence企业内部自己弄的（这是cadence的文章）？\nmodel\nexperiment\nPROS 2.0 - Routability Opt+Route WL estimation-Trans-2023-CNN-CNHK+Cadence # background\nthe amount of routing resources on a design is limited. The quality of a GR solution has a great impact on that of the resulted DR routing solution Congestion in a GR solution is one of the major causes of DRC violations in the DR solution since most of DRC violations are due to overcrowded wires and vias [1], [2] a better GR solution with less congestion is needed to lower the probability of getting DRC violations in advance. if the initial GR solution is not good and has a lot of congestion, the GR tool can hardly tackle the problem by rip-up and reroute. placement engines [3]–[5] which take routing congestion into consideration are applied FCN:FCN常用于图像中的每像素分类问题。采用任意输入大小，并产生大小完全相同的输出。GR拥塞预测也可以被视为任意大小的芯片设计上的像素二进制分类问题（拥塞与否）。因此，基于FCN的预测器可以自然地应用于PROS。 task:\nstage: post-placement, pre-route FCN based GR congestion predictor, use the predicted GR congestion to optimize the cost parameters of GR. predictor based parameter optimizer to generate a better GR solution. GR tools are driven by the cost parameters stored in each G-cell. When arriving at a G-cell g, the tool will compute the cost, called moving cost, to move to each of its neighboring G-cells and push these costs into a heap. With optimized cost parameters in G-cells, the GR tool can find better paths and allocate the routing resources to each net more smartly. PROS optimizes two types of cost parameters based on the prediction result, including overflow cost and wire/via cost . PROS will adjust the cost parameters in the projected congestion regions on all layers overflow cost wire/via cost: divided into two groups (small/large) according to their BBox sizes. Increasing the wire/via cost for small nets may be useless for congestion reduction and it may even increase the wire length or create new congestion due to detours out of the potential congestion region. In contrast, increasing the wire/via cost for large nets can be helpful since they can select another route within its BBox to completely avoid the potential congestion region CNN based wirelength estimator , By multiplying the predicted wirelength ratio and the precomputed FLUTE wirelength (训练一个系数). The lack of consideration of routing congestion in traditional methods is due to the dif ficulty of quickly obtaining accurate congestion estimation at the placement stage contribution:\nplug-in for Innovus: it can avoid extra runtime overhead of feature preparation industrial design suite advanced technology node SOTA high accuracy first work that utilizes the information of GR congestion to estimate routed wirelength at the placement stage PROS does not change a lot for the original EDA steps Overall Flow :\n分类和回归\nF is the feature number. XWL has two features: These two features will be resized to 128 × 128 before prediction the predicted congestion map the cell pin density map data\nfeature F\nHorizontal/Vertical Track Capacity Map\nCell Density Map\nFlip-Flop Cell Density Map\nFixed Cell Density Map\nCell Pin Density Map\nPin Accessibility Map\nHorizontal/Vertical Net Density Map\nSmall/Large-Net RUDY Map\nPin RUDY Map ?\nlabel\ncongestion label pre-process\nPROS does not need a very detailed congestion map\n最后还是为了优化服务的\nmodel\nDC: get more local information, but more GPU usage(acceptable) SUB: w*h*4c –\u0026gt;2w*2h*c. Compared with bilinear upsampling which is not trainable, subpixel upsampling can learn to recover the local information. Compared with deconvolution, subpixel upsampling is parameter free, so it will not significantly increase the training difficulty. dataset\nindustrial benchmark suite and DAC-2012 benchmark suite(19个 benchmark)\nindustrial benchmark suite 通过11种不同布局参数，翻转和旋转，制造了一共有1664个(约等于19*11*8)benchmark\nDAC-2012 20 different placements\n(4, 4, 4, 4, 3) 5折交叉验证\nexperiment\nenv\nTensorflow Intel Xeon CPUs at 2.2 GHz 256 GB memory NVIDIA TITAN V GPU setting\nAdam\nOne entire training process of the congestion predictor has 25 training epochs! 这么少（收敛好快）\ncongestion classification prediction\ncompare with PROBABILISTIC METHODS\nDR优化结果\n线长估计\nRuntime\ndetail routing # background # -Detailed Router-DATE-2021-RL # [DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route](\u0026ldquo;D:\\MyNotes\\EDA\\Routing\\DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route.pdf\u0026rdquo;) # BackGround\nmost time-consuming stages in the package design flow package designs have fewer layers; thus, we need to prevent net crashing cautiously contrbution:\nredefine the routing area and shrink the routing problem by dividing the entire design into non-overlapping boxes use DRL, not heuristic prove the number of design rule violations (DRVs), wirelength and layout pattern. task\n2-pin nets Initial routing: ignores the number of bends and allows design rule violations\nModel\nmulti-agent deep reinforcement learning (MARL) task [15] for asynchronous routing planning between nets. We regard each net as an agent, which needs to consider the actions of other agents while making pathing decisions to avoid routing conflict\nroute and slide the window repeatedly. advantage of box:process every box independently\nsequential routing\nthe repulsion point will be moved from the inner ring to the outer one until the box is successfully routed.\n具体算法：\nsequential routing\nRefinement\n-Detail routing+match+Opt-ISPD-2023-RL+GNN-FinFET # background:\ncutom circuits: a custom detailed router cannot adopt specialized layout strategies for specific circuit classes like human layout experts\n一直在强调match的问题：\ncontribution\nopt roouting, FinFET, sign-off solution 异构图 A rip-up and re-routing scheme can easily adapt to future design constraints three categories of routing methodologies\nTemplate-based methods manual design suffers from scalability issues Simulation-based techniques provide accurate performance feedback and can be generalized to consider various performance metrics (e.g., phase margin, power dissipation) across circuit classes long execution time and resource-hungry computations Constraint-based approaches widely adopted in existing custom routing studies PR Tools # Placement and routing (PnR) is the most time-consuming part of the physical design flow\nPlacer # Chip Placement with Deep Reinforcement Learning-marcro-arXiv-2020-RL # Differentiable-Timing-Driven Global Placement-global placement-DAC-2022-GNN- # Polar 2.0 # An effective routability-driven placer\ncells that are estimated to have high congestion are spread out and inflated to distribute routing demand more evenly.\nNTUPlace3 # DeepPlace # flow\nRePlAce\u0026ndash;TCAD-2018- # DREAMPlace-GP-DAC+TCAD+ICCAD+DATE-2019~2023 # introduction\nOver 30X speedup over the CPU implementation ( RePlAce) is achieved in global placement and legalization on ISPD 2005 contest benchmarks\nDREAMPlace runs on both CPU and GPU. If it is installed on a machine without GPU, only CPU support will be enabled with multi-threading.\nDREAMPlace also integrates a GPU-accelerated detailed placer, ABCDPlace, which can achieve around 16X speedup on million-size benchmarks over the widely-adopted sequential placer NTUPlace3 on CPU.\nPublications\nYibo Lin, Shounak Dhar, Wuxi Li, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement\u0026rdquo;, ACM/IEEE Design Automation Conference (DAC), Las Vegas, NV, Jun 2-6, 2019 ( preprint) ( slides) Yibo Lin, Zixuan Jiang, Jiaqi Gu, Wuxi Li, Shounak Dhar, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement\u0026rdquo;, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 Yibo Lin, Wuxi Li, Jiaqi Gu, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;ABCDPlace: Accelerated Batch-based Concurrent Detailed Placement on Multi-threaded CPUs and GPUs\u0026rdquo;, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 ( preprint) Yibo Lin, David Z. Pan, Haoxing Ren and Brucek Khailany, \u0026ldquo;DREAMPlace 2.0: Open-Source GPU-Accelerated Global and Detailed Placement for Large-Scale VLSI Designs\u0026rdquo;, China Semiconductor Technology International Conference (CSTIC), Shanghai, China, Jun, 2020 ( preprint)(Invited Paper) Jiaqi Gu, Zixuan Jiang, Yibo Lin and David Z. Pan, \u0026ldquo;DREAMPlace 3.0: Multi-Electrostatics Based Robust VLSI Placement with Region Constraints\u0026rdquo;, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), Nov 2-5, 2020 ( preprint) Peiyu Liao, Siting Liu, Zhitang Chen, Wenlong Lv, Yibo Lin and Bei Yu, \u0026ldquo;DREAMPlace 4.0: Timing-driven Global Placement with Momentum-based Net Weighting\u0026rdquo;, IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), Antwerp, Belgium, Mar 14-23, 2022 ( preprint) Yifan Chen, Zaiwen Wen, Yun Liang, Yibo Lin, \u0026ldquo;Stronger Mixed-Size Placement Backbone Considering Second-Order Information\u0026rdquo;, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), San Francisco, CA, Oct, 2023 ( preprint) Architecture\nflow\nRouter # background # Global routing plays a crucial role in electronic design automation (EDA), serving not only as a means of optimizing routing but also as a tool for estimating routability in earlier stages such as logic synthesis and physical planning.\nOptimal(最优) global routing is a NP-complete problem.\nDRL：\n传统2dGR flow\n3dGR flow\nGR_outdated # FLUTE # FLUTE is an RSMT construction algorithm adopting a look-up table approach, which is both fast and optimal for low-degree nets. However, FLUTE is unaware of routing congestion.\n下面是一系列FLUTE和基于FLUTE的改进\nFastRoute1.0—2006 # roposed a simple way to construct congestion driven Steiner tree and an edge shifting technique to further refine it fastroute 2.0-Monotonic–2007 # monotonic routing to explore all shortest routing paths for two-pin connections. task\nflow\nfastroute 3.0-virtual capacity-ICCAD-2008- # fastroute 4.0-via min tree+3 bending-ASPDAC-2009- # 层分配\n?\nMaizeRouter- # 2nd place of ISPD 2007 contest 2D GR 1st place of ISPD 2007 contest 3D GR BoxRouter 1.0 # 3rd place of ISPD 2007 contest 2D GR 2nd place of ISPD 2007 contest 3D GR integer linear programming (ILP) based FGR-3d-TCAD-2008- # 1st place of ISPD 2007 contest 2D GR 3rd place of ISPD 2007 contest 3D GR -Layer assignment+Via minization-Trans-2008-DP-NTHU # Congestion-Constrained Layer Assignment for Via Minimization in Global Routing CUGR’s rely work ISPD07 contest后的一个跟进工作 也没提到maze routing 没定义wire cost, 在每一对GCell之间layer assignment, 慢？ 第一次用DP? background:\nthere are two main approaches\n3D: route all nets directly on the multilayer solution space. Because this approach directly generates a multilayer global routing result, it can take the via cost into account during construction. However, this method may cost too much CPU time with a large problem size. (现在都用GPU做并行了，这种方法就变多了)\nsuch as\n2D + layer assigment: The other approach is to first compress a multilayer grid graph into a one-layer grid graph, then use a one-layer router to solve the one-layer global routing problem, and finally perform layer assignment to assign each wire in the multilayer grid graph\nThe edges corresponding to vias disappear in the one-layer grid graph. The capacity of each edge in the one-layer grid graph is obtained by accumulating the corresponding edge capacities in the three-layer grid graph\nThis approach can take advantage of many current full-fledged one-layer routers, e.g., [2]–[4], and use an affordable run time to generate an initial one-layer routing result. 本文主要针对layer assignment. 注意layer assignment 是对二维的所有边进行层分配。\nvias not only degrade the reliability and the performance of a design but also increase the manufacturing cost.\nprevious work’s layer assignment use greedy heuristics [8] or time-consuming integer linear programming methods [9] to minimize the via cost.\n像这种串行的还是要考虑net order, 越早布线的net越不会拥塞，net order很重要\ntask and contribution:\n这篇没有考虑优先方向（To simplify the presentation of our algorithm, we do not make any assumption about the preferred routing direction for each layer in the layer assignment problem.）不过也说明了这个工作能够很简单引用到考虑优先方向的情况 follow ISPD07 contest, 假设via的capacity是无限的（CUGR中明确了不进行这种假设） based on a one-layer routing result minimize via cost, WL and congestion overflow propose a polynomial-time algorithm: first generate net order , then solves the layer assignment problem can improve 3 winner of ISPD07 contest model\nCOngestion-constrained Layer Assignment (COLA)’s submodule\nNet order generation\nThe net order has a direct influence on the utilization of routing resources, so it is one of the key parts of COLA.\n对net进行打分决定order\n注意，线长越短，分数越高，net越应该先布线。解释：\nEemove Cycles\nArbitrarily remove.\n（为什么映射到第一层会有cycles？初始是怎么连起来的？没说？FLUTE算法是08年才出来，可能当时还没用上）\nSingle-net layer assignment （SOLA+APEC）\nSOLA(Singlenet Optimal Layer Assignment)\ndetermines an optimal layer assignment result without considering congestion constraints for a given net\ndynamic programming technique\n不考虑拥塞，这个方法能得到最好质量\nstep:\n01: for tree in layer 1, random select a pin as root, then use DFS or DFS to get a queue, so get the edge order. It become a DAG\n02: 定义图5(c)中, a的父节点是p2，定义mvc(v, r)（minimum via cost）\n03:\n​\tfor pins who have not child, mvc:\n​\tfor pins who have child and not root:\n​\t这个公式其实就是为了确定下每个点下一步的layer在哪里。比如算出最小是mvc(v, 1), 那么e_(v, ch(e))就在第r层\n​\tfor root:\nthe difference is excluding r in ∆\nbecause mvc(v, r) does not depend on the value of r when v\nis the root, we have mvc (v, 1) = mvc(v, 2) = · · · = mvc(v, k)\nAPEC(Accurate and Predictable Examination for Congestion constraints)\ncan detect and prevent any congestion constraint violation in advance\nprevention condition:\n如果存在一个在layer1上压缩的边不满足这两个condition，那么这条边的layer assignment（SOLA）结果就不可能满足congesion\nSOLA+APEC always finds a layer assignment result satisfying both prevention conditions for each net\nCOLA\n​\ndata:\nsix-layer benchmarks from ISPD’07\nGRIP-3d+IP-DAC-2009 # 基于整数规划\n3d: solve the 3D problem directly on the 3D routing grids,\nslow: Although theoretically the direct 3D technique should produce better solutions, in practice it is less successful in both solution quality and runtime than 2D routing with layer assignment –cite–\u0026gt; [Fastroute4.1]\nslow: Although we see solutions with shorter wirelength generated by full-3D concurrent approach like GRIP [21], that solution quality is achieved by impractically long runtime –cite–\u0026gt; [Fastroute4.1]\nMGR–ICCAD-2011\nmulti-level （coarsened and fine-gained）\nFastRoute4.1-an efficient and high-quality global router-2012 # https://dl.acm.org/doi/abs/10.1155/2012/608362\nbackground\nFastRoute is a global routing tool for VLSI back-end design. It is based on sequential rip-up and re-route (RRR) and a lot of novel techniques. FastRoute 1.0 first uses FLUTE to construct congestion-driven Steiner trees, which will later undergo the edge shifting process to optimize tree structure to reduce congestion. It then uses pattern routing and maze routing with logistic function based cost function to solve the congestion problem. FastRoute 2.0 proposed monotonic routing and multi-source multi-sink maze routing techniques to enhance the capability to reduce congestion. FastRoute 3.0 introduced the virtual capacity technique to adaptively change the capacity associated with each global edge to divert wire usage from highly congested regions to less congested regions. FastRoute 4.0 proposed via-aware Steiner tree, 3-bend routing and a delicate layer assignment algorithm to effectively reduce via count while maintaining outstanding congestion reduction capability. FastRoute 4.1 simplifies the way the virtual capacities are updated and applies a single set of tuning parameters to all benchmark circuits.\nmodel\nflow\nNTHU Route 1.0- -TVLSI-2010- # NTHU Route 2.0- -TCAD-2013 # 2D\nNCTU GR 1.0-3D-congestion relaxed layer assignment- 2011- # it improved the scheme to estimate the realtime congestion more accurately by using a history term that will gradually wear off as the number of iterations increases if the overflow disappears. NCTU GR 2.0-Multithreaded Collision Aware- CAD-2013- # people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm\nPengjuY/NCTU-GR2: This is a binary file of NCTUgr2, which is a global router\nnet-level parallel method 2D BoxRouter 2.0 # background\ntask\n是一个2d的\n整数规划\nOGRE- new cost function- -2019- - # Open source! LEF/DEF-based 3D 用的是老方法，不过解释的挺清楚的 components by a group of undergraduate students as a course project. GR_Adv # -DRL method-2019-DRL- # task\nDRL(DQN) for global route have not use real world design example:\n​\tfrom A to B\n​\tread means over flow\npipeline\nmodel\nstate:\n(pos_x/y/z, distance_x/y/z, 周围的capacity, )这种编码方案可以被视为当前状态、导航和本地容量信息的混合 action: 上下左右前后\nreward：\ncontribution\nfirst deep learning model for global routing\n-only CNN-DAC-2020-CNN(VAE)- # no experiment! 只用CNN分类结果不会好吧 不知道是什么类型的文章，只用了两页 background\nis approach treats the global routing problem as an image processing problem and solves it with a deep learning system\ndataset\nISPD’98 ibm01 64x64 circuit\nmodel\n-DRL-arxiv-2021-JP # [SPRoute 1.0: A Scalable Parallel Negotiation-based Global Router-ICCAD-2019]( IEEE Xplore Full-Text PDF:) # task\n基于net-level多线程的并行加速迷宫算法\nnegotiation-based rip-up and reroute two-phase maze routing\nresolves livelock issue\nopen source\nintroduced a concept called soft capacity to reserve routing space for detailed routing and explored several parallelization strategies to speed up global routing. background\n总体\nIn many global routers, maze routing is the most time-consuming stage.\nchallenge\n因为这个现象，多线程反而慢了\n原理\nGalois system\nNet-level Parallelism\nFine-grain Parallelism\ndata\nISPD 2008 contest\nSPRoute 2.0- detailed routability driven-ASP DAC-2019- # 特点\n基于多线程的并行加速\n2D\n开源： asyncvlsi/SPRoute: A parallel global router using the Galois framework\nCUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK # ICCAD 2019 Contest First Place\nopen source!\n3d+多线程+\n这个文章没有讨论prefer direction\n多线程体现在哪里？\n注意：这种格式的GR输出可以适配Innovus\ntime-complexity of 3D pattern routing is $\\mathcal{O}(L^4|V|)$\ncompare with [Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU), CUGR reduces the complexity to $\\mathcal{O}(L^4|V|)$ by selecting the root carefully so that each vertex will have at most three preceding vertices instead of four. 注意，这里说 相比[Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU)的$\\mathcal{O}(L^5|V|)$ ，它的复杂度是$\\mathcal{O}(L^4|V|)$ ，感觉是放在了[Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU)进行不转弯的DP-based layer assignment方法上了，实际上按照本文说的方法，理论上是$L * L^{23}|V|$，因为CUGR每次是对一个L pattern为单位计算mvc,时间复杂度是$2L*L$.确实是$L^4$, CUGR对一个L pattern分了两部分计算mvc没一部分时间复杂度是$L*2$\nbackground\nA common strategy of doing 3D global routing, as adopted by NCTU-GR 2.0 [5], NTHU-Route 2.0 [6], NTUgr [7] and FastRoute 4.0 [8], is to first compress the 3D grid graph into a 2D grid graph and perform 2D global routing. directly route the nets in a 3D grid graph：FGR [10] , GRIP [11] , MGR [12] Traditional pattern routing generates 2D topologies only, while our proposed 3D pattern routing directly generates 3D topologies without the need of an extra layer assignment stage 使用DR结果进行多角度metrics 评估： task\ndetailed-routability-driven directly-3d multi thread GR contibution\nprobability-based cost scheme minimizing the possibility of overflow after detailed routing 3D pattern routing technique (2D pattern routing + layer assignment)(前面又说directly in the 3D space?) without overflow even only L shape patten routing pre-work[15] 是先在2d上进行pattern routing, 然后进行layer assignment, 这里是直接在3d进行pattern routing. 3d pattern routing can avoid loss of accuracy caused by compressing 3D grid graph to 2D multi-level maze routing: coarsened level –\u0026gt; searches for a region with the best routability. first narrows the search space to a smaller region fine-grained level –\u0026gt; searches for a lowest cost solution within the region patching mechanism further improve the detailed routability flow\nIn 3D pattern routing (inital routing), the nets are broken down into two-pin nets, and a dynamic programming based algorithm will route the two pin nets sequentially using Lshape patterns and stacking vias at the turns.\nIn the multi-level 3D maze routing phase, the grid graph is coarsened to shrink the routing space, and maze routing is first performed in the coarsened space with an objective to find a routing region with the highest routability. A fine-grained maze routing will then search for a lowest cost path within the region. use its patching mechanism here.\nmodel\nGcell之间的容量等于track，一般GR表征via的容量是无限的，但是在本文中不是\nthree base definition:\nresource = capacity - demand 这三个变量在GCell和wire_edge上都有特征，也就是说有6个值 resource 能够直接表示拥程度 cost scheme\n主要分成wire和via两部分：\nwire cost:\n*wl*is wire lenght cost\neo is expected overflow cost, where uoc is hyper parameter, The larger d(u, v) is, the more likely it is to be congested. is accurate if the DR adopts the simplest strategy of picking a track randomly to route. However, most well designed detailed routers will do much better than random selection.\nlg(u,v) is a variable to refine d(u, v). “+1” 是为了值域在（0，1）表示概率。 slope is hyper parameter. When the resources are abundant, there is almost no congestion cost, but the cost will increase rapidly as the resources are being used up and will keep increasing almost linearly after all the resources are used\nvia cost:\nthanks to our 3D pattern routing strategy, a via cost scheme can be embedded to reflect the impact. uvc is hyper parameter. 公式（5a）为什么要“+1” Initial Routing / 3D Pattern Routing\nuse FLUTE first (not congestion awared)\nuse edge shifting (described in FastRoute) to alleviate congestion.\nrandomly choose one node in net, use DFS to get a queue and then get a DAG\n类似[15]，动态规划选择cost最小的3d L pattern，每个L pattern有(2 * L * L)种可能\n最后在root处得到最终的结果\nMulti-level 3D Maze Routing\nmaze route planing\naims at finding a smaller but highly routable search space\ncompress a block of G-cells (5x5 in our implementation), use avg to descripe capacity, demand, resource\ncost function:\n得到灰色粗网格：\n之后会在这几个BBox中分别进行计算cost scheme，得到上图黑色实线\nfine-grained maze routing within guides\nPostprocessing / Guide Patching\nwe can add new guides to improve detailed routability. adding new stand-alone guides to alleviate routing hot spots.\nthree kind of patching:\nPin Region Patching\nmost effective\nthe ideal way of improving pin accessibility is to identify those hard-to-access pins and assign more resources to them\nOur global router will check the upper (or lower) two layers of a pin, which are vital for accessing the pin. use 3 × 3 patching guides.\n没写判断hard-to-access pins 的具体的方法\nLong Segment Patching:\na longer routing segment often means more wrong way wires and causing more congestion. If a guide is longer than a specified length I, we’ll consider long segment patching. if a G-cell with resource below a threshold T is encountered, a single G-cell route guide will be patched above or below it, depending on which of them has sufficient resource Violation Patching:\nFor G-cell with inevitable violations, patching will be used again to enable the detailed router to search with more flexibility.\ndata\niccad 2019 dataset\nexperiment\n他自己又比赛后改进了\nour algorithm’s peak memory is close to the first place and is 1.83 times of that of the second place on average (ours is 8.22 GB on average and is 19.8 GB for\nthe biggest design)\nFastGR-GPU pattern routing+ multi thread maze–DATE-2022-PKU+CUHK+HNAL # GPU-accelerated accelerated the 3D pattern routing algorithm of [CUGR](# CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK) for initial routing by both net-level and path-level parallelization on GPU Gamer- -Trans-2022- - # GPU-accelerated accelerated the two-level maze routing of [CUGR](# CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK) for rip-up and reroute by updating vertical and horizontal routing costs alternatively on GPU GGR-super fast gpu accelerate-ICCAD-2022- # open source！ Xplace/cpp_to_py/gpugr at main · cuhk-eda/Xplace\nbackground\nPerformance depends on the detail route\nModern global routing problem, which was introduced at the 2019 CAD contest at ICCAD, targets at closing the gap between global routing and detailed routing. The LEF/DEF files for detailed routing are directly used as the input for global routing.\nThe global routing quality is evaluated using an academic detailed router Dr. CU[8]\n2019 ICCAD contest on global routing did not directly evaluate global routing results based on overflows and total wirelength. The new evaluation uses the global routing results as route guides for a detailed router, and the metrics are all detailed routing related\n2D \u0026amp; 3D\nNCTU-GR 2.0[13], SPRoute[7] and FastRoute 4.0[14] are 2D GR\nHowever, compressed 2D grid graphs are less accurate than 3D grid graphs in terms of routing resources, which could limit the global routing quality.\nCUGR[11]. It has both 3D pattern routing and 3D maze routing\nmulti-thread vs GPU\nLEF/DEF based academic global routers SPRoute 2.0[6] is the only 2D GR\nGAMER[10] is a novel parallel maze routing algorithm integrated in CUGR.\nFastGR[12] introduced GPU parallelization of L-shape pattern routing\ncontribution\nflow\ndata\nmodel\nCUGR 2.0-DAG-based-DAC-2023- -CUHK # open source! background\nmany of the aforementioned global routers is that most of them rely heavily on time-consuming path search algorithms like maze routing to resolve overflows. These approaches are not efficient enough even with parallilization and may cause lots of unnecessary detours contribution:\na DAG-based generalized pattern routing algorithm\na new dynamic programming-based algorithm to calculate the routing cost\ntime complexity from $\\mathcal{O}(L^4|V|)$ to $\\mathcal{O}(L^2|V|)$\na DAG augmentation algorithm that enables the creation of alternative paths in a routing DAG. can even shift or create Steiner points. over 99% nets can be successfully routed without the need of maze routing\na new sparse graph maze routing algorithm\ncreation of alternative paths in a\nrouting DAG\nflow\nRSMT\nDFS and Routing DAG with L pattern\n注意多了节点g,f,i,h, 现在每条都是直线\nRouting DAG with other patterns，但是在这里没用做初始布线，初始只用了L-shape。文章也就这里提了一下，后面都和这个无关，得去源码仔细看看。\nDynamic Programming-based DAG routing(L-shape + Layer assignment)\n没说怎么舍弃的？\nDAG-based pattern routing with augmentation\nsparse graph maze routing algorithm\nmodel\ncost\nDynamic Programming-based\nDAG Augmentation for Congestion\ncreate alternative paths\nSteiner point movement\n具体怎么移动的文章也没说\nexperiment:\ncompare with CUGR [12] and SPRoute 2.0 [13]\nonly one thread for run time\nEffectiveness of steiner point augmentation\nrun time compare with GPU-accelerated GR\ncompare with FastGR [14] and GAMER [15]\nGPU的好坏也有关系吧。本实验用的RTX 3090\nslightly faster than FastGR for initial routing\naround 5.2× as fast as GAMER\nInstantGR-Scalable GPU Parallelization-ICCAD-2024-CUHK # open source! second place of ISPD25 contest GPU Parallelization parallel algorithm is mainly based on the DAG-based global routing algorithm in [CUGR2](# CUGR2.0 EDGE- -DAC-2023-). 应该是3D pattern routing DP的部分和maze routing的部分 parallel while do initial routing and RRR 提高了并行度，但是还是有串行的部分 也用了FLUTE 一定要以net为单元吗？是为了用DP background\nGPU memory is limited This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored nets in a batch can be routed in parallel task:\nparallelism for large-scale partitioned design contribution\na new method for net-level batch generation. based on 3D fine-grained overlap checking and explores more parallelism by increasing the number of nets per batch node-level parallel routing approach. achieves much higher parallelism compared to traditional net-level parallel routing. flow\nIn initial routing, we construct a basic routing DAG to perform L-shape pattern routing. key points\nspecific explanation show in routing2\nNET-LEVEL PARALLELISM\nsimultaneous routing of a batch of nets that do not “overlap”\n[2, 3, 14, 19, 20, 22, 26] 19年开始的，cugr2和fastgr都用了\nTypical Batch Generation Algorithm\nused in [2, 3, 14, 19, 20]\nR-trees 是实现line 4的常用做法\npessimistically approximates significantly lowers the degree of parallelism\ndefine and graph model\n以segment为单位，同时分开了水平和垂直两个部分，假设全部为L-shape，同时对于不在一条线上的两个节点，有两个L\nThese four nets will be divided into just one batch based on our exact representation of routing graphs for overlap checking, while into four batches by the traditional bounding box-based pessimistic approximation\nvia model:\nvia用一个十字表示\nOverlap Checking Algorithms\n以水平子图进行展示，垂直同理\n以水平segment为单位进行checking\n首先判断是不是y坐标相等：group the segments with the same 𝑦\ntradictional algorithm:\nThis is a classical computational geometry problem that can be efficiently solved by segment trees [1] in 𝑂(log𝑛) time for both operations,\nnew algorithm motivation:\nsegments are very short\nnew algorithm: Point Exhaustion\nsimply use a Boolean array to record whether each point in [1, 𝑛] is covered by some segment 𝑠 ∈ 𝑆. We mark every point 𝑥 ∈ [𝑙, 𝑟] when a segment [𝑙, 𝑟] is inserted, and check every point 𝑥 ∈ [𝑙𝑞, 𝑟𝑞] for overlap query of a segment [𝑙𝑞, 𝑟𝑞].\nfurther improve the efficiency of this point exhaustion by using bit arrays\nanother improvement: representative point exhaustion allowing a little bit of overlap. it only checks the two end points of a query segment. ??什么意思 covering most overlap scenarios in practice. The only scenario that this algorithm fails to find the overlap of two overlapping segments is when the query segment [𝑙𝑞,𝑟𝑞] contains the overlapping segment [𝑙,𝑟], [𝑙,𝑟] ⊂ [𝑙𝑞,𝑟𝑞] NODE-LEVEL PARALLELISM\n还是以net为单位分到不同的batch？\nrouting nodes of the same depth in parallel\nSuppose we have 4 nets, Net A, B, C and D in our grid graph. Since nets with overlap cannot be routed together, Net A and B are distributed to batch 0, as shown in Figure 7a, and nets C and D are distributed to batch 1.\nexperiment:\n4 NVIDIA A800 GPUs and 8 CPU threads.\ncompare different overlap checking methods\nThe number of nets per batch is limited to 1000\ncompare 2 largest benchmark\ncompare with Top-3 Global Routers of ISPD2024 Contest\nRuntime (s) of DAG-Based Augmented Routing with and without Node-Level Parallelism\nacceleration 那一行好像是加速倍率才对\nHeLEM-GR-Heterogeneous+Linearized Exponential Multiplier Method-ICCAD-2024- -PEK # first place of ISPD25 contest not open source 2025/2/6 2D routing algorithm background\nPRNet- -NeurIPS-2022- -SJTU+Noah’s Ark # PRNet can generate each route in one-shot but cannot guarantee connectivity which requires considerable post-processing for failed routes HubRouter 是两阶段框架，PRNet 是端到端框架。 HubRouter-generative model-NeurIPS-2023-GAN+RL-SJTU # open source! a chinese interpretation a global routing solver that includes a two-phase learning framework HubRouter 是两阶段框架，PRNet 是端到端框架。 对比 PRNet 生成模型，PRNet 在 CGAN 中使用双向映射将连接约束注入训练目标，将准确率提高了 10%，但在复杂情况下几乎无效。 background\n全局布线(Global Routing - GR)是 VLSI 设计中最复杂且最耗时的组合问题之一。GR 目标是总线长最小，同时避免拥塞(Congestion)，是个 NP 问题。\n传统采用启发式算法，多样性和规模问题对传统算法有了挑战，机器学习(ML)已经用于全局布线，在芯片设计中从逻辑合成到布局\n深度强化学习(Deep Reinforcement Learning - DRL )和生成式模型(Generative model)已经被用来解决全局布线。问题在于，DRL很受状态空间(State Space)影响，随着网格空间增大，需要花费大量时间生成。However, DRL methods suffer from large state space and often need to spend enormous time on generating routes as the scale of grids increases on the test instance, i.e., the netlist, which is practically intimidating for real-world global routing\n相反，生成式模型有一次性生成能力，在计算上更容易处理。\n生成式方法在训练时候考虑连通性限制，确保布线满足电路连通性要求。但是问题在于，如果初始生成路径不满足连通性要求时候，后处理阶段会变成一种穷举搜索过程。\n图一这里上图表示原始布线，下图表示算法生成的布线，生成布线没有正确连接所有应该连接的点(pin)，对于这样的情况，平均连通率很低，低于20%，意味着超过80%的生成布线需要经过耗时的后处理才能达到要求。显著的缺点。其实就和[CNN-based](# -only CNN-DAC-2020-CNN(VAE)-)这篇一样\ncontribution:\n为了解决上述问题，定义了一个新的概念，叫hub。将pin - pin问题 \u0026ndash;\u0026gt; hub - pin问题 。\n提出了一种新的两阶段全局布线方法 \u0026ndash;\u0026gt; HubRouter\ngeneration phase（生成阶段）\nhubs, routes, and stripe masks are together generated under a multi-task framework by generative models\n可以在多个框架下生成，比如 GAN (Generative Adversarial Nets) , VAE (Variational Auto-Encoder) , DPM (Diffusion Probabilistic Models) 。虽然hub是生成阶段的主要输出，但为了提升生成质量和准确性，发现生成附加信息是非常有用的。比如感知和掩码(local perception and stripe masks)，能够去除噪声点。引入多任务学习，布线和掩码一起生成，提高 hub 生成质量\npin-hub-connection phase（hub和pin连接阶段）\n将连接视为最小斯坦纳树(RSMT)问题，使用 actor-critic 模型网络策略。\nis hub generate correcttly, reconstruction time complexity can be reduced to O(n log n)\nSOTA generative global routing models\nmodel:\nHub\n(virtual) key point in the route transferring the pin-pin connection problem to the hub-pin connection problem 斯坦纳点(Rectilinear Steiner Point \u0026ndash;\u0026gt; RSP)是搜索全局最小总距离，但是 hub 是来确定路径。RSPs are special cases of hubs RSP是Hub的特例，Hub可以随意生成不同形状的路径(不仅是最短的) 这里的 c 和 x 分别代表条件图像和输入图像。条件图像可能包括引脚位置、已经提取的中心点以及条带掩模（stripe mask）。条带掩模是用来指示布线区域的一种方式，它可以帮助模型更好地理解哪些区域可以用于布线 flow\nhub生成阶段\nHub 生成可以表示为图像到图像的multi-task learning framework 任务, address the impact of sensitive noise points with stripe mask learning\n附录 B 介绍了将 GAN，VAE，EAN 纳入到生成框架\n在这个阶段，模型旨在逼近条件分布 pθ(x|z, c) 使其接近先验分布 p(x|c)。给定条件 c 和从先验分布 pz(z) 中采样得到的潜在变量 z（通常假设为高斯分布），模型会生成一些“中心点（hubs）”. 这里的 c 和 x 分别代表条件图像和输入图像。z is a latent variable from a prior distribution\nThe main objective of hub generation is to minimize the difference between probability distributions p(x|c) and pθ(x|z, c)\na noise hub, especially the outermost one, can largely harm the wirelength of routing. Use stripe mask to focus on bad cases for hub generation\nhub和pin连接阶段\n模型连接第一阶段生成的中心点，以获得最终的布线路由。这个过程可以被视为构建矩形稳定最小生成树（Rectilinear Steiner Minimum Tree，RSMT）的一部分。为了完成布线，模型遵循了一个基于强化学习（Reinforcement Learning，RL）的算法 REST。 在两阶段的过程中，作者还提出了一个多任务学习框架来提高生成中心点的质量。特别是，提出了一种新颖的条带掩模学习方法，旨在减轻噪声点案例可能造成的负面影响。算法的具体细节在附录 B 中给出。 detail router # DRCU\nacademic detailed\n综述 # ML4PR # Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview\n放置和布线是两个不可或缺且具有挑战性的 NP-hard 问题\n机器学习凭借其数据驱动的性质显示出了广阔的前景，它可以减少对知识和先验的依赖，并且通过其先进的计算范式具有更大的可扩展性 (例如 GPU 加速的深度网络)\n挑战:\nplacement:\n在路由完成之前，无法评估诸如可达性之类的放置目标；因此，在优化循环中可能需要花费数小时才能获得反馈，这对于进行数千次查询来说是负担不起的 现代的放置器需要在几个小时内处理数万个宏和数百万个标准单元。这种可扩展性的要求仍然超出了现有 ML 方法的能力 routing:\n在公平的比较下，现有技术很难在效率和求解质量上系统地优于经典布线算法 大多数基于学习的技术在具有数千个网络的小型电路上工作得很好，而实际的布线引擎需要在超大型 3D 网格图 ( \u0026gt; 1000 × 1000 × 10 ) (\u0026gt; 1000 × 1000 × 10)(\u0026gt;1000×1000×10) 上有效地处理数百万个网络并产生高质量的解决方案 相关工作\nplacement\nRouting\n超大规模集成电路布线算法综述 # 超大规模集成电路布线算法综述\nbackground\n布线相关详细看routing2.md, 详细布线、面向可制造性设计的布线算法 还没记录\nEDA+GNN # 详细看 A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks\n参考 # [AI技术带给EDA的机遇和挑战](AI技术带给EDA的机遇和挑战-Yibo Lin.pdf) [Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview]([ 读论文] Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview_toward machine learning\u0026hellip;.lake-CSDN博客) 【阅读】A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN综述翻译_ppaml-CSDN博客 bak # CongestionNet-Congestion Prediction-IFIP-2019-GNN\n-placement Congestion prediction-arXiv-2021-GNN\n输入：网表\n输出：congestion at placement stage\nEDA-ML: Graph Representation LearningFramework for Digital IC Design Automation\n德雷塞尔大学电气与计算机工程系 Pratik Shrestha和Ioannis Savidis\nbackground\nVLSI : traditional methodologies -\u0026gt; ML,Graph representation learning ability to capture complex relationships in graph-structured data\nGNN：\ntask\nflow\ndata\n模型\n实验\n相关数据集 # only rtl # Home :: OpenCores # IWLS 2005 Benchmarks # openlane-examples: Examples from the Openlane repository # Global route # ISPD-2007 # the first published multilayer global routing benchmarks and the sizes of these benchmarks are large enough as compared to real industry cases has a two-layer and a six-layer version. ISPD-2008 # ICCAD-2019 # 2019 CAD Contest @ ICCAD\nISPD-2024 # Dockerfile无法创建镜像了，401，Github也找不到benchmarks\nISPD-2025 # Detail Route # ISPD-2018/2019 # Initial Detailed Routing Contest at ISPD 2018\nInitial Detailed Routing Contest at ISPD 2019\n一个别人写的parse脚本：Handling-the-ISPD19-benchmark-dataset\nhttps://ispd.cc/contests/19/ispd19eval.tgz：一个结果验证工具\n还可以看看被人的结果\ncongestion/DRC/IR drop/timing # circuitnet/CircuitNet: CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA)\n背景：\nf.daixianiu.cn/csdn/14209355328255857.html在研究过程中，我们发现AI+EDA的研究常常受限于公开数据集，不像计算机视觉领域有ImageNet这样的大数据集可以很方便地验证算法。针对这一问题，我们近期跟黄如院士、王润声教授等合作，发布了首个致力于芯片设计AI for EDA应用的开源数据集——CircuitNet，包含1万以上的数据样本，涵盖从实际制造工艺PDK下数字设计流程不同阶段中提取到的各类特征。 TimingPredict/TimingPredict: Official open source repository for \u0026ldquo;A Timing Engine Inspired Graph Neural Network Model for Pre-Routing Slack Prediction\u0026rdquo; (DAC 2022)\n相关会议/期刊 # 会议 # DAC:\n每年举办一次学术论坛和工业贸易展览 一般11月截止 ICCAD：\nInternational Conference on Computer-Aided Design 由电气电子工程师学会（IEEE）和美国计算机学会（ACM）共同举办的国际计算机辅助设计会议（ICCAD）被公认为EDA领域最重要的会议之一，享有很高的国际学术地位和广泛的影响力。该会议是探索EDA研究领域新挑战、展示前沿创新解决方案和识别新兴技术的重要论坛，涵盖了从器件和电路级到系统级的所有设计与自动化主题、以及后CMOS设计等新型方向。着重于学术研究，论文涉及专门的算法的研究进展。 一般4月截止 DATE 2025\nDesign, Automation and Test in Europe Conference 欧洲设计自动化和测试会议 一般9月截止 ASP-DAC\n亚洲、南太平洋设计自动化会议 一般7月截止 ISPD：\nInternational Symposium on Physical Design\n国际物理设计会议。是专注集成电路物理设计的国际研讨会，主题涵盖从ASIC和FPGA的传统物理设计到新兴半导体技术的物理设计自动化方法。\nCCF-C. 9月份左右\n每年ISPD会议同步举办国际物理设计竞赛，通常由国际知名芯片企业命题和组织，竞赛历时3个多月，结果在ISPD会议上揭晓。\nGLSVLSI\nCCF-C 大湖区超大规模集成电路设计国际会议 一般2月截止 25年为第35届 VLSI:\n有个DTCO? 一般1月 ISEDA:\n由IEEE和ACM主办，EDA²和CIE EDA委员会联合主办的ISEDA （EDA国际研讨会）是一个致力于VLSI设计自动化的年度顶级论坛。研讨会旨在探索新的挑战，展示前沿技术，并为EDA社区提供预测EDA研究领域未来发展方向的机会。ISEDA涵盖了从器件和电路级到系统级的所有EDA主题，从模拟到数字设计以及制造。会议的形式旨在培养富有成效和新颖 二月 25年第三届 NeurIPS ICML 期刊 # TCAD\n由美国电器电子工程师学会（IEEE）出版(就是Trans?) TODAES\n由美国计算机学会（ACM）出版的电子系统设计自动化汇刊 It publishes innovative work documenting significant research and development advances on the specification, design, analysis, simulation, testing, and evaluation of electronic systems, emphasizing a computer science/engineering orientation. Design automation for machine learning/AI and machine learning/AI for design automation are very much welcomed. For topics of interest please see https://dl.acm.org/journal/todaes/about. 参考 # (99+ 封私信 / 81 条消息) 集成电路设计的学术会议含金量排名如何？ - 知乎 相关科研实验室 # 清华 # 清华大学是国内较早从事EDA研究的高校，洪先龙教授和边计年教授做物理实现和逻辑综合，两位老先生的学生大部分去了三大EDA公司\n北大-无锡EDA研究院 # 无锡北京大学电子设计自动化研究院\n北京大学无锡电子设计自动化研究院-开源工具整合\n北京大学集成电路学院成立了国内唯一聚焦EDA技术的“设计自动化与计算系统系”，打造先进的教学与人才培养体系，并与国内外领先的企业深入合作，部分成果已经成功得到转化应用，相关技术是业内目前唯一的解决方案；近期依托院系新成立了无锡北京大学EDA研究院，加上此前与EDA及设计方向头部企业共建的多个联合实验室，形成了教育、科技和人才三位一体的布局。\n研究方向包括布局布线、FPGA设计自动化的可重构算法\n林亦波 Yibo Lin:yibolin@pku.edu.cn\nContest@ISPD 2024第一名指导的本科生赵春源提出的高效GPU异构并行布线算法\nCADathlon@ICCAD 2024第一名指导郭资政（毕设开源项目作者）、麦景。在9小时内，运用自己的编码和分析技巧来解决6道集成电路与系统中电子设计自动化问题\nCAD Contest@ICCAD第一名指导杜宇凡、郭资政。C赛题《Scalable Logic Gate Sizing Using ML Techniques and GPU Acceleration》\nDreamPlace, Limbo开源项目作者\n相关采访 北大林亦波：探索AI+EDA新路径 | 青源专栏 2022-09\n一个现象：\n复旦 # 集成芯片与系统国家重点实验室\n研究方向包括物理实现、参数提取、逻辑综合、可制造性设计等方向\n陈建利教授\n指导蔡志杰、魏民、邹鹏，ISPD 2024 contest 第三名 北航 # 港中文-EDA Center # CUHK EDA Center官网\nCUHK EDA Github\nBei Yu(余备)@CUHK-CSE\nbyu@cse.cuhk.edu.hk\nResearch Topics\nCAD Contest@ICCAD 2012第二名获得者\nSiting Liu(刘思婷)@CUHK-CSE\nlusicaliu@outlook.com\nF.Y. Young\nJinwei Liu 陈廷欢CHEN, Tinghuan\n方向：VLSI CAD and deep learning accelerators for edge devices chentinghuan@cuhk.edu.cn CHEN, Tinghuan # 福大 # 福州大学早期EDA研究始于范更华教授和朱文兴教授，当前的研究方向主要是物理实现。福州大学团队曾连续三年在CAD Contest@ICCAD夺冠。\n福州大学团队在CAD Contest@ICCAD大赛中提出的6T\u0026amp;6T PPNN单元布局方法已转让给华大九天\n林智锋教授\n指导陈忆鹭、吴昭怡， ISPD 2024 contest 第三名 上海交大 # 首页_上海人工智能实验室\n东南大学-国家ASIC工程中心 # 研究方向是亚阈值和近阈值相关的时序分析\nCAD Contest@ICCAD 2017第一名获奖者福州大学的朱自然（Ziran Zhu）毕业后任教于东南大学ASIC中心\n2020年和国微集团成立EDA联合实验室，瞄准EDA共性技术研发\n时龙兴:\n老所长 闫浩:\nyanhao@seu.edu.cn 领域：智能EDA，面向先进工艺、高能效电路设计中存在的问题，应用人工智能算法辅助电路设计；先进制程/低电压下的时序分析与优化 华中科技大学 # 西安电子科技大学 # 在国内较早开始从事成品率分析算法的研究，并且一直在宽禁带半导体的器件建模、可靠性分析等领域有深入的研究和突出的成果\n在2019年和囯微集团建立EDA研究院之后，开始进入布局布线和原型验证领域\n广东工业大学 # 电子设计自动化（EDA）科研团队-广东工业大学集成电路学院\n电子设计自动化（EDA）科研团队依托广东工业大学集成电路学院成立。面向人工智能辅助集成电路设计EDA工具开发、应用等国家重大战略与行业重大需求，以人工智能辅助EDA为研究核心，聚焦于数字集成电路设计后端工具、FPGA设计工具优化等领域的前沿基础理论和关键技术研究。团队主要开展“数据驱动机器学习的集成电路智能设计”、“人工智能方法实现集成电路的敏捷设计”、“基于传统的分析和优化技术的集成电路辅助设计”等研究\n数据驱动机器学习的集成电路智能设计 人工智能方法实现集成电路的敏捷设计 基于传统的分析和优化技术的集成电路辅助设计 国立清华大学 # University of California # Design Automation Laboratory\n相关企业/机构 # 华为诺亚方舟 \u0026amp; 海思 # Huawei Noah’s Ark Lab AI4EDA\nCAD Contest@ICCAD 2018第一名获奖者香港中文大学的陈劲松（Jingsong Chen，2021年博士毕业）毕业后加入华为\nEDA国创中心 # 与东南大学 有关联\n中心介绍—国家集成电路设计自动化技术创新中心，EDA国创中心【官方网站】\n芯行纪 # AmazeSys # 应用于数字芯片物理设计领域的布局布线工具\n包含宏单元布局规划、电源规划、布局、时钟树综合、布线、优化、寄生参数提取以及时序功耗分析等全功能模块，支持先进工艺制程下的超大规模设计，可完成数字芯片从Netlist到GDS的完整设计流程，快速达成性能、功耗、面积优化等设计目标\n基于强大的机器学习引擎内核，AmazeSys具备自适应超高质量优化能力。该引擎智能提取设计本身特点进行样本训练，综合性能、功耗、面积和布线拥塞等多项关键指标，快速获取量身定制的最佳优化方案，可有效帮助用户降低调整大量工具设置的时间成本。\nAmazeFP # 智能布局规划工具AmazeFP将机器学习技术与布局规划引警结合，在兼顾性能、功耗和面积(PPA)的同时，提供了高度智能的拥塞感知、便捷的数据流分析和宏单元自动整理对齐功能，有效解决当前数字芯片在后端设计阶段的布局规划节点面临的经验值需求高、手工耗时长、数据流结构分析不够深入、设计目标收敛性差等难题，助力用户在后端设计初期快速有效地获取高质量布局规划方案，减少迭代次数，从而节约大规模设计的研发成本，提速产品上市时间。\nAmazeFP-ME # 作为一款EDA机器学习的工具，AmazeFP-ME在AmazeFP的基础上，能够快速探索数百倍甚至更多的庞大解空间，无需用户手动调参，同时配备优异且精准的数据、图形分析功能，可为用户提供高效便捷的设计体验\nAmazeFP-ME作为AmazeFP的AI配套工具，将机器学习技术引入到AmazeFP的解空间探索中，不仅进一步显著地提升了PPA，还为用户创造全新的自动化使用体验。\nAmazeDRCLite # 云 # 华大九天 # 东南大学-华大九天-NiiCEDA联合实验室\nPyAether # Aether就是全定制电路（例如模拟、存储、射频、平板等）设计平台，包括原理图，版图，仿真环境，以及数据版本管理工具和Python接口等。\nPython拥有众多针对****数据科学和人工智能的强大的开源库，例如NumPy和Pandas用于数据处理，Matplotlib用于数据可视化，Scikit-Learn提供了大量的预处理方法和机器学习算法，TensorFlow和PyTorch则是深度学习领域的重要工具。这些库大大降低了开发难度，使得Python在AI领域的地位无可替代。所以无论是数据清洗和预处理，还是模型建立，例如决策树，神经网络，贝叶斯优化等，以及模型训练和测试，对模型结果的解读等，都会天然的使用Python。\n所以Python的开放性生态、天然的数据挖掘、包括机器学习的人工智能（AI）以及各类算法优化包，友好的web开发，使用户可以在更开放、更强大的生态体系里开展设计。可以用它来构建电路与版图的自动化任务，快速进行数据处理和分析。例如，PyAether可以赋能IC CAD，更好得响应IC 设计和版图各种要求。\n10月18日深度解析 PyAether EDA 生态系统，带您探索电路设计自动化的秘籍！ - 华大九天PyAether - EETOP 创芯网论坛 (原名：电子顶级开发网) - import pyAether class InvLe: def __init__(self, lib, cell, tech_lib, view=\u0026#34;layout\u0026#34;, mode=\u0026#34;a\u0026#34;): r\u0026#34;\u0026#34;\u0026#34;InvLe init function, receive the specified layout information. Parameters ---------- lib : str Library name. cell : str Cell name. tech_lib : str Attach tech library name. view : str View name, the default value is \u0026#39;layout\u0026#39;. mode : str Mode for open design, the default value is \u0026#39;a\u0026#39;. \u0026#34;\u0026#34;\u0026#34; pyAether.emyInitDb() pyAether.emyInitLog() self.pnt_x = 0 self.pnt_y = 0 self.namespace = pyAether.emyUnixNS() self.design = self.open_design(lib, cell, view, mode=mode) self.block = self.design.getTopBlock() if self.block is None: self.block = pyAether.emyBlock.create(self.design) self.uu2dbu = self.block.getDBUPerUU() oplib = self.design.getLib() tech_scl = pyAether.emyScalarName(self.namespace, tech_lib) tech = pyAether.emyTech.open(tech_scl) tech.attach(oplib, tech_scl) def open_design(self, lib, cell, view, view_type=\u0026#34;maskLayout\u0026#34;, mode=\u0026#34;r\u0026#34;): r\u0026#34;\u0026#34;\u0026#34;This function is used to open design and return an emyDesign object. Parameters ---------- lib : str Library name. cell : str Cell name. view : str View name. view_type : str Type of view, the default value is \u0026#39;layout\u0026#39;. mode : str Mode for open design, the default value is \u0026#39;r\u0026#39;. Returns ------- design : emyDesign An emyDesign object opened by given parameters. \u0026#34;\u0026#34;\u0026#34; lib_scl = pyAether.emyScalarName(self.namespace, lib) cell_scl = pyAether.emyScalarName(self.namespace, cell) view_scl = pyAether.emyScalarName(self.namespace, view) reserved_view = pyAether.emyReservedViewType(view_type) view_type = pyAether.emyViewType.get(reserved_view) design = pyAether.emyDesign.open(lib_scl, cell_scl, view_scl, view_type, mode) return design def create_inst(self, master_lib, master_cell, master_view, inst_name, point, params, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarInst object on specified block. Parameters ---------- master_lib : str Library name of instance. master_cell : str Cell name of instance. master_view : str View name of instance. inst_name : str Text string of instance. point : tuple Point to create an emyTransform object, such as (0, 0). params: emyParamArray emyParamArray kwargs Other keyword arguments, here specifies view_type, mode, view, status. \u0026#34;\u0026#34;\u0026#34; view_type = kwargs.get(\u0026#34;view_type\u0026#34;, \u0026#34;maskLayout\u0026#34;) mode = kwargs.get(\u0026#34;mode\u0026#34;, \u0026#34;r\u0026#34;) view = kwargs.get(\u0026#34;view\u0026#34;, pyAether.emcInheritFromTopBlock) status = kwargs.get(\u0026#34;status\u0026#34;, pyAether.emcNonePlacementStatus) master = self.open_design(master_lib, master_cell, master_view, view_type, mode) inst_scl_name = pyAether.emyScalarName(self.namespace, inst_name) pnt_x0, pnt_y0 = point point_1 = pyAether.emyPoint(int(pnt_x0 * self.uu2dbu), int(pnt_y0 * self.uu2dbu)) trans = pyAether.emyTransform(point_1) pyAether.emyScalarInst.create(self.block, master, inst_scl_name, trans, params, view, status) def create_net(self, net_name, path, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- net_name : str It specifies the net name string. path : list It specifies path list. kwargs Other keyword arguments, here specifies sigType, isGlobal, view. Returns ------- scl_net : emyScalarNet An emyScalarNet object created by given parameters. \u0026#34;\u0026#34;\u0026#34; sig_type = kwargs.get(\u0026#34;sigType\u0026#34;, pyAether.emySigType(pyAether.emcSignalSigType)) is_global = kwargs.get(\u0026#34;isGlobal\u0026#34;, False) view = kwargs.get( \u0026#34;view\u0026#34;, pyAether.emyBlockDomainVisibility(pyAether.emcInheritFromTopBlock)) net = pyAether.emyScalarName(self.namespace, net_name) scl_net = pyAether.emyScalarNet.create(self.block, net, sig_type, is_global, view) path.addToNet(scl_net) return scl_net def create_path(self, layer, purpose, width, start_point, end_point): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- layer : str It specifies the layer name string. purpose : str It specifies the purpose name string. width : float Define the width of the path. start_point : tuple Path start point, such as (0, 0). end_point : tuple Path end point, such as (1, 1). Returns ------- path : emyPath A path object created by given parameters. \u0026#34;\u0026#34;\u0026#34; (sta_x0, sta_y0), (end_x0, end_y0) = start_point, end_point sta_pnt = pyAether.emyPoint( int(self.pnt_x * self.uu2dbu) + int(sta_x0 * self.uu2dbu), int(self.pnt_y * self.uu2dbu) + int(sta_y0 * self.uu2dbu)) end_pnt = pyAether.emyPoint( int(self.pnt_x * self.uu2dbu) + int(end_x0 * self.uu2dbu), int(self.pnt_y * self.uu2dbu) + int(end_y0 * self.uu2dbu)) points = [sta_pnt, end_pnt] layernum = pyAether.emyGetLayerNumByName(self.design, layer) purposenum = pyAether.emyGetPurposeNumByName(self.design, purpose) wid = int(width * self.uu2dbu) path = pyAether.emyPath.create(self.block, layernum, purposenum, wid, points) return path def create_gr(self, centerLine, templateName, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- centerLine : emyPointArrayF Set the drawing route of the guard ring. templateName : str Set the template name of the guard ring. kwargs Other keyword arguments, here specifies type, justify, offset, topLayer, stackMode, maxContPattern, isBodyMode, bodyWidth, contRow, contSpaceX, contSpaceY, contSizeX, contSizeY, bIsChamfer, chamferAmount, metalSameBody, stackSameMetal, cornerContact. Returns ------- rect_nwgr : emyRect Build nwGuardRings. \u0026#34;\u0026#34;\u0026#34; type = kwargs.get(\u0026#34;type\u0026#34;, \u0026#34;Polygon\u0026#34;) justify = kwargs.get(\u0026#34;justify\u0026#34;, \u0026#34;Center\u0026#34;) offset = kwargs.get(\u0026#34;offset\u0026#34;, 0) topLayer = kwargs.get(\u0026#34;topLayer\u0026#34;, None) stackMode = kwargs.get(\u0026#34;stackMode\u0026#34;, False) maxContPattern = kwargs.get(\u0026#34;maxContPattern\u0026#34;, False) isBodyMode = kwargs.get(\u0026#34;isBodyMode\u0026#34;, True) bodyWidth = kwargs.get(\u0026#34;bodyWidth\u0026#34;, 0.5) contRow = kwargs.get(\u0026#34;contRow\u0026#34;, 0) contSpaceX = kwargs.get(\u0026#34;contSpaceX\u0026#34;, 0) contSpaceY = kwargs.get(\u0026#34;contSpaceY\u0026#34;, 0) contSizeX = kwargs.get(\u0026#34;contSizeX\u0026#34;, 0) contSizeY = kwargs.get(\u0026#34;contSizeY\u0026#34;, 0) bIsChamfer = kwargs.get(\u0026#34;bIsChamfer\u0026#34;, False) chamferAmount = kwargs.get(\u0026#34;chamferAmount \u0026#34;, 0) metalSameBody = kwargs.get(\u0026#34;metalSameBody\u0026#34;, False) stackSameMetal = kwargs.get(\u0026#34;stackSameMetal\u0026#34;, False) cornerContact = kwargs.get(\u0026#34;cornerContact\u0026#34;, True) pyAether.aeCrtGuardring(self.design, centerLine, templateName, type=type, justify=justify, offset=offset, stackMode=stackMode, maxContPattern=maxContPattern, isBodyMode=isBodyMode, contRow=contRow, contSpaceX=contSpaceX, topLayer=topLayer, contSpaceY=contSpaceY, contSizeX=contSizeX, contSizeY=contSizeY, bIsChamfer=bIsChamfer, chamferAmount=chamferAmount, metalSameBody=metalSameBody, stackSameMetal=stackSameMetal, cornerContact=cornerContact, bodyWidth=bodyWidth) def close(self): r\u0026#34;\u0026#34;\u0026#34;This function save and close the emyDesign object which is opened. \u0026#34;\u0026#34;\u0026#34; self.design.save() self.design.close() def create(self, x_0, y_0): r\u0026#34;\u0026#34;\u0026#34;This function creates an inverter. \u0026#34;\u0026#34;\u0026#34; self.pnt_x = x_0 self.pnt_y = y_0 # Create scalar instances params_p18 = pyAether.emyParamArray() params_p18.append(pyAether.emyParam(\u0026#39;Single_Width\u0026#39;, \u0026#39;1u\u0026#39;)) self.create_inst(\u0026#34;reference_pdk\u0026#34;, \u0026#34;p18\u0026#34;, \u0026#34;layout\u0026#34;, \u0026#34;M0\u0026#34;, (0.43, 3.15), params_p18) # pyAether.emyArray() params_n18 = pyAether.emyParamArray() params_n18.append(pyAether.emyParam(\u0026#39;Single_Width\u0026#39;, \u0026#39;600n\u0026#39;)) params_n18.append(pyAether.emyParam(\u0026#39;SD_Metal_Width\u0026#39;, \u0026#39;370n\u0026#39;)) self.create_inst(\u0026#34;reference_pdk\u0026#34;, \u0026#34;n18\u0026#34;, \u0026#34;layout\u0026#34;, \u0026#34;M1\u0026#34;, (0.29, 1.17), params_n18) # Create path path1 = self.create_path(\u0026#34;GT\u0026#34;, \u0026#34;drawing\u0026#34;, 0.18, (1.0, 3.15), (1.0, 1.77)) path2 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (1.36, 3.47), (1.36, 1.21)) path3 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (0.64, 1.21), (0.64, 0.18)) path4 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (0.64, 4.11), (0.64, 5.14)) # Create net self.create_net(\u0026#34;Y\u0026#34;, path1) self.create_net(\u0026#34;A\u0026#34;, path2) self.create_net(\u0026#34;vss\u0026#34;, path3) self.create_net(\u0026#34;vdd\u0026#34;, path4) # create GR self.create_gr([(0.53, 4.89), (1.47, 4.89)], \u0026#34;NWGR\u0026#34;, bodyWidth=0.4) # create PGR self.create_gr([(0.52, 0.41), (1.48, 0.41)], \u0026#34;PGR\u0026#34;, bodyWidth=0.4) if __name__ == \u0026#39;__main__\u0026#39;: example = InvLe(\u0026#34;lib01\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;reference_pdk\u0026#34;, \u0026#34;layout\u0026#34;, mode=\u0026#34;w\u0026#34;) example.create(0, 0) example.close() 概伦电子 # 收购了Entasys\n鸿芯微纳 # 华芯巨数 # 浙江\n嘉立创 # PCB\n相关竞赛 # CADathlon@ICCAD # CADathlon@ICCAD 2024 | ICCAD 2024\nEDA领域的**“奥林匹克运动会”，始于2002年** in-person event, all-day programming competition, 9 hours, two-person teams, information about the problems and relevant research papers will be released online one week before the competition. 一般在10月份举办 six problems Circuit Design \u0026amp; Analysis Physical Design \u0026amp; Design for Manufacturability Logic \u0026amp; High-Level Synthesis System Design \u0026amp; Analysis Functional Verification \u0026amp; Testing Future technologies (Bio-EDA, Security, AI, etc.) Contest@ISPD # International Symposium on Physical Design (ISPD)\n于2005年首次举办 Contest@ISPD作为ISPD研讨会的一部分，是全球三大顶尖国际物理设计学术竞赛之一，由全球研究计算机科学的权威学会ACM（Association for Computing Machinery）所举办 每年12月份由业界一流公司（IBM、Intel、Xilinx等）公布学术竞赛题目，3月份提交研发成果和软件系统，由业界公司负责提供测试电路，并测试参赛队伍所提交的软件系统，最后于3月底或4月初在年度ACM ISPD会议上公布竞赛结果。 题目 First Place 2015 Blockage-Aware Detailed Routing-Driven Placement Contest NTUPlacerDR CAD Contest@ICCAD # 始于 2012年 覆盖了EDA前端（front-end）和后端（back-end） 由IEEE CEDA、ACM SIGDA和工业界Cadence、Synopsys等共同赞助 Each year the organizing committee announce three challenging problems in different topic, can participate in one or more problems Blockage-Aware Detailed Routing-Driven Placement Contest\n历年相关赛题 # 题目 Sponsor 2024-C Scalable Logic Gate Sizing Using ML Techniques and GPU Acceleration Nvidia 2011 Routability-driven Placement Contest and Benchmark Suite 侠客岛 # EDA精英挑战赛 # TAU Contest # Tau 2021 Contest\n数字电路时序分析竞赛（TAU） 始于2011年，是由国际计算机协会ACM所举办的专业赛事 一般由IBM、Cadence、Synopsys、TMSC等国际顶尖公司参与命题 好像到21年就没了。。。 Programming Contest@IWLS # IWLS Contest\n始于2017年 是由IEEE/ACM International Workshop on Logic \u0026amp; Synthesis（IWLS）举办 由业界一流公司（Synopsys、Xilinx、Google等）公布竞赛题目 以逻辑综合（Logic Synthesis）和工具研发为竞赛主题 “全国大学生集成电路创新创业大赛”的华大九天赛道 # 全国大学生集成电路创新创业大赛\n第八届集创赛杯赛题目——华大九天杯 - 全国大学生集成电路创新创业大赛\nLLM4HWDesign Contest # 2024年ICCAD新设立LLM for Hardware Design Contest\nLLM4HW Design竞赛旨在为硬件代码生成构建大规模、高质量的Verilog代码生成数据集。在基于LLM的硬件代码生成中引发一场类似ImageNet的革命。为了实现这一目标，LLM4HWDesign竞赛鼓励参与者收集数据样本，并开发创新的数据清理和标记技术，以有效提高硬件代码生成数据集的规模和质量，为推进LLM辅助硬件设计工作流程建立关键基础设施。\nDAC System Design Contest # DAC 2012 Routability-Driven Placement Contest and Benchmark Suite\n参考 # 盘点全球顶级EDA竞赛及中国大陆获奖情况|清华大学|福州大学|iccad|上海交通大学|eda_网易订阅 相关PDK # "},{"id":5,"href":"/zh/docs/Digtal/flow/flow/","title":"Flow","section":"Physical Design","content":" AI 4 Science # 数字集成电路后端设计整体流程 # 在完成前端设计、逻辑综合和时序分析后，后端设计阶段开始\n（1）布局规划（Floorplan）： 在布局规划阶段，设计团队确定芯片的大致布局，包括模块位置、互连和电源网络的布局。这个阶段的主要目标是确保设计满足所有功能需求和制造约束，同时优化芯片的性能和成本。\n（2）宏块和标准单元布局（Placement）： 此阶段中，具体摆放包括宏模块和标准单元。算法将尝试在保持功能和电气性能的前提下，最小化连线长度和延迟，优化布局密度。\n（3）时钟树合成（Clock Tree Synthesis，CTS）： 布局完成后，进行时钟树合成。CTS 的目的是构建一个时钟网络，以最小化芯片上不同部分之间的时钟偏差，并确保整个芯片的同步运行。\n（4）布线（Routing）： 在 CTS 之后，进行布线阶段，此阶段建立电子连接，以实现设计中的所有逻辑互联。布线需要解决路径规划和信号完整性问题，确保信号在整个芯片上无干扰地传递。\n（5）验证和测评： 最后，进行布局与布线后的验证工作，包括电路验证、时序分析和功耗分析等。\nFloorplanning（布图) # 确定核心和外围区域：定义芯片的核心逻辑区和外围接口区。 核心区域：这是用于放置 逻辑门、触发器等基础元件的区域。 外围区域：这里通常用于放置 I/O pads，电源和地引脚。 确定 IP Blocks 的位置：IP（Intellectual Property）模块的大致位置和尺寸。 硬宏（Hard Macros）：例如存储器、 模数转换器（ADCs）等，通常有固定的大小和形状。 软宏（Soft Macros）：通常是可以重新合成的逻辑模块，如处理器核心、 DSP 单元 等。 初步 Power Planning：设计初步的电源网格和地网。 电源网格设计：创建电源和地网格来提供电流和参考电压。 电源环（Power Rings）：在芯片外围设计电源环，用于电源和地的分发。 电源铺垫（Power Pads）：确定用于外部电源连接的电源和地铺垫的位置。 I/O Planning：规划输入/输出引脚的位置。 引脚位置：根据接口要求（如 GPIO、DDR 接口等）确定 I/O 引脚的位置。 引脚电特性：确定每个 I/O 引脚的电性能需求，如驱动能力、接受阈值等。 设置约束：设置时序、面积和功耗的约束。（各种 view, block) 时序约束：定义时钟域、时钟频率和时序要求。 面积约束：如果有面积限制，需要明确这一点。 功耗约束：设定功耗上限或优化目标。 Placement（布局） # 设计的所有逻辑元件（例如标准单元、触发器、门等）和预定义的 IP 块（例如硬宏）被物理地放置在芯片的核心区域内\n全局布局：进行粗略的布局优化。 草图生成：使用不同的算法（例如 模拟退火、 遗传算法 等）来生成一个初步的元件布局草图。（不会对准 row) 优化目标：主要考虑的是最小化布线长度、改善功耗和满足时序约束。 详细布局：进一步优化每个标准单元和宏单元的位置。 局部优化：在全局布局的基础上进行更细致的调整。 对齐和间距检查：确保所有元件都符合工艺规则，包括对齐、间距和其他布局规则。 优化：针对时序、功耗等进行局部优化。 Timing Driven Placement：根据时序需求进行局部或全局优化。 功耗优化：通过智能地布局来减少功耗（例如，通过聚集功耗高的单元）。 Power Planning：尽管大部分电源规划可能已在 Floorplanning 阶段完成，但在 Placement 阶段也可能需要进行一些细致的调整。例如，为了满足特定模块或逻辑块的电流需求，可能需要添加额外的电源或地连接。 验证 设计规则检查（DRC）：确保布局满足所有工艺和设计规则。 电气规则检查（ERC）：确保布局不会导致电气问题（例如，电流密度过高）。 Clock Tree Synthesis (CTS)（ 时钟树 综合） # 主要目的是生成一个有效的时钟分布网络。这个网络负责将时钟信号从一个或多个时钟源（Clock Source）传送到芯片内所有需要时钟的元件（如触发器和存储器元件）。在这一过程中，设计师需要权衡多个因素，包括但不限于时序、功耗、面积和可靠性\n创建时钟树：构建用于分发时钟信号的时钟树。 时钟缓冲：添加缓冲器来减少时钟偏斜。 优化：优化时钟树以满足时序和功耗需求。 Routing（布线） # 实现逻辑元件之间的物理连接\n全局布线：确定大致的连线路径。 路径规划：在这一步骤中，算法会大致规划出每一条互联线（net）应该走的路径。主要目标是规划逻辑元素（或电路网）之间的连接路径。这通常在一个 高级的抽象层面 上进行，一般不考虑过于详细的设计规则，比如具体的线宽和距离。 资源分配：为了确保所有的互联线都能被合适地布置，需要进行资源分配。 路径搜索：使用各种搜索算法（如 A*、Maze Routing 等）为每个网络找到一条或多条全局路径。 资源分配：在布线网格上为每条路径分配必要的资源，如布线轨和过孔。 处理冲突：当两个或更多的路径有冲突时（如共用相同的网格或资源），进行调整以解决冲突。 Skew 和延迟优化：对关键网络（如时钟网络）进行特殊处理，以最小化 skew 和信号延迟。 详细布线：在全局布线指导下，进行精确的连线。 实际布线：依据全局布线的结果，进行实际的布线操作。 处理冲突和过载：如果在布线过程中出现资源冲突或过载，需要进行相应的调整。 修复布线冲突：解决任何布线冲突或溢出。 生成最终的布线文件：这通常是一个包含所有物理信息的 GDSII 文件或其他类似格式的文件。 Physical Verification（物理验证） # 负责确保设计满足所有工艺和功能规格\nDRC（Design Rule Check）：使用工艺规则文件来验证设计，确保没有违反任何制程规则。\nLVS（Layout vs. Schematic）：确保物理布局与逻辑原理图一致。\nERC（Electrical Rule Check）：检查电流路径、电源连通性等。\n天线效应 检查：运用专用的检查工具来识别和解决可能的天线效应。\n抗辐射和电磁兼容（EMC）验证\n抗静电放电（ESD）和抗热设计\n时序验证(STA)\nRC 提取和 信号完整性分析\n尺寸和密度检查\nSign-off Checks # 它标志着设计即将完成，并准备进入制造阶段。在这个阶段，设计需要经过一系列严格的验证和审查，以确保其满足所有工艺、性能和功能规格\n时序 Sign-off：使用工艺库的最终版本和高精度模型来执行最终的时序分析。 静态时序分析（STA）：使用工艺最差条件（PVT，Process-Voltage-Temperature）进行时序验证。 动态时序分析：仿真整个时钟树和关键数据路径，以确认时序要求得到满足。 功耗 Sign-off：进行全芯片级的功耗 EDA 软件研发难点 # 参考 # 数字后端整体流程（Physical Design） - 知乎 EDA 重要性 # EDA 发展历史 # 中国大陆 # 由于1994年至2008年，中国大陆在EDA领域有差不多十五年的低迷期。很多高校失去了EDA的研究条件和生存环境，使得很多项目搞不下去，老师开始转型，导致高校从事EDA研究的人员越来越少。\n参考 # 超大规模集成电路物理设计-从图分割到时序收敛：第一章 # AI4EDA # 传统 EDA 缺点 # (1) 它依赖于硬件设计人员的专业知识来选择合适的 EDA 工具配置，(2) RTL 的设计空间探索，逻辑综合和物理综合是手动的，因此是有限且耗时的，(3) 设计中的更正将重新初始化流程，(4) 没有早期分析或结果的可预测性。\nGNN # 近年来，随着深度学习技术的广泛应用，越来越多的研究将其引入EDA领域。特别是图神经网络（Graph Neural Networks, GNN），凭借其在处理复杂图结构数据方面的显著优势，逐渐成为EDA后端设计中物理验证的重要工具。–cite–\u0026gt; 专题解读 | GNN在EDA后端设计物理验证环节中验证应力的应用\n由于考虑了特征和拓扑信息，GNN 已被证明优于其他 ML 模型\n[41] 中的研究 首次认识到 GNN 在 EDA 中的巨大潜力。他们表示，图形结构是表示布尔函数、网表和布局的最直观方式，这些是 EDA 流程的主要关注点。他们 将 GNN 视为 EDA 改进 QoR 并取代使用的传统浅层方法或数学优化技术的机会。\n基于 GNN 的架构优于其他模型和解决方案。上面列出的工作将他们的结果与浅层 ML、深度学习方法或特定任务的基线进行了比较。毫无疑问，GNN 的优越性是由于对拓扑和特征信息的考虑，这是以构建训练数据集的更大努力和更高的训练时间为代价的\nGNN 的优势与两个因素有关：定义明确的初始特征和图学习能力 [39]。定义明确的特征捕捉任务的基本特征，并为图学习提供宝贵的信息。 GNN 捕获特征和拓扑信息。 这与仅考虑图形连通性的方法相比，它具有明显的优势。\nG =(V, E) 分别不同的任务\n是否有向\n是否有环\n是否异构\n是否动态\n其他特殊图：二分图，正交图，超图\nrelate work 素材 # RL # 市场 # 三巨头： # 新思科技（Synopsys）：成立于 1986 年，是全球排名第一的电子设计自动化解决方案提供商，提供从设计到制造的全流程 EDA 工具，包括逻辑综合、时序分析、验证等。最大，还有 ip 楷登电子（Cadence Design Systems）：由 SDA Systems 和 ECAD 两家公司于 1988 年合并而成，提供广泛的 EDA 工具，包括模拟及数字集成电路设计和验证工具。 西门子 EDA（Siemens EDA）：前身是 Mentor Graphics，成立于 1981 年，2016 年被 西门子收购。Siemens EDA 提供全面的 EDA 软件、硬件及服务，包括 FPGA 设计、PCB 设计和 IC 设计工具、、、、、、、、、、、、、、、、、、、、、、 历史 # EDA 流程 # 数字前端 # 逻辑综合 将 HDL 中的 RTL 块映射到从 给定技术库 中选择的 门组合，同时针对不同目标优化设计。通常，这种优化涉及 时序收敛、面积和功耗之间的权衡。\n无需进行逻辑综合, 通过 RTL 预测 PPA # 精确时序或逻辑估计 [83]、[84]。\n功耗\n来识别与功耗相关的 RTL 信号。 Simmani [92] 和早期的功耗 建模工作 [93] 专注于 FPGA 和其他平台上的快速功耗 仿真，强调了 ML 方法的更广泛适用性，有助于在设 计阶段进行高效功耗分析。\nRTL 测试和验证领域：过学习 RTL 设计的语义抽象、促进功能预测和有效的测试生 成（显着缩短验证周期）\n数字后端 # Floorplanning Floorplan initialization - define the chip area, utilization IO pin placement (for designs without pads) Tap cell and well tie insertion PDN- power distribution network creation Global Placement Macro placement (RAMs, embedded macros) Standard cell placement Automatic placement optimization and repair for max slew, max capacitance, and max fanout violations and long wires Detailed Placement Legalize placement - align to grid, adhere to design rules Incremental timing analysis for early estimates Clock Tree Synthesis Insert buffers and resize for high fanout nets Optimize setup/hold timing Global Routing Antenna repair Create routing guides Detailed Routing Legalize routes, DRC-correct routing to meet timing, power constraints sign off Parasitic extraction using OpenRCX Final timing verification Final physical verification Dummy metal fill for manufacturability Use KLayout or Magic using generated GDS for DRC signoff 网表 # AI for Datapath Circuits：优化电路网表结构？加法器乘法器等\n[DRiLLS-Synthesis optimization(min area)-DAC-2020-RL(A2C)-](DRiLLS-Synthesis optimization(min area)-DAC-2020-RL(A2C)-.pdf)\n与仿真器互动 布图 floorplanning # 较大块被放置在二维网格上，以实现 最佳 PPA，同时 遵守设计规则。这可以表示为 马尔可夫过程，可以使用 RL 来解决。\nGoogle 展示了使用 DRL 框架对张量处理单元 (TPU) 加速器进行局部规划的成功芯片宏放置。在 [44] 中，将 GNN 合并到 RL 框架中以对过程的不同状态进行编码，预测拥塞、密度和线路长度的奖励标签，并推广到未见的网表。所提出的架构称为基于边缘的图神经网络（Edge-GNN）[44]，它计算整个网表的节点和边缘嵌入。此 RL 代理提供与人类设计师相当或更好的结果，但需要数小时而不是数月。\n布局 # 人工智能在标准单元设计中的应用，特别是布局和布线，由于其高密度和严格的可布线性要求，带来了一 系列独特的挑战。利用强化学习的人工智能辅助方法 已被证明可以改善布局顺序和可布线性，从而提供更 好的线长性能 [188]。\n任务：致力于确定单元内最佳晶体管位置\nglobal placement\ninvolves macro placement and standard cell placement, most crucial but timeconsuming steps in the chip design process, which can be cast as a constrained optimization problem. Detailed placement\nincludes legalization, wirelength and routability refinement Solution from global placement is often illegal: cells may overlap or occupy illegal sites, e.g. between placement rows. This is because global placers are unaware of these constraints. snaps standard cell to the sites of rows with minimum adverse impact on placement quality. 方向\nTraditional Placers Enhancement\nPL-GNN [Ward et al., 2012]\n结合了支持向量机（SVM）和神经网络来进行数据路径提取和评估，促进数据路径感知的放置策略。\nPL-GNN [Lu et al., 2021]\n种基于图学习的框架，该框架通过基于逻辑亲和性信息和设计实例的属性生成单元簇来为商业布局器提供布局指导\nDREAMPlace [Lin et al., 2020] 基于最先进的分析放置算法 RePlAce，DREAMPlace 通过深度学习工具包 PyTorch 实现手动优化的关键运算符，并比基于 CPU 的工具实现了超过 30 倍的加速\nPlacement Decision Making\nGoogle [Mirhoseini et al., 2021] nature.\nproposes an end-to-end learning method for macro placement that models chip placement as a sequential decision making problem. In each step, the RL agent places one macro and target metrics are used as reward until the last action.\nGNN is adopted in the value network to encode the netlist information and deconvolution layers in the policy network output the mask of current macro position.\nDeepPlace [Cheng and Yan, 2021]\nfor the placement of macros and standard cells RL + GNN + CNN base a gradient-based classical cell placer ([Lin et al., 2020]) Prediction Model Embedded in Placement\nML also assists placers to optimize complicated objectives like routability by embedding prediction models, as it is difficult to foresee routing congestion accurately during placement\nIEEE Xplore Full-Text PDF:\nbuilt to predict #DRVs at the macro placement stage without cell placement and routing information macro placer : 此外，模拟退火优化用于搜索具有预期最少 DRV 的最优宏布局 cnn [Chan et al., 2017]\n(1) machine-learning techniques to effectively predict detailed-route DRC violations after global routing and\n(2) detailed placement techniques to effectively reduce detailed-route DRC violations.\n[Liu et al., 2021b]\npredicts congestion hotspots and then incorporates this prediction model into a placement engine,\nRL\n许多研究探索了早期可路由性预测。 RouteNet [114] 使用 CNN 来预测路由设计后规则违 规 (DRV)，从而避免难以路由的布局。\n称为 Net 的 GAT 用于在 [61] 布局前中 估计路径长度。为此，他们 将网表转换为有向图，其中网络代表节点，边在两个方向上连接网络。单元数、扇入、扇出大小和面积用作特征节点。使用聚类和分区结果定义边缘特征。\nneurips21-1.pdf 全流程参数优化\u0026amp; VLSI Placement Parameter Optimization using Deep Reinforcement Learning (acm.org) 为了实现 PPA（性能、功耗、面积）目标，人类工程师通常需要花费大量时间调整商业放置工具的多个设置（maximum density, congestion effort, etc.）。本文提出了一个深度强化学习（RL）框架，用于优化商业 EDA 工具的放置参数。GCN（GraphSAGE） 是一个关键组件，因为它提取 RL 代理所需的本地和全局信息\n常见解决算法：动态规划，强化学习，满足性模型理论\n布线 # 任务：完成 cell 之间的连线。按照设计规则（例如允许角度的类型）连接放置的组件、门和时钟信号\nglobal routing\ndetail routing\nconsidering complicated design rules 详细布线还需要考虑优选布线方向，其中相邻布线层优选垂直布线方向。遵循其相应层的首选方向（例如，X 或 Y 方向）的连续网格边缘被描述为布线轨道 方向\nLearning-aided Routability Prediction 常用方法：A-star、整数线性规划和可满足性模理论\nDRC 检查：RL 方法，，简化了路由过程并支持使用 A 星或迷宫路由来获得最佳解决方案。机器学习技术 还促进了 DRC 规则的适应，简化了标准单元布局跨技 术节点的迁移 [190]\nCongestionNet 使用多层 GAT, 特征节点是 50 维向量，包含有关 单元类型、大小、引脚数和逻辑描述 的信息, 拥塞图被分成网格，每个网格的拥塞值被作为放置在该网格中的单元格的标签。对于超过 100 万个单元的电路，推理时间约为 19 秒\nhttps://ieeexplore.ieee.org/document/9643435/：GNN+LSTM, 预测端口路由 TNS, 利用 gnn 获得 embedding，用 place, opt.place, opt.cts 后的图分别预测电路 TNS 值，各自的 TNS 预测再构建一个 LSTM 网络，用于预测最后的 routing 后的 TNS 值，\n每个节点的特征都与任务相关，例如单元的最差松弛、最差的输出和输入压摆以及驱动网络的开关功率。这些是从技术库中收集并生成的报告。每个阶段的网表由全局 GNN 编码。在这三个阶段中的每一个阶段，图嵌入的使用都是双重的：它们是预测模型和 LSTM 的输入，其中图嵌入用作时间序列。单一预测模型预测每个阶段的 TNS，而 LSTM 将综合低点映射到连续低点。每阶段预测平均实现小于 12.6% 的归一化均方根误差，而基于 GNN 的 LSTM 预测在两个测试电路中实现小于 5.2%\n验证 # timing, power, drc\n逆向工程 # ReIGNN [107] 和 GNN-RE [108] 等工具利用 ML 来执行逆向工程任务，例如识 别状态寄存器和破译子电路的功能。\n模拟 # 模拟设计流程 的高复杂度是由于 大的设计空间和信号敏感性 w.r.t.噪音。因此，模拟流程可以从 ML 等现代方法中受益匪浅，从而使方法现代化并提高 QoR。\n拓扑生成 # Sizing(调整长宽比 ) # CircuitGNN # AutoCkt : Deep Reinforcement Learning of Analog Circuit Designs (DATE,2020）\nGCN-RL Circuit Designer: Transferable Transistor Sizing with Graph Neural Networks and Reinforcement Learning (DAC, 2020)\nCktGNN : Circuit Graph Neural Network for Electronic Design Automation (ICLR, 2023)\nDNN- Opt : An RL Inspired Optimization for Analog Circuit Sizing using Deep Neural Networks (DAC, 2021)\nAnalog Layout Automation：版图大小，DRC 预测 [208]，布局 [212]，路由 [210]， # 预测寄生参数：[217]，ParaGraph [46] ， [35] # LLM 大语言模型 # 将生成式人工智能（特别是大型语言模型 (LLM)）集成 到 IC 设计中正在成为一种变革趋势。通过利用专有数 据集，IC 设计公司可以开发人工智能助手来增强和加快 设计过程。这些工具能够提供深入的见解，自动执行和 完善传统的手动任务\n相关数据集：\n生成 RTL # 功能验证 # LLM 通过将自然语言规范转换为 SystemVerilog 断言 (SVA)，在功能验证方面取得了重大进展。此过程 确保 RTL 实现遵循他们的预期规格。\nLLM 在解决布尔可满足性 （SAT）问题 [179] 方面取得了成功，可应用于验证算 术电路。\nSecurity Verification: 使用 LLM 指出 RTL 的安全漏洞，基于 ChatGPT 推荐安全 RTL 代码 [181] 和相关的断言 [182]\n脚本生成和架构设计 # TCL 脚本生成: ChatEDA [183] 引入了基于 LLM 的代理，旨 在促进使用自然语言进行 EDA 工具控制，提供了一种 替代方案传统 TCL 脚本。\nGPT4AIGChip [184] 利用 LLMs 生成 AI 加速器高级合成的 C 代码。\n同样，Yan 等人 [185] 研究了 llm 在优化 内存计算(CIM) DNN 加速器中的使用，展示了该模型在提高计算效率方面的潜力\n[186] 深入研 究量子架构设计，探索量子计算的前沿。\n模拟 # 参考 # 浅谈大语言模型与 EDA\nLLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation\nLCM # EDA 工作流程从最初的规格延伸到详细的最终布局， 涵盖各种电路设计格式，每种格式都需要 LCM 内的 不同编码器。这些编码器旨在处理特定模式（规范、 架构设计、高级算法、RTL 设计、电路网表和物理布 局），是 LCM 的核心组件。\n虽然这些模型已经在基准数据集上 证明了有效性，但它们推广到新颖设计的能力仍然是 一个令人担忧的问题。\n电路数据固有的计算和结构的 独特融合需要超越通用人工智能解决方案能力的细致 入微的理解。例如，在不深入理解电路设计细微差别 的情况下将 LLM 应用于 RTL 生成通常无法实现最佳 PPA 结果。\n大型基础模型（如 BERT [2]、GPT [5] 和 MAE [8]）的出现，已经重新定义了人工智能的格 局，提供了一种分叉的方法，对不同的数据进行广泛 的预训练，然后针对特定任务进行有针对性的微调。 这种方法有助于实现各种数据类型的突破，预示着人 工智能应用的新时代。\n通过支 持 LCM，我们站在 EDA 革命的风口浪尖，超越特定 于任务的限制，拥抱人工智能原生解决方案推动电路 设计创新、效率和卓越的未来\n对齐挑战\n鉴于 LCM 依赖于广泛、高质量的训练数据集，数据 稀缺成为一个关键障碍\n团队 # 北大 CECA\n上交\n香港中文\n复旦\n华为诺亚方舟实验室，华为海思\n参考 # 2403.07257] The Dawn of AI-Native EDA: Opportunities and Challenges of Large Circuit Models (arxiv.org)\nA Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN\n书： Machine Learning Applications in Electronic Design Automation | SpringerLink\ninnovus # flow # floorplan # 考虑因素 # 封装形式 面积、绕通性、电源完整性、时序性能、功耗 Hard IP 使用需求 基础概念 # Box # Die Box: 整个芯片区域\nCore Box: 标准单元和 IP 摆放单元\nIO Box: IO 单元摆放区域(红色与黄色之间)\nCore2IO Box: 隔离距离，电压隔离，ESD 保护，Core 电源环创建（绿色红色之间）\nsite, row, # Site(最小布局单位) # SITE 的类别通常分为 core 和 pad，分别对应着 std cell 的 row 和 io cell 的 row。 SITE 的方向通常有 X，Y，R90 三个参数。X 代表可以沿 X 轴翻转，Y 代表可以沿 Y 轴翻转，R90 代表可以任意翻转。 SIZE 定义了 site 的宽度，通常 std cell 都是 site 的整数倍高度，宽度 Row(Standard/l0 cell 摆放位置) # 整数倍 Site Row 也有自己的方向，如上图箭头所示，通常相邻的 row 会 abut 且 flip，这样相邻 site 可以 共用一根电源线，节省 Power 资源。 Row Cut 问题 非整数倍 Row 低功耗设计 所有 std cell 都必须 snap 到 row 上面，这是最基本的 place 规则 默认的 std cell 摆放方向遵从 Row 的方向，即方向箭头一致，但是根据 cell 本身的 symmetry，std cell 的摆放位置也可以有如上图所示的选择 实际 design 中，我们还能经常见到一些其他种类的 row。常见的有 double height，trible height 的 row，用来摆放两倍高，三倍高的 cell。 一般我们只允许创建整数倍高的 row，而在 Voltage island 中，我们允许创建非整数倍高的 Row，比如默认电压区域用的是 9T 单元，而在 Voltage island 中我们使用了 12T 的 cell，这时候就需要创建非整数倍高度的 row EndCap, WellTap, Decap # 在后端物理设计中，除了与，非，或等一些常见的标准单元外，还有一些特殊的物理单元(physical cell)，它们通常 没有逻辑电路，不存在与 netlist 当中，但是对整个芯片的运行，稳定却起着举足轻重的作用。\nEndCap # 也叫 boundary cell， 拐角单元 是一种特殊的标准单元。 作用是确保每个 nwell 都是 nwell enclosed，类似一个封闭环。主要加在 row 的结尾(两边都要加)，以及 memory 或者其他 block 的周围包边 WellTap # welltap 是只包含 well contact 的 cell，将衬底接到电源和地网络，避免衬底悬浮。主要防止 CMOS 器件的寄生闩锁效应(latch-up)\n一般 tap cell 的作用范围是 30~40um, 即每隔 60um 左右放置一个 tap cell，具体的数据要参考艺商给的 document\nwell tap cell 一般交错摆放，类似棋盘分布。 Decap # Decap cell，去耦单元，这是一种特殊的 Filler cell。 当电路中大量单元同时翻转时会导致冲放电瞬间电流增大，使得电路 动态供电电压下降 或地线电压升高，引起动态电压降俗称 IR-drop。为了避免 IR-drop 对电路性能的影响，通常在电源和地线之间放置 由 MOS 管构成的电容，这种电容被称为去耦电容或者去耦单元，它的作用是在瞬态电流增大，电压下降时向电路补充电流以保持电源和地线之间的电压稳定，防止电源线的电压降和地线电压的升高。 Filler # 缓解 dynamic IR drop, eco\n通常是单元库中与逻辑无关的填充物\n可以分为 I/O filler(pad filler)以及普通的 standard cell filler.\npad filer，通常是用来填充 I/O 单元与 I/O 单元之间的空隙。为了更好的完成 power ring，也就是 ESD 之间的电源连接。通常是在 Floorplan 阶段时添加。\nstandard cell filler, 也是为了填充 std cell 之间的空隙。主要是为了满足 DRC 规则和设计需求，并形成 power rails。这个在 route 之前，之后加都可以。\nDecap cell，去耦单元，这是一种特殊的 Filler cell。\n当电路中大量单元同时翻转时会导致冲放电瞬间电流增大，使得电路 动态供电电压下降 或地线电压升高，引起动态电压降俗称 IR-drop。为了避免 IR-drop 对电路性能的影响，通常在电源和地线之间放置 由 MOS 管构成的电容，这种电容被称为去耦电容或者去耦单元，它的作用是在瞬态电流增大，电压下降时向电路补充电流以保持电源和地线之间的电压稳定，防止电源线的电压降和地线电压的升高。\n需要注意的是 Decap cell 是 带有 metal 层 的，为了不影响工具 routing resource，一般建议是最后 routing 全部结束后再加，加完之后再添加普通的不带 metal 的 filer.\nhard IP # hard IP 就是 macro\nmacro 有自己 单独的 lef 文件， 定义形状，pin 信息等等\nhard IP 一般有：SRAM/DDR/PLL/AD/DA\n常用原则\nMacro 一般摆放在芯片或模块(block)边缘 Macro 摆放时尽量缩短与其通信的 10 或 Macro 的距离 Macro 摆放时尽量缩短其 pins 与 standard cell 谡辑的距离 Macro 之间留够安全距离 重视 macro 之间的 channel，可以 abut 尽量 abut, channel 中在 place 时根据需求加入 soft blockage 标准单元区域尽量保持连续，不要产生小宽度的 channel; 长宽比接近 1 backbox # BlackBox 类似于一个 HardMacro，它内部的东西完全看不见，只是一个黑盒子，但是它又类似于一个 ModuleBoundary。它可以被改变形状，而且它可以被分配 pin 和被分割出去(partition)。如下图所示，灰色的形状就是 Black Box。\nBlackBox 是一种较为粗糙的模型，由于它看不见里面的东西，这样的结构使得它做任何 implementation 速度都很快，取而代之的精准度就会相对较低\ntrack, pitch # track # 走线轨道，信号线通常在 track 上 可以约束走线的方向 Std Cell 的高度通常用 metal2 track pitch 来表示，常用的 std cell 库有 7T/9T /12T，就是以 track 来区分的， 9T 就是说 std cell 的高度范围内可以走九条线，所以一般来讲， 7Tcell 的 size 最小， 9T cell 的 size 稍大。 布线时，往往第一层一般是水平，第二层垂直，相互交替 .lef 中定义如下，举例：\nLAYER M1 TYPE ROUTING ;#TYPE ROUTING代表这是一层走线层，我们还有其他的type包括Implant, Masterslice等. DIRECTION VERTICAL ; #DIRECTION代表这层Metal prefer走线方向，这边值得注意的是，每层track会分为pref track和non pref track。pref track就是这层layer上主流的走线方向，那剩下的non pref track就是非主流方向。因此上述例子中的主流走线方向就是vertical(纵向)，非主流就是横向(honrizontal)。通常。走non-pref track的wire会比较宽，这样就比较占用绕线资源。所以，一般不推荐使用non-pref track。特别是在先进工艺的设计中，绕线资源极其紧张，一般很少用到non-pref track. PITCH 0.090 0.064 #track之间的间距，垂直方向间距是0.09，水平方向是0.064. OFFSET 0.000 0.000 #第一条track偏离起始点的举例 MAXWIDTH 2; #WIDTH就代表默认这层layer上wire的宽度？MAXWIDTH就代表最高不能超过多少width WIDTH 0.032; Grid # Litho Grid，中文名，光刻格点。又被称为制造单元格点，这是 最基本的网格单元，任何元件都要对 Litho Grid 上，不然就无法被制造 它定义在 design 的 technology LEF. e.g.: MANUFACTURINGGRID 0.001;. 这就代表着改设计的制造单元格点间距为 0.001, 起始点是 Die Box 的 lower left 角上 Blockage, halo # Net, Wire # Net # 线网，也就是 Verilog 里的 wire(还有 tri、wor、trior、wand、triand、trireg、tri1、tri0、supply0、supply1) Wire\n后端工具中的 wire 指的是 net 的 物理化概念 每一条 net 在后端工具里面是由许多小段的 wire 组成，每一小段 wire 我们称之为 wire segment. wire 按照类型可以分为 Regular Wire(信号线)，Special Wire(电源线)，Patch Wire(补丁线)。 Regular Wire 就是我们平常见到的信号连线，连接各个 Siqnal Pin 的金属线段。每层金属层上的 Regular wire 默认的宽度都是一样的。 Special Wire 就是电源接地线，平常我们所见到的 power ring，stripes，power rail 等都是 Special Wire。一般用高层金属走线. Patch Wire，我们称之为补丁线。这是先进工艺中的一种走线，用于修复 Min Area，MinStep 等 DRC，不属于任何 net。 Pin # 引脚\n分为 Instance Pin, I/O Pin, Physical Pin, Partition Pin:\nInstance Pin: cell 的 pin\nI/O Pin: 模块输入输出，也叫 IO port\nPhysical Pin: Physical Pin 是 IO pin 具体物理化的信息，该引脚用于底层模块与上层模块拼接时的接口，类似一个纽扣一样，定义模块走线的起点和终点。它也是有具体的金属层参数信息，和普通 wire 一样。\nPartition Pin: 切分模块的引脚。用于在顶层模块未切分时，定义 physical pin 的位置，这个阶段的 physical pin，我们称之为 partition pin。和 Physical Pin 一样，他具有实际的金属层参数信息。\nplacement # 摆放标准单元，同时满足各种 constraint\n会删掉综合后加入的 buffer\n基础概念 # Tie High/Low\n电压转换\n尺寸越小越重要，静电\nGlobal/Detail Place\nDetail 是把 Global 后的单元放到网格上同时满足 constraint 要求\ndrv\nhvt 和 lvt\nHVT (High Voltage Threshold)：高电压阈值晶体管。这类单元库的特点是它们的阈值电压较高，因此它们在泄漏电流（leakage current）方面表现较好，也就是说 在静态功耗方面比较低。但是，它们的开关速度较慢，因此在性能（speed）方面不如低阈值电压的单元库。HVT 单元库通常用于对功耗要求较高的场合，但对性能要求不是非常高的地方。 LVT (Low Voltage Threshold)：低电压阈值晶体管。与 HVT 相反，LVT 单元库的阈值电压较低，这使得它们在开关速度上更快，因此性能较高。但是，这种速度的提升是以增加泄漏电流为代价的，也就是说它们的静态功耗较高。LVT 单元库通常用于对性能要求较高的设计中。 CTS # placement 后的 clock tree 是理想的（没有延时）\n主要的行为是插入 buffer/inverter\n希望到同一级（流水线的级？）的时钟 delay 是一致的\n如果有不同 clock，也要考虑 clock 之间的影响\ninnouvs 的 CTS 工具叫 ccopt\n评价指标：(latency (insertion delay), skew, clock power, clock em, long common path(cppr), duty cycle)\n基本概念 # route # 三个步骤：global route, track assignment（分配 global route 的 track 给对应的 net）, detail route\n基本知识 # nano # SI # Antenna # eco route # 工艺制造，栅极放电破坏\nsignoff 的时候会检查这个问题，工具会加上\n连接到栅极的面积不要太大\nsign off # 基本知识 # mode # function # 最常见 标准时序约束模式 Scan shift # 移位扫描模式 由于芯片内部是个黑盒子，在外部难以控制。我们将芯片中的所应用的普通寄存器替换成带有扫描功能的扫描寄存器，首尾相连成串，从而可以实现附加的测试功能，这就是 Scan chain 的概念。下图一就是扫描寄存器，下图二就是将扫描寄存器串起来的 Scan Chain Capture # 也叫 Stuck-at 模式 DC 模式：主要检查我们平时常见的 stuckat 0/1 错误。比如下图中的 inverter A 端如果被接到了 VSS 端的话，就是一个 stuck at 1 的 fault ASST # At Speed MBIST # Boundary Scan # common command # #gui innovus -no_gui win/win_off #gui 开关 win_off用不了？ #run innovus -init init.tcl source xxx.tcl dbGet top.insts.name selectInst xxx_insts_name dbGet selected.pgInstTerms.name #kill ps -ef | grep innovus killall -9 innovus 实战 c # 0_所需文件： # netlist\ntech_lef, cell_lef(standard cell, io, ip(ram))\npex_tech(best, worst, typ_qrcTechFile)\nmmmc.viewDefinition.tcl\nlibrary_set\nfast standard cell\u0026rsquo;s .lib, ip\u0026rsquo;s .lib slow standard cell\u0026rsquo;s .lib, ip\u0026rsquo;s .lib rc corner\nbest/worst qrcTechFile(unreadable) delay_corner\nconstraint_mode\nconfig sdc_file\nanalysis_view\n1_数据初始化 # 设置 netlist\ntech_lef，cell_lef\npex_tech\nset scenarios\nset cell type\n############################################################## # Common design settings # Created by Yanfuti ############################################################## ### design information set design \u0026#34;leon\u0026#34; ### design data directory set project_root \u0026#34;..\u0026#34; set library_root \u0026#34;~/BackEnd/innovus_learn/library\u0026#34; set reports_root \u0026#34;${project_root}/reports\u0026#34; ### gate level netlist files set import_netlists \u0026#34;\u0026#34; lappend import_netlists \u0026#34;${project_root}/netlist/post_syn_netlist/${design}.vnet.gz\u0026#34; ### SDC files ### tech lef set tech_lef \u0026#34;${library_root}/tlef/gsclib045_tech.lef\u0026#34; ### library files set cell_lef \u0026#34;\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/gsclib045_hvt_macro.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/gsclib045_macro.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/MEM1_256X32.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/MEM2_128X32.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/pdkIO.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/pads.lef\u0026#34; ### PEX tech set qrc_tech(rcbest) \u0026#34;${library_root}/tech/qrc/rcbest/qrcTechFile\u0026#34; set qrc_tech(rcworst) \u0026#34;${library_root}/tech/qrc/rcworst/qrcTechFile\u0026#34; set qrc_tech(typical) \u0026#34;${library_root}/tech/qrc/typical/qrcTechFile\u0026#34; ### view (scenarios) of each step set default_scenarios \u0026#34;func_slow_rcworst\u0026#34; set placeopt_scenarios \u0026#34;func_slow_rcworst\u0026#34; set cts_scenarios \u0026#34;cts_slow_rcworst\u0026#34; set clockopt_scenarios \u0026#34;func_slow_rcworst func_fast_rcbest\u0026#34; set routeopt_scenarios \u0026#34;func_slow_rcworst func_fast_rcbest\u0026#34; ### cells type settings set fillers_ref \u0026#34;FILL1 FILL16 FILL2 FILL32 FILL4 FILL64 FILL8\u0026#34; set welltap_ref \u0026#34;DECAP8\u0026#34; ############################################################## # END ############################################################## 2_import # set init_top_cell $design #给该design赋一个名字 set init_verilog $import_netlists #设置verilog文件的路径 set init_lef_file [concat $tech_lef $lef_files] #设置lef file的路径 set init_pwr_net \u0026#34;VDD\u0026#34; #表示初始电源网络的标识符或名称 set init_gnd_net \u0026#34;VSS\u0026#34; #表示初始接地网络的标识符或名称 set init_mmmc_file \u0026#34;../viewDefinition.tcl\u0026#34; #设置mmmc文件的路径 setImportMode -keepEmptyModule true #-keepEmptyModule是一个命令的参数，它指定是否在导入设计时保留空的模块，空的模块，顾名思义，没有任何内容（如实例化，信号，逻辑，声明等）的模块。通过保留这些模块，可以确保设计的层次结构不变，方便后续的设计迭代与调试。 ### read design init_design #开始导入设计 setIoFlowFlag 0 #此内容可以先忽略 ### connect pg (pg--power ground) globalNetConnect $init_pwr_net -type pgpin -pin VDD -all #globalNetConnect，用于连接全局网络也就是用于定义全局电源（Power）和地（Ground）连接。在后端设计阶段，需要明确的定义电源和地如何连接到各个模块和单元。$init_pwr_net 是一个变量，表示初始电源网络的名称，此处等价于VDD，-type 是指定连接的类型是电源/地引脚（pgpin）-------pgpin（power ground pin），-pin VDD，这是另一个参数，用于指定连接的引脚名称或标识符，这里是指定连接到电源引脚，也就是要将$init_pwr_net 连接到所有名为VDD的引脚上，-all 表示该连接适用于设计中的所有实例。 globalNetConnect $init_gnd_net -type pgpin -pin VSS -all #同上，这里不挨个解释，综合说明一下，也可看作是上一条的总结：将变量$init_pwr_net（通常是表示某个电源网络，例如 VSS）连接到设计中所有单元和模块中的 VSS 引脚。这种全局连接是为了确保设计中的所有模块和单元都能正确地连接到电源网络，确保电源供给的一致性和可靠性。 ### save design file delete -force ${data_dir}/${current_step}.enc* #保存设计之前把该路径下存在的.enc文件全部删除 saveDesign ${data_dir}/${current_step}.enc #saveDesign命令，用于保存设计，其后接的是保存设计的文件路径 mmmc(viewDefinition.tcl)\n### library set (-aocv or lvf, spatial socv) create_library_set -name \u0026#34;fast\u0026#34; -timing\\ [list \\ ${library_root}/liberty/fast_vdd1v2_basicCells.lib\\ ${library_root}/liberty/fast_vdd1v2_basicCells_hvt.lib\\ ${library_root}/liberty/MEM1_256X32_slow.lib\\ ${library_root}/liberty/MEM2_128X32_slow.lib\\ ] create_library_set -name \u0026#34;slow\u0026#34; -timing\\ [list \\ ${library_root}/liberty/slow_vdd1v0_basicCells.lib\\ ${library_root}/liberty/slow_vdd1v0_basicCells_hvt.lib\\ ${library_root}/liberty/MEM1_256X32_slow.lib\\ ${library_root}/liberty/MEM2_128X32_slow.lib\\ ] ### rc corner create_rc_corner -name \u0026#34;rc_best\u0026#34;\\ -preRoute_res 1.34236\\ -postRoute_res 1.34236\\ -preRoute_cap 1.10066\\ -postRoute_cap 0.960235\\ -postRoute_xcap 1.22327\\ -preRoute_clkres 0\\ -preRoute_clkcap 0\\ -postRoute_clkcap {0.969117 0 0}\\ -T 0\\ -qx_tech_file ${library_root}/tech/qrc/rcbest/qrcTechFile create_rc_corner -name \u0026#34;rc_worst\u0026#34;\\ -preRoute_res 1.34236\\ -postRoute_res 1.34236\\ -preRoute_cap 1.10066\\ -postRoute_cap 0.960234\\ -postRoute_xcap 1.22327\\ -preRoute_clkres 0\\ -preRoute_clkcap 0\\ -postRoute_clkcap {0.969117 0 0}\\ -T 125\\ -qx_tech_file ${library_root}/tech/qrc/rcworst/qrcTechFile ### delay corner for each pvt (process voltage temperature) : library set + rc corner create_delay_corner -name slow_rcworst\\ -library_set slow\\ -rc_corner rc_worst create_delay_corner -name fast_rcbest\\ -library_set fast\\ -rc_corner rc_best ### mode : (func + shift + capture) #一般对不同情况有多个sdc文件，比如现在有两种delay_corner,就可以写两个，不过现在只有一个现成的sdc文件所以只写一个 create_constraint_mode -name functional \\ -sdc_files [list ${sdc_file}] ### define view (mode + delay corner) create_analysis_view -name func_slow_rcworst -constraint_mode functional -delay_corner slow_rcworst create_analysis_view -name func_fast_rcbest -constraint_mode functional -delay_corner fast_rcbest ### set analysis view status set_analysis_view -setup [list func_slow_rcworst] -hold [list func_fast_rcbest] 3_floorPlan # floorPlan -site CoreSite -d 930 600.28 0 1.71 0 1.71 -fplanOrigin llcorner\t#-d \u0026lt;W H Left Bottom Right Top\u0026gt; 得到的是Die size; -s 得到的是Core size; #-fplanOrigin llcorner 设置原点坐标 #手动放置marco: shift+r进入移动模式，选中后移动marco 对齐，移动：用 ctrl 选择多个 macro\n导出位置 tcl 文件，方便下次自动化：\n注意！这部分要手工！！\n1. 选中macrof 2. writeFPlanScript -selected -fileName ${project_root}/scripts/macro_placement.tcl 3. source ${project_root}/scripts/macro_placement.tcl #fix macro dbGet top.insts.cell.subClass block dbGet [dbGet top.insts.cell.subClass block -p2].name dbSet [dbGet top.insts.cell.subClass block -p2].pStatus fixed ### create placement and routing halo around hard macros (instance name vs cell name, and reference name) set halo_left 2.0 set halo_right 2.0 set halo_top 2.0 set halo_bottom 2.0 set rhalo_space 2.0 deleteHaloFromBlock -allBlock deleteRoutingHalo -allBlocks #addHaloToBlock $halo_left $halo_bottom $halo_right $halo_top -allBlock foreach macro [dbGet [dbGet top.insts.cell.subClass block -p2].name] { addHaloToBlock $halo_left $halo_bottom $halo_right $halo_top $macro addRoutingHalo -space $rhalo_space -top Metal11 -bottom Metal1 -inst $macro } ### place ports set input_ports [dbGet [dbGet top.terms.direction input -p].name] editPin -pinWidth 0.08 -pinDepth 0.32 -fixOverlap 1 -unit TRACK -spreadDirection clockwise -layer 5 -spreadType START -spacing 4 -start 0 -200 -pin $input_ports -fixedPin -side LEFT set output_ports [dbGet [dbGet top.terms.direction output -p].name] editPin -pinWidth 0.08 -pinDepth 0.32 -fixOverlap 1 -unit TRACK -spreadDirection counterclockwise -layer 5 -spreadType START -spacing 4 -start 0 -200 -pin $output_ports -fixedPin -side RIGHT dbSet top.terms.pStatus fixed #放置blockage 2. writeFPlanScript -selected -fileName ${project_root}/scripts/blockage_placement.tcl 3. source ${project_root}/scripts/blockage_placement.tcl #一些endcap, welltap ### insert boundary cells (endcap) set endcap_prefix \u0026#34;ENDCAP\u0026#34; set endcap_left \u0026#34;FILL2\u0026#34; set endcap_right \u0026#34;FILL2\u0026#34; set endcap_top \u0026#34;FILL1\u0026#34; set endcap_bottom \u0026#34;FILL1\u0026#34; deleteFiller -prefix $endcap_prefix setEndCapMode -reset setEndCapMode -topEdge $endcap_top setEndCapMode -bottomEdge $endcap_bottom setEndCapMode -leftEdge $endcap_left setEndCapMode -rightEdge $endcap_left setEndCapMode -leftBottomCorner $endcap_bottom setEndCapMode -leftTopCorner $endcap_top setEndCapMode -rightBottomCorner $endcap_bottom setEndCapMode -rightTopCorner $endcap_top setEndCapMode -leftBottomEdge $endcap_left setEndCapMode -leftTopEdge $endcap_left setEndCapMode -rightBottomEdge $endcap_right setEndCapMode -rightTopEdge $endcap_right addEndCap -prefix $endcap_prefix ### create well tap cells (fix latch up) set welltap_prefix \u0026#34;WELLTAP\u0026#34; deleteFiller -prefix $welltap_prefix addWellTap -prefix $welltap_prefix -cell $welltap_ref -cellInterval 70 -checkerBoard 4_powerPlan # ### remove all existing power routing editDelete -use {POWER} -shape {RING STRIPE FOLLOWPIN IOWIRE COREWIRE BLOCKWIRE PADRING BLOCKRING FILLWIRE FILLWIREOPC DRCFILL} #Add power Stripe setAddStripeMode -reset setAddStripeMode -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal1#指定最底层和最顶层要用via连接的是哪些层，此处我们只create Metal1最底层的rails，所以top_layer和bottom_layer都是Metal1。 addStripe -nets { VDD } -layer Metal1 -direction horizontal -width 0.120 -spacing 1.710 -set_to_set_distance 3.420 -start [expr 1.71 - 0.120 / 2.0] -stop $die_y1 -area $die_area -area_blockage $macro_region #-nets 指定是VDD #-layer 指定使用的层，此处是Metal1 #-direction 指定方向，此处为horizontal #-width 一般来说是std cell的VDD的width是多少就设为多少，下图所示是0.12，所以我们也设为0.12 addStripe -nets { VSS } -layer Metal1 -direction horizontal -width 0.120 -spacing 1.710 -set_to_set_distance 3.420 -start [expr 1.71*2 - 0.120 / 2.0] -stop $die_y1 -area $die_area -area_blockage $macro_region ##给macro通过ring加上power strip ### create power rings for memory cells {Metal8 \u0026amp; Metal9} setAddRingMode -reset deselectAll selectInst [dbGet [dbGet top.insts.cell.subClass block -p2].name] setAddRingMode -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addRing -nets {VDD VSS} -type block_rings -around selected -layer {top Metal9 bottom Metal9 left Metal8 right Metal8} -width {top 5 bottom 5 left 5 right 5} -spacing {top 1.25 bottom 1.25 left 1.25 right 1.25} -offset {top 5 bottom 5 left 5 right 5} deselectAll ### create power stripes (Metal8 and Metal9) #editDelete -use {POWER} -shape {RING STRIPE FOLLOWPIN IOWIRE COREWIRE BLOCKWIRE PADRING BLOCKRING FILLWIRE FILLWIREOPC DRCFILL} setAddStripeMode -reset setAddStripeMode -break_at {block_ring} -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addStripe -nets {VDD VSS} -layer Metal9 -direction horizontal -width 5 -spacing 1.25 -set_to_set_distance 72 -start_from bottom -start_offset 40 -stop_offset 0 -block_ring_top_layer_limit Metal9 -block_ring_bottom_layer_limit Metal1 setAddStripeMode -reset setAddStripeMode -break_at {block_ring} -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addStripe -nets {VDD VSS} -layer Metal8 -direction vertical -width 5 -spacing 1.25 -set_to_set_distance 75 -start_from left -start_offset 35 -stop_offset 0 -block_ring_top_layer_limit Metal9 -block_ring_bottom_layer_limit Metal1 #check set report_drc_dir ${project_root}/reports/${current_step} file mkdir ${report_drc_dir} verify_drc -limit 99999 -report ${report_drc_dir}/verify_drc.rpt#给一个error数量的限制 -limit 99999 verifyConnectivity -net {VDD VSS} -error 99999 -report ${report_drc_dir}/verifyConnectivity.rpt #给一个error数量的限制 -limit 99999 redirect -tee ${report_drc_dir}/checkPlace.rpt {checkPlace} 可以在这里查看报告：\n#上面这个bug： deleteRouteBlk -name $rblkg_prefix 5_place_opt # setDesignMode\n-node，别称“超级开关”，是比较重要的一个设置，可以针对 某一种特定的工艺做一些基础的设置。它的选项很多，分别对应不同 Foundary 的不同工艺的区别，N 系列就是台积电的，S 系列就是三星的。。。\n-process，相比于-node，-process 是更 通用的设置，因为可以看到-node 里面的都是 20 以下的，此处用到的工艺是 45，所以使用更为通用的-process 45。在成熟的工艺中，都有特定的数字去代替，比如 40，28 等等。\n-topRoutingLayer,-bottomRoutingLayer. 就是告诉工具只能用哪些层进行绕线\nsetAnalysisMode\n-analysisType {single | bcwc | onChipVariation}\n其中(onChipVariation)模拟的 PVT 条件的偏差会更接近实际情况，会减少一些不必要的悲观量。\n一般都用 OCV\n-cppr 是关于 clock line 上的 common path 的一个处理方式\nsetOptMode\n-addInstancePrefix, -addNetPrefix\n工具在优化的过程中会增加很多新的 Cell，对于这些 Cell，我们希望他们都带一个我们能快速辨别他们的名字。也就是 Prefix（前缀）。当然，可以给 Instance 加 Prefix，那么也可以给 Net 加 Prefix\ne.g.:\nsetOptMode -addInstancePrefix \u0026#34;PRECTS_\u0026#34; -addNetPrefix \u0026#34;PRECTS_NET_\u0026#34; -powerEffort {none|low|high}\n-maxDensity -maxLength setTieHiLoMode\n这条命令本身只是去控制那些加的 Tie-high 和 Tie-low 的 Cell，也就是说在电路中某些地方电平需要拉高和拉低，就需要 专门的 Cell 去做这些连接。\n-maxFanout 2 ，就是设置一个 Tie cell 可以连接几个 Fanout。若设置的太大，可能出现的问题：需要拉高的时候拉不高，需要拉低的时候拉不低。若是设置的太小，可能导致 Tie Cell 最后局部的 density 会出现问题。 -honorDontTouch true ，就是设置为 honorDontTouch 的情况下到底要不要加 Tie，一般加的 DontTouch 都是工程师自己加的，也就是真的不希望动的地方，所以设置为 true -honorDontUse true，同上一样，是工程师真的不需要用到的，所以设置为 true。 -prefix “PRECTS_TIE_” , 给加的 Tie cell 加一个 Prefix（前缀）。便于识别。 -cell {TIEHI TIELO} 就是指定我们需要加的 Tie Cell 的类型 setNanoRouteMode\n这里的绕线是 global route\n-routeWithTimingDriven -true 也就是告诉工具在绕线的时候考虑时序。 group_path, setPathGroupOptions\n-effortLevel 对不同的 path group 的关注不一样，如此处，我们 关心 reg2reg，所以把 reg2reg 的 effortLevel 设置为 high set_dont_use_cells\n一般用于优化 PPA 的时候, 把一些面积大的, 功耗大的删掉\nset_clock_uncertainty\nset_clock_uncertainty 150 [all_clocks] -setup\nplace : jitter + clock skew + route correlation (si) + extra margin clock : jitter + route correlation (si) + extra margin route : jitter + extra margin signoff : jitter + extra margin set_max_transition\n一般可以按照 clock_cycle 的比例来定，对 clock 上面的 transition 一般定为 5%-8%，对 data 上面的 transition 一般定为 15%-20%\n库里面也有一些关于 max_transition 的限制, 但是往往比较宽松, 需要自己设置\n-clock_path xxx [all_clocks]\n-data_path xxx [all_clocks]\n-override, 覆盖其他地方的关于 max_transition 的设置\nplace_opt_design\n使用 GigaPlace 进行布局优化\n-expanded_views 就是告诉工具不要做 view 的 merge\n-out_dir 就是告诉工具输出的 path 放在哪个地方\n-prefix ”innovus_placeopt“\n6_CTS # set_ccopt_property\n查看 clk_buffer 种类：get_lib_cell *CLK*BUF*，一般不选 hvt buffer_cells clock_gating_cells use_inverters effort max_fanout target_skew target_max_trans target_insertion_delay route_type use_estimated_routes_during_final_implementation add_ndr\nNDR:(Non-Default Rule)\nclock 上的 route 需要和 standard cell 上的不一样，需要更大的间距。。。\nccopt_design\n7_cts_opt # optDesign -expandedViews -setup -hold -drv -outDir \u0026quot;myreports/${current_step}/innovus_clockopt\u0026quot; -postCTS -prefix \u0026quot;innovus_clockopt\u0026quot;\n8_route # 优化 # 优化目标 # 时序(Performance)\n设计规则(DRV): transition(slew)/cap/wire length setup / hold /recovery/ removal /other 噪声: Sl violation 功耗(Power):\nleakage/internal/switching 面积(Area): total standard cell area\nDFM: 电迁移(EM)\ninnovus 优化流程 # 有些公司不做 postCTS_opt, 应为还没有进行真实的布线，RC 延时估算不准，尤其是对 hold 来说。\n做关于 hold 的优化是很有限的，基本上只有插入 buffer 和调整 size，CTS 之后基本不会将存在的 buffer 删掉，因此一般没什么优化\n在 placement 就存在的 vio 很难在后面的优化中去掉\n文件名称 # GDSII： # 它是用来描述掩模几何图形的事实标准，是二进制格式，内容包括层和几何图形的基本组成。\nCIF： # （caltech intermediate format）, 叫 caltech 中介格式，是另一种基本文本的掩模描述语言。\nLEF： # （library exchange format）, 叫库交换格式，它是描述库单元的物理属性，包括端口位置、层定义和通孔定义。它抽象了单元的底层几何细节，提供了足够的信息，以便允许布线器在不对内部单元约束来进行修订的基础上进行单元连接。\n包含了工艺的技术信息，如布线的层数、最小的线宽、线与线之间的最小距离以及每个被选用 cell，BLOCK，PAD 的大小和 pin 的实际位置。 cell，PAD 的这些信息由厂家提供的 LEF 文件给出，自己定制的 BLOCK 的 LEF 文件描述经 ABSTRACT 后生成，只要把这两个 LEF 文件整合起来就可以了。\nLayer： pitch: track 之间的最小距离 offset：track 到边缘的最小距离 area：一块金属的最小面积 SPACINGTABLE: Standard cell # DEF： # （design exchange format），叫设计交换格式，它描述的是 实际的设计，对库单元及它们的位置和连接关系进行了列表，使用 DEF 来在不同的设计系统间传递设计，同时又可以保持设计的内容不变。DEF 与只传递几何信息的 GDSII 不一样。它还给出了器件的物理位置关系和时序限制等信息。\n主要包含如下内容:\n版本和设计名称\n单位和数据库设置\n设计组件（Components）\n引脚（Pins）\n网表（Nets）\n轨道（Tracks）和 GCell 网格\n区域（Regions）和楼层规划（Floorplanning）区域\n组（Groups）和组约束\nVIAs\n特殊网表（Special Nets）\n属性（Properties）\n一个实例:\nVERSION 5.8 ; DIVIDERCHAR \u0026#34;/\u0026#34; ; BUSBITCHARS \u0026#34;[]\u0026#34; ; DESIGN my_chip_design ; UNITS DISTANCE MICRONS 1000 ; DIEAREA ( 0 0 ) ( 100000 100000 ) ; // Components COMPONENTS 300 ; - comp1 cell1 + PLACED ( 10000 10000 ) N ; - comp2 cell2 + PLACED ( 20000 20000 ) N ; ... END COMPONENTS // Pins PINS 50 ; - pin1 + NET net1 + DIRECTION INPUT + USE SIGNAL + PORT + LAYER metal1 ( 0 0 ) ( 100 100 ) + PLACED ( 5000 5000 ) N ; ... END PINS // Nets NETS 200 ; - net1 + ROUTED + metal1 ( 10000 10000 ) ( 15000 15000 ) + VIA via1 ( 15000 15000 ) + metal2 ( 15000 15000 ) ( 20000 20000 ) ; ... END NETS // Tracks and GCells Grid TRACKS ... END TRACKS GCELLGRID ... END GCELLGRID // Regions and Floorplan REGIONS ... END REGIONS // Groups and Constraints GROUPS ... END GROUPS // VIAs VIAS 10 ; - via1 + RECT metal1 ( -5 -5 ) ( 5 5 ) + RECT via ( -5 -5 ) ( 5 5 ) + RECT metal2 ( -5 -5 ) ( 5 5 ) ; ... END VIAS // Special Nets SPECIALNETS ... END SPECIALNETS // Properties PROPERTYDEFINITIONS ... END PROPERTYDEFINITIONS END DESIGN 相关指令\ndefin\ndefout\n[def 文件的作用及相关操作_.def 文件-CSDN 博客]( https://blog.csdn.net/NCG951204/article/details/126570067#:~:text=defin ：加载一)\nLib: # 命名规则：\n​\tlib 文件\n​\tcell：\n文本格式: .lib 文件通常是文本文件，使用人类可读的 ASCII 文本来描述。 标准化: .lib 文件使用的是 Liberty 格式，这是一个业界标准，用于描述电子电路库的性能。 可携带性和可读性: 由于它是一个文本文件，所以很容易通过文本编辑器查看和修改，并且容易在不同的设计工具和平台之间转移。 用途: Liberty 文件主要用于逻辑合成和静态时序分析（STA）。它包含有关单元（如门、触发器等）的时序和功耗特性 SDF： # (Standard delay format), 叫标准延时格式，是 IEEE 标准，它描述设计中的时序信息，指明了模块管脚和管脚之间的延迟、时钟到数据的延迟和内部连接延迟。\nDSPF、RSPF、SBPF 和 SPEF： # DSPF（detailed standard parasitic format）, 叫详细标准寄生格式，属于 CADENCE 公司的文件格式。\nRSPF（reduced standard parasitic format）, 叫精简标准寄生格式，属于 CADENCE 公司的文件格式。\nSBPF（synopsys binary parasitic format）, 叫新思科技二进制寄生格式，属于 SYNOPSYS 公司的文件格式。\nSPEF（standard parasitic exchange format）, 叫标准寄生交换格式，属于 IEEE 国际标准文件格式。\n以上四种文件格式都是从网表中提取出来的表示 RC 值信息，是在提取工具与时序验证工具之间传递 RC 信息的文件格式。\nALF： # (Advanved library format), 叫先进库格式，是一种用于描述基本库单元的格式。它包含电性能参数。\nPDEF： # （physical design exchange format）叫物理设计交换格式。它是 SYNOPSYS 公司用在前端和后端工具之间传递信息的文件格式。描述了与单元层次分组相关的互连信息。这种文件格式只有在使用 SYNOPSYS 公司的 Physical Compiler 工具才会用到，而且.13 以下工艺基本都会用到该工具。\nTLF # TLF 文件是描述 cell 时序的文件，标准单元的 rise time，hold time，fall time 都在 TLF 内定义。时序分析时就调用 TLF 文件，根据 cell 的输入信号强度和 cell 的负载来计算 cell 的各种时序信息。\nGCF # GCF 文件包括 TLF/CTLF 文件的路径，以及综合时序、面积等约束条件。在布局布线前，GCF 文件将设计者对电路的时序要求提供给 SE。这些信息将在时序驱动布局布线以及静态时序分析中被调用。\ninstall # 环境：ubuntu20.04, innovus20\n安装包： innovus20_install\n依赖 # sudo apt-get -y install openjdk-11-jdk sudo apt-get install ksh sudo apt-get install csh sudo apt-get install xterm sudo add-apt-repository ppa:linuxuprising/libpng12 sudo apt update sudo apt install libpng12-0 sudo apt install libjpeg62 sudo apt install libncurses5 1.进入 官网 下载 Xbin.tgz 这个文件\n解压 # #解压3个innovus20压缩包 #InstallScape是一个安装cadence软件的工具，解压以后进入03.InstallScape/iscape/bin/ sh iscape.sh 安装 # 等待，弹出终端选 no，然后回车结束\n破解 # #在crack文件夹中 ./1patch.sh /your/install/path python cdslicgen.py #生成license.dat cp patch/license.dat /path/you/want/to/place/License/ #把license放到一个你要放的位置 cdslicgen.py 破解改动在这里，我只是发现了别人的脚本在这里会报错，改了一点：\n环境变量 # 根据你的安装路径和 license 路径对应修改\n# \u0026gt;\u0026gt;\u0026gt; innovus initialize \u0026gt;\u0026gt;\u0026gt; export INNOVUS_HOME=/opt/EDA_Tools/cadence/innovus20 # license export LM_LICENSE_FILE=${INNOVUS_HOME}/License/license.dat export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${INNOVUS_HOME}/tools.lnx86/lib/64bit:${INNOVUS_HOME}/tools.lnx86 export PATH=${PATH}:${INNOVUS_HOME}/tools.lnx86/bin # \u0026lt;\u0026lt;\u0026lt; innovus initialize \u0026lt;\u0026lt;\u0026lt; 大致结束 # innovus \u0026amp; 其他相关 bug # 1.libstdc++.so.6\n[Cadence Innovus2020 在 Ubuntu20.04 上的安装教程【超详细】_innovus 安装-CSDN 博客]( https://blog.csdn.net/qq_44447544/article/details/122698979?ops_request_misc =%7B%22request%5Fid%22%3A%22A2277519-6B4E-4DD3-952A-1958A9EA40EA%22%2C%22scm%22%3A%2220140713.130102334..%22%7D\u0026amp;request_id = A2277519-6B4E-4DD3-952A-1958A9EA40EA\u0026amp;biz_id = 0\u0026amp;utm_medium = distribute.pc_search_result.none-task-blog-2alltop_click~default-2-122698979-null-null.142^v100^control\u0026amp;utm_term = innovus 安装\u0026amp;spm = 1018.2226.3001.4187)\nsudo ln -s /lib/x86_64-linux-gnu/libstdc++.so.6.0.30 libstdc++.so.6\n2.No LSB modules are available.\nsudo apt-get install lsb-core\n3.place_opt_design 后\nterminate called after throwing an instance of \u0026#39;std::runtime_error\u0026#39; what(): locale::facet::_S_create_c_locale name not valid Innovus terminated by internal (ABORT) error/signal... *** Stack trace: /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x12f9ffe5] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(syStackTrace+0xa5)[0x12fa0456] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4aa5ef3] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15goSignalHandler13executeActionEiP7siginfoPv+0x47)[0x7c97667] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15goSignalHandler16executeSigActionEiP7siginfoPv+0x84)[0x7c98494] /lib/x86_64-linux-gnu/libc.so.6(+0x4251f)[0x7f2653c1951f] /lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f2653c6d9fc] /lib/x86_64-linux-gnu/libc.so.6(raise+0x15)[0x7f2653c19475] /lib/x86_64-linux-gnu/libc.so.6(abort+0xd2)[0x7f2653bff7f2] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(+0xa2b9d)[0x7f265ac76b9d] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(+0xae20b)[0x7f265ac8220b] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZSt9terminatev+0x16)[0x7f265ac82276] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(__cxa_throw+0x47)[0x7f265ac824d7] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZSt21__throw_runtime_errorPKc+0x3f)[0x7f265ac7951c] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6locale5facet18_S_create_c_localeERP15_ _locale_structPKcS2_+0x27)[0x7f265aca5257] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6locale5_ImplC2EPKcm+0x54)[0x7f265ac96d04] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6localeC1EPKc+0x144)[0x7f265ac978e4] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK11oiInstCntCL5printERKSsb+0x2a)[0x7490eaa] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15oiPhyDesignMcCL6createERK22oiPhyDesignGridParamCLiib+0x290)[0x74948e0] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z17oiPhyInitDesignMci+0x22)[0x7495112] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4d546fb] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN10tcmBaseCmd7executeEP10Tcl_InterpiPPc+0x166)[0x15264886] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN6tcmMgr9cmdParserEPvP10Tcl_InterpiPPc+0x693)[0x15257fe3] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclInvokeStringCommand+0x7f)[0x20ed56df] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20edc527] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_EvalEx+0x15)[0x20edce55] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_Eval+0x14)[0x20edce74] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN5oiTcl9CmdInterp6evalOKEPKc+0x2d)[0x4d87a8d] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK14rdaOptDesignCL3runEv+0x9c3)[0x4d2b543] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4d4da81] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN10tcmBaseCmd7executeEP10Tcl_InterpiPPc+0x166)[0x15264886] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN6tcmMgr9cmdParserEPvP10Tcl_InterpiPPc+0xad2)[0x15258422] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclInvokeStringCommand+0x7f)[0x20ed56df] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20edc527] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_EvalEx+0x15)[0x20edce55] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNREvalObjEx+0x6e)[0x20edcefe] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20f9270a] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20ef0150] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_RecordAndEvalObj+0xf3)[0x20f78753] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_RecordAndEval+0x37)[0x20f788b7] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z17rdaEditCmdLineEndPc+0x344)[0x4b68f44] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN9seConsole7sesMode9DoExecuteERKSsPv+0xc6)[0xfb3bc66] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline9EmacsMode10AcceptLineEv+0x3b)[0x10cac8eb] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline11ModeCommandINS_9EmacsModeEE15CommandFnNoKeysERKN5boost8functionIFvRS1_EEERNS_6EditorE+0x60)[0x10cb4e70] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN5boost6detail8function26void_function_obj_invoker2INS_3_bi6bind_tINS3_11unspecifiedENS_8functionIFvRN7Redline6EditorEEEENS3_5list1INS_3argILi1EEEEEEEvS9_RKNS7_14KeyCombinationEE6invokeERNS1_15function_bufferES9_SJ_+0x1a)[0x10cc46ca] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK7Redline7Command3RunERNS_6EditorERKNS_14KeyCombinationE+0x1b)[0x10cc43eb] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline6Editor9Internals3RunEb+0xdf)[0x10ca8f0f] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20fdce36] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_ServiceEvent+0x86)[0x20f9e886] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_DoOneEvent+0x128)[0x20f9eb88] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libtq.so(_ZN17TqEventDispatcher13processEventsE6QFlagsIN10QEventLoop17ProcessEventsFlagEE+0x69)[0x7f265741b239] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/Qt/v5//64bit/lib/libcdsQt5Core.so.5(_ZN10QEventLoop4execE6QFlagsINS_17ProcessEventsFlagEE+0xe9)[0x7f2656ad00c9] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/Qt/v5//64bit/lib/libcdsQt5Core.so.5(_ZN16QCoreApplication4execEv+0x83)[0x7f2656ad8953] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libtq.so(_ZN13TqApplication4execEv+0x176)[0x7f265741a896] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z12edi_app_initP10Tcl_Interp+0x2a8)[0x4b510d8] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_MainEx+0x176)[0x20f993c6] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(main+0x1d1)[0x41d4b71] /lib/x86_64-linux-gnu/libc.so.6(+0x29d8f)[0x7f2653c00d8f] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x7f)[0x7f2653c00e3f] /opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4aa2c1c] ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== gdb ==== ==== ==== ==== ==== ==== ==== ==== ==== ==== Using: gdb Could not attach to process. If your uid matches the uid of the target process, check the setting of /proc/sys/kernel/yama/ptrace_scope, or try again as the root user. For more details, see /etc/sysctl.d/10-ptrace.conf ptrace: Operation not permitted. /home/pengxuan/Project/mylab/innovus/lab2/work/1314912: No such file or directory. 参考 # Cadence Innovus2020 在Ubuntu20.04上的安装教程【超详细】_innovus安装-CSDN博客\ninnovus2020安装_innovus安装-CSDN博客\nUbuntu18.04安装Cadence Innovus2021_innovus安装-CSDN博客\n参考 # 官方文档：UserGuide, Command reference\nOpenROAD/ORFS/OpenLane # 特点 # 优点 # 开源，可以自定义修改\n该领域的热门应用\n作者回复迅速（一般第二天就会回复）\n自动化程度较高\n还在不断更新中，更新快\n缺点 # 有一些商用工具有的功能他没有 relation between openroad/SRFS/openlane # openroad # basic model netlist2gds, 也可以hdl2gds，但是比较麻烦， 用abc做综合 越来越流行了，比赛也开始用了 ORFS # hdl2gds pdk friendly， 可以直接跑7nm 支持重新编译OpenROAD（自定义修改） gui不知道为什么用起来很卡 内置AutoTuner，一个扫参自动优化PPA的工具 支持在线使用（Colab） openlance # hdl2gds most auto 内置只有sky130 PDK 不支持重新编译OpenROAD Architecture # openlane\nOpenLane Flow Stages # OpenLane flow consists of several stages. By default all flow steps are run in sequence. Each stage may consist of multiple sub-stages. OpenLane can also be run interactively as shown [here][25].\nSynthesis Yosys - Perform RTL synthesis and technology mapping. OpenSTA - Performs static timing analysis on the resulting netlist to generate timing reports Floorplaning OpenROAD/Initialize Floorplan - Defines the core area for the macro as well as the rows (used for placement) and the tracks (used for routing) OpenLane IO Placer - Places the macro input and output ports OpenROAD/PDN Generator - Generates the power distribution network OpenROAD/Tapcell - Inserts welltap and endcap cells in the floorplan Placement OpenROAD/RePlace - Performs global placement OpenROAD/Resizer - Performs optional optimizations on the design OpenROAD/OpenDP - Performs detailed placement to legalize the globally placed components CTS OpenROAD/TritonCTS - Synthesizes the clock distribution network (the clock tree) Routing OpenROAD/FastRoute - Performs global routing to generate a guide file for the detailed router OpenROAD/TritonRoute - Performs detailed routing OpenROAD/OpenRCX - Performs SPEF extraction Tapeout Magic - Streams out the final GDSII layout file from the routed def KLayout - Streams out the final GDSII layout file from the routed def as a back-up Signoff Magic - Performs DRC Checks \u0026amp; Antenna Checks Magic - Performs DRC Checks \u0026amp; an XOR sanity-check between the two generated GDS-II files Netgen - Performs LVS Checks All tools in the OpenLane flow are free, libre and open-source software. While OpenLane itself as a script (and its associated build scripts) are under the Apache License, version 2.0, tools may fall under stricter licenses.\nEverything in Floorplanning through Routing is done using OpenROAD and its various sub-utilities, hence the name “OpenLane.”\nPDK # The OpenROAD application is PDK independent. However, it has been tested and validated with specific PDKs in the context of various flow controllers.\nOpenLane supports SkyWater 130nm and GlobalFoundries 180nm.\nOpenROAD-flow-scripts supports several public and private PDKs including:\nOpen-Source PDKs # GF180 - 180nm SKY130 - 130nm Nangate45 - 45nm ASAP7 - Predictive FinFET 7nm Proprietary PDKs # These PDKS are supported in OpenROAD-flow-scripts only. They are used to test and calibrate OpenROAD against commercial platforms and ensure good QoR. The PDKs and platform-specific files for these kits cannot be provided due to NDA restrictions. However, if you are able to access these platforms independently, you can create the necessary platform-specific files yourself.\nGF55 - 55nm GF12 - 12nm Intel22 - 22nm Intel16 - 16nm TSMC65 - 65nm Basic Run # openroad [-help] [-version] [-no_init] [-exit] [-gui] [-threads count|max] [-log file_name] cmd_file -help show help and exit -version show version and exit -no_init do not read .openroad init file -threads count|max use count threads -no_splash do not show the license splash at startup -exit exit after reading cmd_file -gui start in gui mode -python start with python interpreter [limited to db operations] -log \u0026lt;file_name\u0026gt; write a log in \u0026lt;file_name\u0026gt; cmd_file source cmd_file OpenROAD sources the Tcl command file ~/.openroad unless the command line option -no_init is specified.\nOpenROAD then sources the command file cmd_file if it is specified on the command line. Unless the -exit command line flag is specified, it enters an interactive Tcl command interpreter.\nA list of the available tools/modules included in the OpenROAD app and their descriptions are available here.\nBasic Command # area # ord::get_die_area ord::get_core_area\nSave Image # # This command can be both be used when the GUI is active and not active to save a screenshot with various options.\nsave_image [-resolution microns_per_pixel] [-area {x0 y0 x1 y1}] [-width width] [-display_option {option value}] filename Options # Switch Name Description filename path to save the image to. -area x0, y0 - first corner of the layout area (in microns) to be saved, default is to save what is visible on the screen unless called when gui is not active and then it selected the whole block. x1, y1 - second corner of the layout area (in microns) to be saved, default is to save what is visible on the screen unless called when gui is not active and then it selected the whole block. -resolution resolution in microns per pixel to use when saving the image, default will match what the GUI has selected. -width width of the output image in pixels, default will be computed from the resolution. Cannot be used with -resolution. -display_option specific setting for a display option to show or hide specific elements. For example, to hide metal1 -display_option {Layers/metal1 false}, to show routing tracks -display_option {Tracks/Pref true}, or to show everthing -display_option {* true} Select Objects # This command selects object based on options. Returns: number of objects selected.\nselect -type object_type [-name glob_pattern] [-filter attribute = value] [-case_insensitive] [-highlight group] Options # Switch Name Description -type name of the object type. For example, Inst for instances, Net for nets, and Marker for database markers. -name (optional) filter selection by the specified name. For example, to only select clk nets *clk*. Use -case_insensitive to filter based on case insensitive instead of case sensitive. -filter (optional) filter selection based on the objects’ properties. attribute represents the property’s name and value the property’s value. In case the property holds a collection (e. g. BTerms in a Net) or a table (e. g. Layers in a Generate Via Rule) value can be any element within those. A special case exists for checking whether a collection is empty or not by using the value CONNECTED. This can be useful to select a specific group of elements (e. g. BTerms=CONNECTED will select only Nets connected to Input/Output Pins). -highlight (optional) add the selection to the specific highlighting group. Values can be 0 to 7. Add a single net to selection # To add a single net to the selected items:\ngui:: selection_add_net name Options # Switch Name Description name name of the net to add. Add multiple nets to selection # To add several nets to the selected items using a regex:\ngui:: selection_add_nets name_regex Options # Switch Name Description name_regex regular expression of the net names to add. Add a single inst to selection # To add a single instance to the selected items:\ngui:: selection_add_inst name Options # Switch Name Description name name of the instance to add. Add multiple insts to selection # To add several instances to the selected items using a regex:\ngui:: selection_add_insts name_regex Options # Switch Name Description name_regex regular expression of the instance names to add. Select at point or area # To add items at a specific point or in an area:\nExample usage:\ngui:: select_at x y gui:: select_at x y append gui:: select_at x0 y0 x1 y1 gui:: select_at x0 y0 x1 y1 append gui:: select_at x0 y0 x1 y1 [append] Or gui:: select_at x y [append] Options # Switch Name Description x, y point in the layout area in microns. x0, y0, x1, y1 first and second corner of the layout area in microns. append if true (the default value) append the new selections to the current selection list, else replace the selection list with the new selections. Select next item from selection # To navigate through multiple selected items: Returns: current index of the selected item.\ngui:: select_next Select previous item from selection # To navigate through multiple selected items: Returns: current index of the selected item.\ngui:: select_previous Clear Selection # To clear the current set of selected items:\ngui:: clear_selections Set Heatmap # To control the settings in the heat maps:\nThe currently availble heat maps are:\nPower Routing Placement IRDrop RUDY [ 1] These options can also be modified in the GUI by double-clicking the underlined display control for the heat map.\ngui:: set_heatmap name [option] [value] Options # Switch Name Description name is the name of the heatmap. option is the name of the option to modify. If option is rebuild the map will be destroyed and rebuilt. value is the new value for the specified option. This is not used when rebuilding map. Dump Heatmap to file # To save the raw data from the heat maps ins a comma separated value (CSV) format:\ngui:: dump_heatmap name filename Options # Switch Name Description name is the name of the heatmap. filename path to the file to write the data to. init # floorplant # placement # Routing # globle routing # Write Guides # This command writes global routing guides, which can be used as input for global routing.\nExample: write_guides route.guide.\nwrite_guides file_name Options # Switch Name Description file_name Guide file name. report and dump # Write Macro Placement # This command writes macro placement.\nwrite_macro_placement file_name Global Routing - FastRoute4.1 # OpenROAD/src/grt at master · The-OpenROAD-Project/OpenROAD\nSwitch Name Description -guide_file Set the output guides file name (e.g., route.guide). -congestion_iterations Set the number of iterations made to remove the overflow of the routing. The default value is 50, and the allowed values are integers [0, MAX_INT]. -congestion_report_file Set the file name to save the congestion report. The file generated can be read by the DRC viewer in the GUI (e.g., report_file.rpt). -congestion_report_iter_step Set the number of iterations to report. The default value is 0, and the allowed values are integers [0, MAX_INT]. -grid_origin Set the (x, y) origin of the routing grid in DBU. For example, -grid_origin {1 1} corresponds to the die (0, 0) + 1 DBU in each x\u0026ndash;, y- direction. -critical_nets_percentage Set the percentage of nets with the worst slack value that are considered timing critical, having preference over other nets during congestion iterations (e.g. -critical_nets_percentage 30). The default value is 0, and the allowed values are integers [0, MAX_INT]. -allow_congestion Allow global routing results to be generated with remaining congestion. The default is false. -verbose This flag enables the full reporting of the global routing. -start_incremental This flag initializes the GRT listener to get the net modified. The default is false. -end_incremental This flag run incremental GRT with the nets modified. The default is false. Using Macro in openlane # debug in openroad # make as follow # cd OpenROAD mkdir build_debug cd build_debug cmake .. -DCMAKE_BUILD_TYPE=DEBUG #wait make #make -j $thread_to_make my lancun.json # { \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;(gdb) Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;/you/path/OpenROAD/build_debug/src/openroad\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;/you/path/OpenROAD-flow-scripts/tools/OpenROAD/build_debug/src/\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true }, { \u0026#34;description\u0026#34;: \u0026#34;Set Disassembly Flavor to Intel\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-gdb-set disassembly-flavor intel\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ] } ] } after add your breakpoints, click the triangle to debug and you have to wait a minutes then you can input you command to debug openroad in terminal I just found out how to do that too, holp this help.\ninstall # Installing OpenROAD — OpenROAD documentation\n#在ubuntu:20.04新的docker容器中 apt update apt-get update --fix-missing apt install git git clone --recursive https://github.com/The-OpenROAD-Project/OpenROAD.git cd OpenROAD/ ./etc/DependencyInstaller.sh cd build/ make make install openroad -help install in a new ubuntu20.04 container\n现在openroad中安装依赖，再直接build ORFS\nBuild from sources using Docker — OpenROAD Flow documentation\napt install swig apt-get install libboost-all-dev a bug:\nIgn:1 https://download.docker.com/linux/ubuntu focal InRelease\nErr:2 https://download.docker.com/linux/ubuntu focal Release\nCould not handshake: Error in the pull function. [IP: 13.35.210.84 443]\nHit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\nHit:4 http://archive.ubuntu.com/ubuntu focal InRelease\nHit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\nHit:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nReading package lists\u0026hellip; Done\nE: The repository \u0026lsquo; https://download.docker.com/linux/ubuntu focal Release\u0026rsquo; no longer has a Release file.\nN: Updating from such a repository can\u0026rsquo;t be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nbuild in docker, not in locally 开源工具 # openroad，openlane rtl-dgs全流程\nALIGN2（“模拟布局，从网表智能生成”）\nGlobal Router:\nNCTUGR 2.0: can generate precise congestion maps\nFastRoute1 [ICCAD 06]:\nFastRoute2 :\nFastRoute3 :\nFastRoute4 :\nLabyrinth [TCAD 2002] :\nChi Dispersion router [DAC 2003] :\n数据集 # openroad 也有一些数据集?\n比如:\nCircuitNet:\n在某些应用中，基于 GNN 的解决方案仍然没有达到完全的准确性。这可以使用 GNN 的结果作为进一步后处理步骤的输入来解决，如 GANA [30] 中那样。然而，我们希望未来的工作能够扩大训练数据和特征集以提高准确性，正如 GRANNITE [71] 中所提出的那样。更大的数据集将启用更深层次的模型，这可以转化为更好的结果。对于数据集生成，我们期望更多地使用开源 EDA 工具和技术。一个开放和标准的数据收集基础设施将最大限度地减少图形构建、映射和标记工作。此外，它将增强对 GNN 和 EDA 的研究，并实现研究结果比较和基准测试。\nChipyard\nOpencores\nPDK # DK即Process Design Kit 工艺设计包，是连接IC设计公司、代工厂和EDA公司的桥梁. PDK包含了从芯片设计到制造的各个环节所需的数据和信息，为了更直观地了解它，我们可以将PDK比作芯片设计过程中的“指导手册”\nPDK的主要作用是将晶圆代工厂的制造工艺要求转化为芯片设计师能够理解的信息。设计师利用PDK中的数据来确保他们的设计能够顺利制造，并将PDK导入到EDA软件中，进行设计、模拟和验证。一旦完成设计，设计师就可以将设计文件发送给晶圆代工厂进行生产。\nA Process Design Kit (PDK) serves as the fundamental building block for integrated circuit (IC) design, playing a crucial role in transforming chip designs into silicon reality. These files serve as essential inputs for Electronic Design Automation (EDA) tools during chip design. Clients engage with a foundry\u0026rsquo;s PDKs before production to ensure that their chip designs align with the foundry\u0026rsquo;s capabilities and intended functionality.EDA Tool Ecosystem and PDK Integration. These tools rely on accurate PDK data to generate layouts, verify designs, and simulate performance. Standardized interfaces across diverse technology platforms enhance PDK usability.\n内容 # 生态 # 上游到下游\n开源PDK # sky130 # GF180 # FreePDK45 # nangate45 # FreePDK45 是北卡罗来纳州立大学的电子设计自动化实验室提供的免费开源的45nm工艺库，使用了MOSIS工艺\nIHP Open Source PDK # ASAP7 # 7nm Predictive PDK\nASAP5 # 5nm\nThe-OpenROAD-Project/asap5\n貌似还用不了\n参考 # DesignAutomationConference_SFO_2024\n"},{"id":6,"href":"/zh/docs/Digtal/Placement/placement/","title":"Placement","section":"Physical Design","content":" 介绍 # Placement # 良好的布局会带来更好的芯片面积利用率、时序性能和可达性，而较差的布局会影响芯片的性能，甚至使其无法制造\n布局可以看作是具有几何约束的二维装箱问题的一个更为复杂的变化。后者被认为是 NP-hard 问题。\n布局与电路设计的逻辑互连和逻辑元件的几何位置有关。由于在布线之前无法准确评估放置解决方案的质量，导致设计流程中的反馈循环很长，因此现代布局需要在早期阶段减少布线拥塞(Congestion)并提高可达性(Routebility)\nWL估计方法 # Global Placement # 通常，全局布局（Global Placement）涉及宏布局（Macro Placement）和标准单元布局（Standard Cell Placement）。\n输入:网表\n优化目标:HPWL线长最小(最基本)…\nDetail Placement # 详细布局（Detailed Placement）包括合法化（legalization），线长（wirelength）和可达性的细化（routability refinement）\nhistory # 参考 # 2021-Place-YuBei-slice.pdf "},{"id":7,"href":"/zh/docs/Digtal/Routing/routing2/","title":"Routing","section":"Physical Design","content":" 简介 # GR \u0026amp; DR # Routing is a critical yet complex phase in the implementation process of integrated circuits (ICs), often necessitating considerable time and effort. Given its complexity, the routing process is typically divided into two stages: global routing and detailed routing. Global routing, the initial stage, establishes coarse-grained wire paths for signal nets, thereby providing valuable guidance for the subsequent detailed routing stage, enhancing its efficiency. Detailed routing, on the other hand, focuses on identifying valid physical paths, primarily within the routing guides set by global routing, while taking into account design rule constraints\nRouting is usually divided into global routing (GR) and detailed routing (DR) –cite–\u0026gt; C. J. Alpert, D. P. Mehta, and S. S. Sapatnekar, Handbook of Algorithms for Physical Design Automation. CRC press, 2008. Routing is usually divided into global routing (GR) and detailed routing (DR) [2]. Global routing serves as a fast routing planning to generate guidance for detailed routing to reduce the search space of each net. Detailed routing then takes the guidance as input and finishes the physical wiring to connect pins in each net. Global routing is also used for routability estimation at early design stages like placement [3–9]. With growing design scales and complexity, it becomes increasingly challenging for global routing to resolve routing overflow within a short time. Therefore, the quality and efficiency of global routing is critical to design closure, as it impacts both its proceeding and succeeding design stages.\nbackground # 输入 # 输出 # 优化指标 # 约束 # 线网连接正确性 布线障碍 版图设计规则 ：金属线的最小宽度（min-width）；金属线间及金属线与布线障碍间的最小线间距（min-spacing）；一条金属线的最小面积（min-area），当金属线的宽度固定为最小宽度时 ，最小面积约束也被称作最小长度约束 Global Router # 概念 # 甚至不需要考虑大部分几何级问题 ，其布线模型的建模较为简单 ，即使在具有数以万计的区域的芯片版图上布线，也只产生较低的时间开销\nroutes every net with only two pins under design constraints turns out to be an NP-complete problem –cite–\u0026gt; M. Kramer and J. Van Leeuwen. The complexity of wirerouting and finding minimum area layouts for arbitrary vlsi circuits. Adv. Comput. Res, 2:129–146, 1984 term # net order: 串行\nOF: over flow\nconjointly： 并行\nguide: 在GR中就是布线通路，GR最终的输出结果\npreferred routing direction : 比如第一层水平优先，第二层垂直优先\nchallenge # advance GR are GPU-Accelerate-based now，main challenge are:\nGPU memory is limited This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored 技术方向 # DP base-layer assignment\nCUGR, InstantGR start use GPU accelarate RL-based\nslow 理论上DRV会很小 generative model\nsuch as: CNN-based, PRNet, Hub Router Actually, global routing is a combinatorial problem and can be formulated as a 0-1 integer linear programming (0-1 ILP) problem it is still NP-complete 另一种分类：来自 HeLEM-GR\ngrid models\n2D\nMany routers such as FastRoute 4.0 [10], BoxRouter 2.0 [11], NCTU-GR 2.0 [12], and SPRoute 2.0 [13] are based on 2D grids (a.k.a 2D routers), which perform layer assignment after routing all nets on the 2D space\n3D\nOther routers such as FGR [14] and CUGR [15] try to directly route on 3D grids to simultaneously determine the routing paths and layers for each net\nhybrid\ngenerates initial routing results on 2D grids and then refines it on 3D grids. TritonRoute-WXL routing kernels\nLee’s algorithm [17] is the basic maze routing kernel in many routers, but it is very time-consuming. routing schemes\n问题建模 # 3d method:\n2D method:\ngcell 定义在.def 文件中\n输入\n输出\n约束\n优化指标\n全局布线要在给定布线资源的情况下 ，优化线长、通孔数及关键线网时延等目标函数\n线长、通孔数、溢出数量、运行时间\nFasterRoute4.1 in OpenROAD # 结构 # fastroute # FastRouteCore # vector\u0026lt;FrNet*\u0026gt; nets_; vector\u0026lt;StTree\u0026gt; sttrees_; // the Steiner trees run() gen_brk_RSMT() for (const int\u0026amp; netID : net_ids_) rsmt = stt_builder_-\u0026gt;makeSteinerTree(…) Tree tree = pdr::primDijkstra(x, y, drvr_index, alpha, logger_); flute_-\u0026gt;flutes(x, y, s, accuracy) steinerTreeVisualization getOverflow2Dmaze() getOverflow2Dmaze fluteNormal(rsmt) layerAssignment() StTreeVisualization()//2d or 3d getOverflow2D routeLAll convertToMazeroute // debug mode Rectilinear Steiner Tree before overflow iterations SteinerTreeBuilder # FrNet # odb::dbNet* db_net_;\nvector\u0026lt;int\u0026gt; pin_x_;\nvector\u0026lt;int\u0026gt; pin_y_;\nvector\u0026lt;int\u0026gt; pin_l_;//layer\nfloat slack_;\nstd::unique_ptr\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt; edge_cost_per_layer_;\nvoid addPin(int x, int y, int layer)\nStTree # vector\u0026lt;TreeNode\u0026gt; nodes // The nodes (pin and Steiner nodes) in the tree. vector\u0026lt;TreeEdge\u0026gt; edges TreeNode # int16_t x, y; // position in the grid graph int nbr[3]; // three neighbors int edge[3]; // three adjacent edges TreeEdge # stt # Flute # initLUT（）\n主要是读取.dat文件 flute()\nflutes()\nflutes_RDP flutes_ALLD SteinerTreeBuilder # unique_ptr\u0026lt;flt::Flute\u0026gt; flute_ Tree # int deg; // degreeStTree int length; // total wirelength vector\u0026lt;Branch\u0026gt; branch; // array of tree branches void printTree(utl::Logger* logger) const; int branchCount() const { return branch.size(); } Branch # int x, y; // starting point of the branch int n; // index of neighbor odb # dbNet pdr # Tree primDijkstra(const vector\u0026amp; x,const vector\u0026amp; y, const int driver_index, const float alpha, Logger* logger) ListGraph graph get_nearest_neighbors buildSpanningTree steinerize makeTree makeTreeRecursive lemon # ListGraph # CUGR # cuhk-eda/cu-gr: CUGR, VLSI Global Routing Tool Developed by CUHK\ninstall # #还是在docker跑把，服务器上的boost版本总是搞不好。。。 apt update apt install git apt install vim apt install build-essential apt install -y build-essential gcc g++ apt install cmake apt install -y libboost-all-dev curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh #yes, opt/miniconda3, yes source ~/.bashrc git clone https://github.com/cuhk-eda/cu-gr cd cu-gr scripts/build.py -o release 报错：\nCMake Error at /usr/local/lib/cmake/Boost-1.80.0/BoostConfig.cmake:141 (find_package): Could not find a configuration file for package \u0026ldquo;boost_filesystem\u0026rdquo; that exactly matches requested version \u0026ldquo;1.80.0\u0026rdquo;.\nThe following configuration files were considered but not accepted:\n/usr/lib/x86_64-linux-gnu/cmake/boost_filesystem-1.74.0/boost_filesystem-config.cmake, version: 1.74.0 /lib/x86_64-linux-gnu/cmake/boost_filesystem-1.74.0/boost_filesystem-config.cmake, version: 1.74.0\nCall Stack (most recent call first): /usr/local/lib/cmake/Boost-1.80.0/BoostConfig.cmake:262 (boost_find_component) /usr/local/share/cmake-3.24/Modules/FindBoost.cmake:594 (find_package) CMakeLists.txt:39 (find_package)\nfix:\n可以使用以下命令来查看系统上安装的 Boost 版本：\ndpkg-query -s libboost-all-dev | grep Version # 对于 Debian/Ubuntu 系统 #如果您已经安装了 Boost 1.74.0，则需要升级到 Boost 1.80.0 版本。 tar -xvf boost_1_80_0.tar.bz2 cd boost_1_80_0 ./bootstrap.sh ./b2 sudo ./b2 install cmake -DBOOST_ROOT =/usr/local/ 报错：\nCMake Error: Invalid value used with \u0026ndash;target Usage: cmake \u0026ndash;build [options] [\u0026ndash; [native-options]] cmake \u0026ndash;build \u0026ndash;preset [options] [\u0026ndash; [native-options]] Options:\n= Project binary directory to be built. --preset , --preset= = Specify a build preset. --list-presets = List available build presets. --parallel [], -j [] = Build in parallel using the given number of jobs. If is omitted the native build tool's default number is used. The CMAKE_BUILD_PARALLEL_LEVEL environment variable specifies a default parallel level when this option is not given. --target ..., -t ... = Build instead of default targets. --config = For multi-configuration tools, choose . --clean-first = Build target 'clean' first, then build. (To clean only, use --target 'clean'.) --resolve-package-references={on|only|off} = Restore/resolve package references during build. --verbose, -v = Enable verbose output - if supported - including the build commands to be executed. -- = Pass remaining options to the native tool. cmake --build build --target -- -j 6 fix:\nscripts/build.py -o release -t iccad19gr#cu-gr, github 写的有问题 scripts/build.py -o release -t route#cu-gr2 run # 按照他说的，不过要自己把iccad19的benchmark放到toys/iccad2019c/下\nFastRoute # install # #in a new ubuntu:22.04 container apt install build-essential apt install gcc apt install libboost-all-dev apt install cmake apt install tcl-dev apt install swig apt install git apt install bison apt install flex git clone --recursive https://github.com/The-OpenROAD-Project/FastRoute4-lefdef cd FastRoute/ cmake . make PARALLEL=nthreads debug # /root/FastRoute-master/third_party/OpenDB/include/opendb/ZInterface.h:38:10: fatal error: tcl.h: No such file or directory 38 | #include \u0026lt;tcl.h\u0026gt; | ^~~~~~~ compilation terminated.\n#cmake 中加上以下两句 include_directories(/usr/include/tcl8.6) link_directories(/usr/lib) CUGR 2.0 # InstantGR # model # database # layer db::net database_cuda # cudb::net flute.hpp # readLUT robin_hood.h # 一个高性能的哈希表实现库 开源 这个库在高性能计算场景（如本项目的集成电路布线）中特别有用，因为它能提供更快的查找和插入操作，同时保持较低的内存占用。 主要优势： 比标准库的 std::unordered_map 性能更好 内存使用更高效 缓存友好的设计 开放寻址法解决冲突 支持异构查找 flow # 开启时钟\nprogram_start = std::chrono::high_resolution_clock::now();\nread input files\nread()\n输入： cap_file_name[]: 容量文件的路径\nnet_file_name[]: 网络文件的路径\n输出： 代码将读取的数据存储在类的成员变量中：\nlayers[]: 存储每层的信息\ncapacity[][][]: 3D数组存储容量信息\nnets: 存储所有网络信息\n其他相关的网格和坐标映射信息\nreadLUT(\u0026quot;POWV9.dat\u0026quot;, \u0026quot;POST9.dat\u0026quot;)\nbuild_cuda_database() cuda相关变量初始化\n先处理单pin的net（有一些两个pin重叠，二维变成单个pin）\n设置两个核函数cuda共享内存大小\ncudaFuncSetAttribute\n具体有什么用？\n对非单Pin的net(nets2route)进行FLUTE建立MSRT\nFLUTE:\nnet.construct_rsmt() my_flute(unordered_set \u0026amp;pos)` flute::flute(cnt, x.data(), y.data(), 3); 最后处理得到水平和垂直segments\nsort, 对非单Pin的net(nets2route)进行根据hpwl从小到大排序\ngenerate_batches_rsmt(nets2route)\nsort, 对每个batch根据net数量从小到大排序 //这个有什么用？\n可以问问\n根据sort后的batches，重新对每个net依次排列到nets2route\nDFS获取DAG图：Routing DAG,\n得到一个segment排序\n对每一个batch, 开启L_shape\nLshape_route_cuda\u0026lt;\u0026lt;\u0026lt;BLOCK_NUM(batches[i].size()), THREAD_NUM\u0026gt;\u0026gt;\u0026gt; (batches[i].size(), batch_cnt_sum[i], node_cnt_sum, nodes, par_nodes, dist, from, layer_range, global_timestamp);\ninstall # compile directly\ndebug # contest # ISPD 07 # ISPD 08 # ICCAD 19 Contest Problem C: GR use Real world design and evaluate by DRouter # 2019 CAD Contest @ ICCAD\n也给了后端详细布线器DrCu,和用于评估结果的脚本\n用的 ISPD2018/19 的数据\n输入：\n输出：\nispd24的比赛是要via的\nevaluate:\nISPD’24 Contest: GPU/ML-Enhanced Large Scale Global Routing Contest # background:\ndata\nevaluate：\n和 ICCAD19 很像\nscale 越大权重越大\n限制：\n最好结果：\n越小越好\ndesign WL cost via cost overflow cost raw score runtime /s median runtime /s scaled score Ariane133_51 9335109 3060400 10369862 22765372 4 11 22100882 Ariane133_68 9443754 2981836 7825647 20251238 8 12 20014313 BlackParrot 58347098 19740536 35450029 113537664 27 70.5 110393434 Nvdla 21345766 4630872 23933347 49909986 4 20 47592238 MemPool-Tile 8407884 3425828 3569040 15402753 3 10 14867672 MemPool-Group 262817992 76146200 70345580 409309772 81 375 391210938 MemPool-Cluster 1094650057 268335040 300359611 1663344708 478 2048 1593513066 Tera-Cluster 12190406272 1542639724 6705414754 20438460750 4310 4584 20402113329 issue:\nISPD25 Contest: Performance-Driven Large Scale Global Routing # Background # ISPD2024 竞赛虽然简化的输入/输出格式和评估指标提高了来自不同背景的参与者对比赛的可访问性，但它们可能会在性能建模中引入不准确性。ISPD2024 竞赛中使用的输入文件 缺少时序和功率信息。仅基于带宽和路由溢出的指标不能准确地模拟定时性能和功耗。例如，最小化总长度并不一定会减少时间关键路径上的延迟。Wires on different metal layers exhibit varying resistance, resulting in different delays and power consumption. Additionally, the impact of vias on delays is difficult to model with simple metrics. Inter-wire coupling capacitance can also cause significant discrepancies between actual and nominal timing responses and power consumption\nProblem Formulation # In global routing, a 3D routing space is defined using global routing cells (GCells), created by a regular grid of horizontal and vertical lines. This configuration results in the formation of a grid graph where each GCell is treated as a vertex and edges connect adjacent GCells within the same layer (GCell edges) or between GCells in neighboring layers (via edges). The global router needs to establish a concrete path for each net within the grid graph and optimize the routability, timing and power.\nFor each testcase, the global router starts with a placed design, and generates a global routing solution. The global routing solution is evaluated by OpenROAD, which reports timing, power, and routing congestion. Additionally, the runtime and memory efficiency of the global router are critical factors.\n文件 # 输入\nFor each testcase, two sets of input files are provided: industry-standard files and simplified files.\nThe industry-standard files include DEF, LEF, LIB, and SDC files. The DEF file contains definitions for CORE, ROW, TRACKS, and GCELLGRID, along with placed COMPONENTS and unrouted NETS. Similar to the ICCAD2019 global routing contest, GCells are specified using the definition from the DEF GCELLGRID section. The LEF file includes MACRO definitions and technology information. The LIB files offer timing and power data for library cells, while the SDC files provide timing constraints. These files serve as the raw input, allowing contestants to perform the most accurate routing resource and performance modeling.\nFor each circuit, we also provide a set of simplified input files, which include a routing resource file (with a .cap extension) and a net information file (with a .net extension). The routing resource file follows the same format as used in the ISPD2024 contest, while the net information file is an extended version of the one used in ISPD2024. The routing resource file offers a detailed representation of the GCell grid graph and its available routing resources. The net information file provides the access points for all the pins within each net, along with the pin names and pre-routing stage slack estimates. These slack estimates provide a rough timing view of the circuit and enable contestants to perform net-based timing optimization. The simplified input files enable contestants to quickly engage with the contest and facilitate framing global routing challenges as mathematical optimization problems.\n输出 镜像使用：\ndocker run -it ispd25:latest /bin/bash\t#启动 Detail Router # 概念 # 问题建模 # Contest # ISPD-2018 # ISPD-2019 # 算法 # 最小树算法 # 矩 形 最 小 斯 坦 纳 树（rectilinear steiner minimal tree，RSMT） 一般会先基于 Pin 生成最小树，分解最小树为 2-Pin(两端口) wire 然后再进行后续处理\nRSMT 和 RMST 的区别\n在图论和计算几何中，RSMT（Rectilinear Steiner Minimum Tree）和 RMST（Rectilinear Minimum Spanning Tree）是两种不同的树结构，主要用于解决不同类型的最小树问题。以下是它们之间的主要区别：\n1. 定义 # RSMT（Rectilinear Steiner Minimum Tree） RSMT 是一种最小生成树，允许在树中添加额外的点（称为 Steiner 点），以减少连接给定终端（节点）所需的总边长。RSMT 的目标是最小化连接所有终端的总路径长度，使用的是矩形距离（L1 距离或曼哈顿距离）。 RMST（Rectilinear Minimum Spanning Tree） RMST 是一种最小生成树，连接给定的终端节点，但不允许添加额外的点。RMST 的目标是找到连接所有终端的最小边长树，同样使用矩形距离。 2. 额外点的使用 # RSMT 允许在树中添加额外的 Steiner 点，这些点可以帮助优化路径，减少总边长。 RMST 仅使用给定的终端节点，不允许添加额外的点，因此可能会导致较长的连接路径。 3. 应用场景 # RSMT 通常用于更复杂的网络设计问题，例如 VLSI 设计和电路布局，其中需要优化连接以减少布线长度和提高效率。 RMST 更常用于简单的网络连接问题，适用于需要在给定节点之间建立最小连接的场景。 4. 计算复杂性 # 计算 RSMT 通常比 RMST 更复杂，因为需要考虑如何有效地选择 Steiner 点以优化树的结构。 RMST 的计算相对简单，因为只需连接给定的终端节点。 相关文献\nFLUTE # 介绍 # 问题阐述\n一个常见的steiner tree算法 9端最快，9端一样也是次优解 基于查找表 诞生与2004 ICCAD, ISPD 05 和 TCAD 07 有相关优化 版本信息\n基本定义 # Degree\nDegree of a net is the number of pins in it\nHanan grid\n只考虑节点是4个方向\nWL\nPOWV\n使用WV的好处\nposition sequence\ny方向是1~4\nposition sequence从x=0开始数\nflow # POWVs Generation ： boundary compaction # Net Breaking for High degree Net\nFor nets with degree \u0026gt; D, recursively break net until degree \u0026lt;= D\n第一步\n查看满足1，3象限 或者2，4象限的情况\n还不能拆成9degree以下的话，使用Net Breaking Heuristic：\nA score for each direction and each pin：\nfor Pin_r in Net:\nS1:\nS2:\nS3:\nS4:\nAccuracy Control Scheme # 文件介绍 # flute.[ch]\n查找表\nPOWV9.dat \u0026ndash; The lookup-table of optimal POWVs up to degree 9. POST9.dat \u0026ndash; The lookup-table for optimal Steiner tree up to degree 9. (Note that it is formerly called PORT9.dat.) TCAD 07 有相关优化（net breaking and merging techniques）\nflute_mst.c \u0026ndash; The net breaking and merging techniques described in the VLSIDAT 08 paper. dist.[ch], dl.[ch], err.[ch], heap.[ch], mst2.[ch], neighbors.[ch], global.h \u0026ndash; Utility functions used by flute_mst.c evaluate\nflute-net.c – A program to evaluate the wirelength of a net. It takes input from stdin as a list of points. rand-pts.c \u0026ndash; A program to generate a list of random points. bookshelf\nflute-ckt.c \u0026ndash; A program to find FLUTE and half-perimeter wirelength of a circuit in bookshelf format. memAlloc.[ch] \u0026ndash; Functions for flute-ckt.c to allocate memory. ibm01/ibm01.* \u0026ndash; ibm01 bookshelf files that can be read by flute-ckt.c 实验结果 # 模型 # 输入\n结构\n输出\n参考 # pdfs.semanticscholar.org/01a6/716144fcd0b88f607e718b78c909bfca415e.pdf FLUTE 模式布线 # 单调\nFastRoute 4.0 的 3-bend Routing\n迷宫算法 # 概念 # 李氏算法 # 有点像 BFS\nA*算法 # 往往是串行的，慢\n往往需要多个 pin 的连线拆成一对一对，导致：\n线搜索算法 # Hetzel 算法\npattern + maze # 线序选择 # 对于串行布线算法, 布线顺序对最终布线质量的影响很大\n以上几种启发式的线序选择策略往往不能完全避免溢出。拆线重布（rip-up and reroute） 策略在初次布线完成后 ，对发生溢出的拥塞区域的线网进行拆除 ，并迭代地 调整线序多次重新布线 ，直到溢出不再减少 ，或达到运行时间限制为止。\n拆线重布 # rip-up and reroute\n层分配 # 并行布线算法 # 整数线性规划 # 线性规划 # 数据集 # 文件定义 # "},{"id":8,"href":"/zh/docs/Digtal/Routing/routing1/","title":"Routing1","section":"Physical Design","content":" 介绍 # 随着IP复用，业界一度试图使用IP内部资源进行布线，但此举可能引发噪声和转换电压过大，因此绕障策略在布线算法中发挥着重要的作用。\n曼哈顿结构以及非曼哈顿结构 # 总体布线的布线算法主要基于曼哈顿结构以及非曼哈顿结构两种，非曼哈顿结构因其更强的布线优化能力受到越来越多研究人员的关注。布线互连结构可分为曼哈顿结构和非曼哈顿结构。曼哈顿结构的布线方向只能是水平走线和垂直走线两种,而非曼哈顿结构的布线方向则更为多样化,主要包括走线方向为 **0°、90°和士45°**的X结构以及走线方向为 0°、60°和 120°的Y结构。随着系统级芯片(System-on-a-Chip,SoC)设计概念的出现和制造工艺的不断发展,**互连线的延迟对 VLSI设计的影响越来越大,同时互连线的不断增长会降低芯片的速度,造成过高的功耗以及增大噪声,**这要求更有效的互连线线长优化和更强的电路性能。但基于曼哈顿结构的相关物理设计阶段在优化互连线线长时限制了相关策略的优化能力。为优化芯片的整体性能,相关研究人员开始尝试基于非曼哈顿结构的布线。\n非曼哈顿结构的数学基础是λ-几何学理论\n(1)当λ=2时,布线的方向为ix/2,走线方向包括 0°和 90°,对应传统的曼哈顿结构,亦称为直角结构。 (2)当λ=3时,布线的方向为 iπ/3,走线方向包括 0°、60°和120°,称为Y结构。 (3)当λ=4时,布线的方向为 i/4,走线方向包括0°、90°和士45°,称为X结构。已经得到工艺支持\n意义 # 物理设计过程是EDA的主要处理对象，是人工最易出错的\n当前,超大规模集成电路(Very Large Scale Integration Circuit,VLSI)设计在许多高科技电子电路的发展中起着至关重要的作用。当前集成电路(IntegratedCircuit,IC)产业向超深亚微米工艺不断推进,芯片的集成度进一步提高,一块芯片上所能集成的电路元件越来越多,VLSI是将数百万个品体管集成到单个芯片中形成 IC 的过程。这一市场趋势对**物理设计(Physical Design,PD)和物理验证(Physical Verification,PV)**提出了许多挑战。以 VLSI为基础的电子信息产业的发展,对我国国民经济的发展、产业技术创新能力的提高以及现代国防建设都具有极其重要的意义。\n物理设计是VLSI构建流程中最为耗时的,其设计好坏将影响芯片的最终性能,包括时延特性,电能消耗、电路稳定性等。\n近年来 ，集成电路领域发展越来越迅猛 ，晶体管数量随集成电路制造⼯艺发展逐年增加 ，芯片内包含的逻辑门数量急剧提升 ，这给集成电路设计带来了巨大的难题。由于超大规模集成电路（very-largescale integration circuit，VLSI）逻辑的高度复杂性 ，其物理设计往往需要使用计算机辅助设计⼯具来完成。这就向电子设计自动化（electronic design automation，EDA）⼯具提出了严峻挑战\n在物理设计过程中 ，布线是极其重要的一环 。布线⼯作占据了 EDA 过程的大部分时间 ，甚至在大部分情况下 ，自动布线的结果还需要设计人员在后期手⼯调整。具备优秀的布线速度及高布线质量的布线器对缩短芯片设计周期有着至关重要的作用 。\n布线 # 在物理设计中需要采用电路划分方法将复杂庞大的电路系统分解至合理小的电路子系统;其次,在电路划分后,布图规划和布局步骤则是将不同形状和大小的单元或模块合理地放置到芯片的不同布线区域,同时满足芯片固有的一些相关几何约束;再次,布局阶段确定模块和引脚各自的位置,在此基础上经总体布线后,将每条待绕线的线网的各部分合理分配到芯片中的各个布线通道区;最后,由详细布线得到各个布线通道区的实际绕线。\n模型输入输出 # 输入 # cell, pin\u0026rsquo;s position netlist graph(connection relation) 设计工艺：多少层，via几何形状信息，各种drc 部分关键线网延时信息 wire和via的电气特性 输出 # 一个尽可能满足约束条件并更少得需要人⼯调整线网的布线结果\n网表内各线网的连接⽅式 ，包含金属线及通孔的几何描述信息\n约束 # 线网连接正确性 布线障碍 :指布线过程中被占用的区域，包括逻辑单元及芯片版图中的布线障碍 ，以及部分已布线网 ，如电源线网和时钟线网等 版图设计规则 :主要由制造⼯艺决定。制造厂商在制造过程中 ，为满足芯片最基本的可制造性 ，尽可能让芯片的设计可用 ，根据现有的制造技术设计了种种版图设计规则。设计规则违反（design rule checking violations，DRC）的数目很大程度上代表了布线质量的高低。 主要包含： 金属线的最小宽度（min-width）； 金属线间及金属线与布线障碍间的最小线间距（min-spacing）； 一条金属线的最小面积（min-area），当金属线的宽度固定为最小宽度时 ，最小面积约束也被称作最小长度约束 总体布线 # 又称概略布线,全局布线\n总体布线负责合理将每条线网的各部分分配到各个布线通道区中(也就是分配布线资源)并明确定义各布线问题\n总体布线的结果对详细布线的成功与否起到决定性作用,同时总体布线严重影响最后制造出来的芯片性能。\n一个经典图论问题\n整个芯片被分为多个区域 ，并将线网的连接关系对应到区域上 ，在区域间连线。由于全局布线不需要考虑版图设计 规则的约束 ，甚至不需要考虑大部分几何级问题 ，其布线模型的建模较为简单 ，即使在具有数以万计的区域的芯片版图上布线，也只产生较低的时间开销\n总体布线中首先将可布线区域划分成多个小格,每个格的布线资源使用带容量的边来表示,所有布线资源由一个网格图表示;再确定一个线网所占用网格图中的边,即线网的大致走线,将各线网合理地分配到各个网格中,以确保尽可能高的布通率。\n**总体布线图(Global Routing Graph, GRG)**将布线区域、每个区域内的布线容量、布线区域内的引脚信息以及不同布线区域之间的相互关系等信息抽象为一张图。不同的设计模式产生多种布线图模型,常见的布线图模型主要包括网格图模型、布线规划图模型以及通道相交图模型\n即使是最简单的问题,如一组两引脚线网在拥塞约束下布线,也是一个NP 完全问题。\n全局布线的主要目标是为后续的详细布线提供指导 ，从而降低布线问题的复杂程度 ，减少整体的时间开销。作为整个布线任务中多种优化目标的主要影响因素 ，全局布线要在给定布线资源的情况下 ，优化线长、通孔数及关键线网时延等目标函数\n评价全局布线算法的主要指标有线长、通孔数、溢出数 量、运行时间\n布线图模型 # 网格图模型 # 一个顶点表示一个总体布线单元(Global Routing Cell,GRC),GRC之间的连接关系则由水平边和垂直边表示。\n对于给定的线网集合,则将它们的引脚集合按照其所在的总体布线单元,映射到该总体布线单元对应的顶点上\n每一个全局布线单元（GRC)被视作全局布线问题中的一个点 ，相邻近的单元所代表的点之间具备一条有容量的边 ，对应相邻单元间的边界 ，这条边的容量代表能穿过此边界的金属线的最大数目 。因此 ，可以通过各边的容量与穿过边的金属线数量估计全局布线的资源拥挤程度。\n布图规划图模型 # 通道相交图模型 # 算法 # 最早用于解决总体布线图上的最短路径问题的是1959年出现的Diikstra算法,该算法的时间复杂度为 O(n^2^)\n后来发展为迷宫系列算法，缺乏寻找最优解的能力，不适用VLSI\n多引脚网分解 # 多引脚线网分解常用于总体布线算法。具有两个以上引脚的线网通常被分解成两个引脚的子网,然后每个子网的点对点布线以某种串行方式执行。这种线网分解是在总体布线开始时执行的,这会影响最终布线结果的质量。许多总体布线都采用多引脚线网分解。分解多引脚线网的两种流行方法是RSMT构造和最小生成树(Minimum Spanning Tree,MST)构造。RSMT 通常提供较短线长的树状拓扑结构,而 MST 由于产生更多的工形双引脚线网而提供更大的灵活性。\n最小树算法 # Steiner 最小树算法 # 多端点线网的总体布线可定义成寻找 Steiner 树问题,精确算法、传统启发式算法、计算智能方法都可用于求解 Steiner 树。\n在VLSI总体布线问题中,多端线网的总体布线问题是寻找一棵连接给定引脚集合的布线树问题,而 Steiner 最小树相对于其他方法所得的布线树来说具有更小的布线树总线长。因此,Steiner最小树被看作总体布线问题中多端线网的最佳连接模型,并且在总体布线图上的Steiner 最小树算法是所有总体布线算法的基础。\n精确算法包括动态规划技术、拉格朗日松弛法、分支界限法等。虽然从理论上能够得到问题的精确解,但是问题规模越大,精确算法越难求解问题。继而研究工作开始转向启发式策略。遗传算法、蚁群算法、鱼群算法、粒子群优化算法等计算智能方法在求解 Steiner 问题中展示出了广阔的应用前景。\n近年来,随着计算能力的增强,加之高性能电路的设计需要,版图设计技术也将随之改进。出于增强电路的性能的目的,研究人员提出新型互连结构,即非曼哈顿互连结构,非曼哈顿结构 Steiner 树则应运而生。\n然而,精确算法受其复杂度限制不适用于求解非曼哈顿结构 Steiner 树这类NP难问题,而贪心策略致使传统启发式算法极易过早收敛。据所查找的资料文献中,目前将计算智能方法应用到求解该NP难问题的研究工作还较少。\n整数线性规划布线 # 慢\n拆线重步 # 在确定了一组线网的初始布线后,通常会发现一些布线资源被过度使用了。然后,现有的布线被拆开,重新分配到一个迭代修复框架中,这个框架被称为“拆线重布”。现代整数线性规划工具帮助基于整数线性规划的总体布线在数小时内成功完成数十万条布线。然而**,商业EDA 工具需要更大的可扩展性和更少的运行时间**。在布线阶段,如果一个线网无法布线,通常是由于物理障碍或其他布线线网占用了它的路径。核心思想是允许临时违规,直到所有线网都被布线。也就是说,迭代地拆开一些线网,并以不同的方式重新对它们布线,以减少违规的数量。如果一次只处理一个网,那么这个策略就是串行法,所以线网的串行处理对最终解的质量影响很大。 文献[31]对于每一个违规的线网定义了拆线重布的成功率,并且只对最有希望改进的线网重布线。然而**,若一个线网在没有违规的情况下不能布线,那么成功率需要重新计算。这是非常昂贵的,尤其是对于大规模的设计。**拆线重布通常与其他总体布线方法相结合,作为进一步提高布线质量的后处理步骤。\n协商拥塞布线 # 层分配问题 # 层分配在可布线性、时序性、串扰性和可制造性方面起着至关重要的作用。如果特定层分配的导线数量过多,则会加剧拥塞和串扰。此外,如果总体时序关键线网被分配到较低层,则时序由于导线宽度/间距较窄而恶化。差的层分配产生的大量通孔,其比线需要更大的面积和更宽的间距,进而导致可布线性/引脚访问问题。对于纳米设计,最小化通孔数量尤为重要,因为通孔故障是关键的可制造性问题之一。层分配是多层总体布线中的关键步骤,因为它将二维总体布线的结果映射到原始的多层解空间。现代集成电路或芯片通常是多层结构。在布线时,大多数布线器通常不会在三维空间中直接布线。相反,它们在二维平面上布线,然后通过层分配技术将二维布线结果恢复到三维空间。有些工作是基于动态规划实现的,此外,BoxRouter 2.0实现了一种复杂的线性规划技术,可以根据二维投影恢复三维布线,并根据三维布线结果优化二维布线器。**层分配的目标通常是保持二维总体布线的总溢出,然后最小化通孔数量。**在层分配中考虑天线效应,通过适当地将导线分配到较高的金属层(不一定是顶层),可以有效地减少天线违规\n一个k层的布线区域可以被划分为一大批的总体布线块并建模成为k层网格图G^k^(V^k^,E^k^)。其中k表示布线层的数量,V ^k^表示第k层网格总体布线单元的集合,E^k^表示第k层的网格布线边,其中每条边表示相邻布线块的边界。相邻层的连接边表示通孔。一条网格边的容量定义为可以经过相邻布线块的布线轨道数。\n层分配定义：\n串行和并行方法 # 串行 # 布线多个线网的最原始和最简单的策略是选择特定的顺序,然后按该顺序布线线网。这种方法的主要优点是:在布线当前线网时,可以知道并考虑前期布线线网的拥塞信息。例如,在将多引脚线网分解成两引脚线网的早期算法中,使用绕障迷宫布线或线路探测布线等方法来对每个线网布线。在这些方法中,单元边界对路径搜索开放,直到所有的路径都被先前考虑的线网占据。在这一点之后,边界被视为障碍。顺序法的缺点是解的质量很大程度上取决于线网的处理顺序,很难找到好的顺序。在任意特定的顺序下,由于过多拥塞,很难对后期的线网布线。\n此外,没有反馈机制允许这些线网将信息反馈给前期布线的线网,以便为后期布线的线网留下一些区域。文献[109]提到没有一种单一的线网排序方法始终表现良好。尽管对于线网的排序问题上存在争议,但在串行布线上已经有了一些很好的研究成果,主要是通过迭代循环将后期布线的线网的拥塞信息反馈给前期布线线网\n虽然串行方法、拆线重布以及其他启发式方法在实践中可能是有效的,但是它们不能提供关于是否存在可行解决方案的具体答案。换句话说,如果这些方法不能找到可行的解决方案,不清楚这是因为可行的解决方案不存在,还是因为启发式方法的缺点。另外,当启发式方法找到可行解时,不知道解是否最优,与最优解相差多远。？\n依据预先给定的线网顺序对线网进行布线,布线过程中先布线网会抢占后布线网的布线资源,不同的布线顺序可能会生成完全不同的布线结果。早期的一项研究指出,在布线开始之前找到一个最优布线顺序是NP难问题,且不存在一个在所有情况下都达到最优的布线顺序选取策略叨。对所有线网同时进行布线的同时布线算法可以避免线序对布线结果的影响。\n策略：\n按端点数量的升序布线。端点数量较多的线网往往会造成内部空间的拥塞。 按线长升序布线以降低容量溢出 ，提升可布性。线长较短的线网布线范围比较小 ，灵活性有限 ，而线长较长的线网则可以在更大范围内绕路 ，寻找更优解。 按线长降序布线以降低总体时延。优先布线长较长的线网 ，降低线长较长 的关键线网对总体时延的影响 ，以提升电路的总体性能。 依据预估的拥塞程度布线 ，优先对较为拥塞的区域内的线网进行布线 并行 # 在串行方法中,路径是根据预定的顺序一次生成的。串行方法是非常快速的，但由于它们的串行性质会导致次优解。并发方法试图利用总体优化方法来解决问题。这些方法可以提供电路布线的总体视图,但需要相当长的时间。从计算复杂性的角度来看,所有网络的并发布线是一个**复杂的问题。使用整数线性规划是实现这一目标的方法之一。**事实上,总体布线问题的数学模型可以修改为 0-1整数规划问题。线性规划由一组约束和可选目标函数组成。这个函数根据约束判断是最大还是最小。约束和目标函数都必须是线性的。这些约束形成了一个线性方程和线性不等式的系统。整数线性规划是一种特殊的线性规划,其中每个变量只能取整数值且都是二进制的,故称为0-1整数线性规划。\n基于并发方法的总体布线器包括对布线区域拥塞的评估,产生了高质量的布线。另外,舍弃可能处于拥堵区域的路径,以减小整数线性规划的输入规模。\n多商品流(multi-commodity flow，MCF)算法将布线问题看作是一个多商品流问题回,并将其建模成整数线性规划(integerlinear programming,ILP)问题进行求解。\n两端线网与多端线网 # 两端线网 # 迷宫布线算法 # 及其变体 A*算法：一般通过设计开销函数来躲避拥塞。开销函数的值往往在边界上穿过的金属线数量接近及超过边容量时迅速增大[9]，迷宫布线类算法具备着极其强大的拥塞避免能力 ，可以对单个线网给出质量极高的布线结果 ，但即使通过开销函数定向减小搜索空间 ，迷宫布线类算法仍然会产生较高的时间开销\n模式布线 # 使用预先设计的模式对两端线网进行布线 ，常用的模式有 L 型（1 拐点）、Z 型（2拐点）[10]与 U 型（2 拐点 ，绕路连线） 由 于路径的搜索空间远小于迷宫布线 ，模式布线类算 法具备极快的布线速度 ，但其布线结果相对较差 。对于跨越 m × n 网格的两端线网 ，L 型模式仅在两种布线⽅式中选取代价较低的一种 ，而 Z 型模式会考虑 m + n 种不同的布线⽅式。因此 ，Z/U 型模式避免拥塞的灵活性要远大于 L 型算法 ，但相应地 ，其单个线网的布线时间复杂度更高\n单调布线 # 随布线问题复杂度的上升 ，L/Z/U 型模式布线已经不能满足问题的需求 。，其布线路径单调地向右上 （ 左 下 ）或 左 上（ 右 下 ）搜 索 ，可 以 搜 索 到 (m + n - 2)!/ (m - 1)!(n - 1)! 种布线⽅式 ，且时间复 杂度与 Z 型相同 ，为 O (mn)，但由于其走线拐点较 多，其布线通孔数会增加。\n三拐点布线（3-bend routing）， # 其路径支持最多 3 个拐点 ，且可以绕路布线。三拐点布线同样使用 O (mn)的时间复杂度 ，具备与迷宫布线相近的拥塞避免能力 ，且由于其最多使用 3 个拐点，极大地减少了通孔数\n多端线网 # 很难直接使用迷宫布线或模式布线进行求解，主流的解决⽅法是最小斯坦纳树\nsteiner最小树算法 # 给定平面上的点Steiner 最小树通过一些 Steiner 点将这些点连接起来,以获得最小的总长度。\nSteiner 最小树(Steiner Minimum Tree,SMT)作为超大规模集成电路物理设计的基本模型之一,可以应用于布图规划、布局和布线阶段。\n作为一个标准的计算机问题，业界一般将布线问题代为Steiner最小树问题\nSteiner最小树问题是一个NP难问题\nSteiner 最小树通常用于物理设计中非关键线网的初始拓扑创建。最小化线长不是时序关键线网优化的唯一日标。然而,大多数线网在布线阶段是不重要的，Steiner 最小树给出了这种线网最理想的布线形式。因此,在布局规划和布局期间,Steiner 最小树通常被用来精确评估拥塞和线长。\n对单个线网的布线,是物理设计中的一个基础问题。无论是总体布线还是详细布线,都会用到线网布线。线网布线又根据线网引脚的个数分为两引脚线网布线和多引脚线网布线。考虑到布线长度最小化,两引脚线网布线在布线图中就转换为最短路径问题,而多引脚线网布线转换为直角 Steiner 最小树(RectilinearSteiner Minimal Tree,RSMT)问题\n拥塞图与拆线重布（rip-up and reroute) # 随着问题复杂度的上升 ，全局布线的布线资源越来越紧张 ，直接进行布线会发生大量无法避免的溢出\nFastRoute[9]使用 FLUTE 算法生成的 RSMT 计算出拥塞图 ，并依据此拥塞图重新构建 RSMT\n在拥塞图的初始化阶段 ，对所有两端线网分别进行拥塞程度计算。若两端点在水平或竖直⽅向具有相同的坐标 ，则直接将拥塞图上两端点间所有的边的拥塞程度加 1.0 。 否则 ，对于两⽅向上坐标都不相同的线网 ，计算其两种可能的 L 型连接⽅式 ，并将两种可能的路径上的边的拥塞程度都加 0.5\n拥塞图的初始化阶段过后 ，由于所有 L 型连接⽅式都在拥塞程度上平均分配 ，在拥塞程度较大的区域 ，拥塞程度可能会超过其容量。为了更好地规划拥塞图的拥塞分布 ，使用一个快速的拆线重布 ，依次将各 L 型连接的两端线网提供的拥塞程度去除后 ，选择拥塞程度更小的一条路径 ，并将此路径的拥塞程度加 1.0。\n拆线重布（rip-up and reroute）策略在初次布线完成后 ，对发生溢出的拥塞区域的线网进行拆除 ，并迭代地调整线序多次重新布线 ，直到溢出不再减少 ，或达到运行时间限制为止。\n一般来讲 ，在初始布线时使用模式布线 ，这样在大量简单线网上拥有极快的布线速度 ，在拆线重布阶段 ，使用迷宫布线类算法 ，或时间复杂度较高的模式布线算法 ，以尽可能地提升重布线网的灵活性 ，并减少溢出次数 ，从而在整体的运行速度和布线质量间取得平衡\n优化目标 # 主要是以减小通孔数量，还要考虑时延问题\n随着器件尺寸迅速缩小,互连延迟对芯片性能产生了至关重要的作用。因此，最小化线路长度和延迟变得越来越重要。由于互连延迟已成为决定系统性能的主要因素,仅考虑拥塞已经不够。在布线过程中,加入时序约束和功耗约束更符合实际工业制造,无论是理论研究还是实际生产都具有重要意义。\n主要研究方向 # 减少拥塞数和溢出数 考虑延时、串扰、拥塞等优化目标 非曼哈顿结构 并行 总体布线器 # ISPD举行的 VLSI 总体布线算法竞赛中,涌现出了: [FGR]( https://web.eecs.umich.edu/~imarkov/pubs/conf/iccad07-fgr.pdf#:~:text=routing technologies and outperform the best), BoxRouter 2.0, [GRIP]( https://jlinderoth.github.io/papers/Wu-Davoodi-Linderoth-10-PP.pdf#:~:text=GRIP: Global Routing via Integer Programming), NCTU-GR2.0, [NTHU Route 2.0]( https://www.cs.nthu.edu.tw/~tcwang/nthuroute/#:~:text=NTHU-Route 2.0 is a fast and)\n到目前(2022.05)为止，性能最好的几款布线器分别是NTHU-Route20、FastKoute 4.NCTU-GR 2.0和 MGR。NCTU-GR2.0在所有学术布线器中性能最好,它使用两种有界迷宫布线算法(最优有界迷宫布线和启发式有界迷宫布线),这两种算法的布线速度比传统的迷宫布线算法快得多。此外,串行总体布线算法,在多核平台上开发了并行多线程总体布线器。MGR是一款多级3D布线器,运行速度比传统3D布线器快得多。近两年来,研究者们尝试采用基于机器学习的方法解决总体布线问题。\n时序驱动的总体布线器TIGER\nFastRoute 1.0 # 串行\n使用steiner结构避免迷宫路径\n实现过程 # # FastRoute 2.0 # 串行\n# FastRoute 3.0 # 串行\n详细布线 # 每个通道区中的最终布线将由详细布线来实现\n详细布线是在尽量遵守总体布线的结果导向的前提下寻找每个布线片段的具体轨道位置,并绕开拥挤区域,同时尽可能满足一些基础的布线设计规则\n在全局布线完成后 ，整个芯片的布线区域中较粗粒度的连接⽅式已经初步确定 ，但全局布线中GCell 之间的连接还不能直接表示成金属线 ，需要对GCell 之间的连接进行轨道分配 ，也是详细布线的前置步骤之一。此后 ，详细布线要在局部范围内满足线网连通率、设计规则违反等关键约束 ，并尽量降低线长和通孔数。\n现代 VLSI 主流的布线策略为区域布线 ，布线过程中依据全局布线网格将整个芯片的布线区域分割成多个详细布线窗口（detail routing window），每个详细 布 线 窗 口 可 由 m × n 的 GCell 组 成（ 一 般 取m = n），更大的详细布线窗口会导致更大的时间和内存开销，但可以改善布线的质量。\n详细布线的布线图 ，即寻路算法的搜索空间，主要有两种构建⽅式：基于网格的（grid-based）和无网格的（gridless） 。\n无网格布线允许金属线放置在布线区域的任意位置上 ，具备较高的布线灵活性。其在每个金属层上 ，使用树结构分割金属层上的几何形状[27]，随后使用瓦片结构[28]或连接图[29]构建路径搜索算法的搜索空间。 由于无网格布线算法会产生较大的时间开销 ，大部分布线算法都使用布线网格构建搜索空间。\n举例 # 算法 # 大多数是串行算法，为了弥补线网顺序对布线结果的影响,串行布线通常采用拆线重布的方式进一步精炼布线结果,可快速获得质量较好的布线方案\n详细布线算法在给定布线网格中找到一个合法的布线路径\n最短路径问题\n李氏算法 # 老旧\nA星算法 # 李氏算法的加速版本\nGDRouter # 提出一个结合总体布线方法和详细布线方法的布线器,从而获得包含总体布线和详细布线的完整布线结果。\nAlgorithms and Data Structures forFast and Good VLSl Routing # 一个详细布线器，包含快速网络和形状网络结构两种数据结构\nDetailed routing algorithms for advancedtechnology nodes # 最短路径算法未能寻找出合理的布线方案时,提出了一种多标签的最短路径算法，用于计算一些不违反设计规则的路径。\nMCFRoute\u0026amp; A_Multicommodity_Flow-Based_Detailed_Router_With_Efficient_Acceleration_Techniques # 设计了一种基于多商品流模型的并行详细布线算法,同时对多个线网进行布线。但是这类算法并未考虑到时延优化问题且时间复杂度高。\n轨道分配问题 # 是全局布线与详细布线的中间步骤\n全局布线生成的布线结果仅仅完成了 GCell 级的连接 ，连接的路径被称为线段（segment）。在轨道分配阶段中 ，segment 特指没有几何形状及位置信息的线段 ，只表示 GCell 间的连接关系。而轨道分配算法中考虑其实际几何形状 ，更贴 近详细布线中金属线的线段被称作 iroute\n在全局布线网格中 ，水平（ 竖直 ）⽅向的一行（列）GCell 共同构成一个面板（panel），其⽅向与对应布线层的优先走线⽅向一致，如图 4 所示。每个面板由多条布线**轨道（track）**构成 ，轨道的数量与全局布线边的容量相同。将所有线网的 iroute 都分配至轨道上 ，并保证一个面板内不同线网的各个 iroute 在同一轨道上没有重叠，是轨道分配⼯作的主要任务\n到最优的轨道分配策略被证明是NP难问题\n优化目标 # 最小重叠代价， 最小线长\n举例 # 参考 # Negotiation-based_track_assignment_considering_local_nets # TraPL # 难点与挑战 # 十几年来,物理设计是集成电路中发展速度最快和自动化程度最高的领域之一。随着集成电路的特征尺寸不断减小,超大规模集成电路的工艺和电路规模以摩尔定律经历了巨大的进步,电路设计中不断增长的复杂性进一步扩大了物理设计中自动化设计问题的难度,并同时迎来一系列新的挑战。\n在SRC发布的“Physical Design CAD Top10 Needs\u0026rsquo;”中指出的当前物理设计亟待解决的十大问题中，布线问题位居前列，在芯片尺寸和容量上，布线工作需要绕线的电路芯片规模达到成千上万个大模块和几百万个小模块，同时要求在合理可行的时间内完成布线工作。同时，VLSI物理设计中的其他一些需求，如定时和互连线分析，都对布线结果的质量有很高的要求。\n在电路规模变大，尺度减小，复杂度飙升的今天，决定边权成为了一个十分重要的问题，随着待优化指标的增多，准确算法的时间空间复杂度均逐渐来到了一个不可接受的地步（毕经这是一个NP-Hard问题），因此业界主流的发展方向是使用近似算法。关于Steiner最小树的研究非常多，目前的理论最优解是 Geosteiner 算法\n随着集成电路设计工艺的不断发展,允许绕线的布线层数随之增加,大幅度减少了互连线宽度和互连线间距,从而提高了集成电路的性能和密度。于是,多层总体布线应运而生\n在现在的 VLSI设计中,随着制程技术的发展,纳米等级CMOS电路的电晶体密度剧烈增加,电路时延问题越突出,时序收敛越困难,最终严重影响芯片的性能和产量。当前,互连线延迟超越门延迟变成影响电路性能的主要因素,并且总体布线结果直接影响芯片面积、速度、可制造性、功率和完成设计周期所需的迭代次数,因此其在决定电路性能方面起着重要作用\n较长的布线会导致明显的信号延迟并导致更大的动态功耗。**过多的通孔会降低芯片的可靠性。**电线间隔的差异会引起电短路或者断路而降低成品率。物理设计是人工设计中耗时最长和错误率最高的设计过程之一。它也是近年来电子设计自动化(Electronic Design Automation,EDA)工具中发展最快和自动化程度最高的领域之一。随着制造工艺的发展,它也是受到影响最大、面临的机遇和挑战最多的领域之一.\n特征尺寸进入纳米级后,器件的尺寸变得越来越小,互连线的线宽越来越细、密度越来越大。互连线变小速度赶不上器件,长度也迅速增加,互连线的延迟远超过门的延迟，占到线网总延迟的 60%~70%。\n集成度的增大使得互连线面积不断增加,约占芯片总面积的30%~40%。为了降低芯片大小,布线金属层的数量也在不断增加。目前最大布线层数已达到13层,预计 2028 年会达到 17 层。\n为了缩短开发周期,IP复用显得越来越重要。这使得布线区域的障碍数量不断增多,密度增大,形状也更加复杂。此外,利用障碍内资源布线可大大缩短互连线长度、减小布线面积和提高芯片性能。当线网障碍内部分较大时,导致输出端的电压转换速率过大,引发噪音和功率问题,并影响信号完整性。这使得在布线过程中需要进一步考虑绕障问题和信号完整性问题\n现代设计中互连结构和网格的高体积与复杂性对可布线性造成了严重的挑战。快速拥塞分析对于在设计的早期阶段解决可布线性问题变得至关重要,例如，在布局期与总体布线一起。在现代设计中,一些新的因素导致了布线拥塞,包括金属层之间明显不同的导线尺寸和间距、层间通孔的尺寸、各种形式的布线拥塞(例如,保留给电网、时钟线网或芯片系统中的JP块),由于引脚密度和总体单元内的布线导致的局部拥塞和位于较高金属层的虚拟引脚。然而,早期的评估技术都没有全面地捕捉到这些新的拥塞源。\n布线问题已经被证明是一个 NP 完全问题，因此 ，为布线问题寻找全局最优解不具备可行性 另外 ，布线过程受制造⼯艺制约 ，存在着很多约束和限制 ，这也令布线的复杂度进一步提升\nIn advanced technology nodes, detailed routing has to deal with complicated design rules and large problem sizes, making its performance more sensitive to the order of nets to be routed.\n迷宫布线（寻路算法） # 李氏算法（迷宫布线算法） # 该算法从源点开始 ，依次访问网格各⽅向上的相邻节点 ，并为该节点标记从源点到该点的已知布线代价。对每个访问到的节点重复相同的过程。这会在整个布线图中产生一个连续扩散的波 ，当这个波扩散到了目标点 ，即目标节点被他的相邻节点访问到时 ，就找到了这样一条路径连通源点与目标点。随后算法进入路径回溯阶段 ，从目标点开始 ，直到回溯到源点，此时就生成了一条最优路径\n这类方法都是每次从线网（nets)中选择一条拆成两端线网来进行布线，效果取决于布线顺序。另外，算法未考虑约束（可布性、拥塞、间距），而这些约束都有滞后性，需要线网全部布线完成后，才能体现。因此基于以上方法的工作更多在顺序布线（sequential routing)前期就考虑各种约束[1-5]。\nA*算法 # （对李氏算法的改进，加速了李氏算法收敛）\nBFS Dijkstra 线搜索算法 # Mikami 等在 1968年提出了第1个使用线段代替节点搜索的路径搜索算法\u0026ndash;线搜索算法。该算法以源点和目标点为基点,首先从两个基点各引出两条相互垂直的直线,当直线遇到障碍物或布线区域边界时,会在当前的直线上选取新的基点并沿垂直方向生成一条新的直线,直到从源点和目标点延伸出的多级直线发生相交,则找到了一条路径连通源点和目标点。由于其并没有遍历所有的搜索空间,所以线搜索算法并不能保证找到最优解。 Hetze1在 2002年提出的Hetze1算法将以线段代替节点进行搜索的思想与A算法结合,在保证找到最优解的情况下具备比A算法更快的求解速度。\n多源多汇迷宫布线 # 多源多汇迷宫布线将同一子树中的所有网格点视为源点,将另一个子树中的所有网格点视为汇点\n并行算法 # 多商品流算法(multi commodity flow, MCF)\n建模为整数线性规划（integer linear programming，ILP）\n由商品的源点和目标点以及商品流经的路径组成。随后将整个布线区域建模成一个三维的布线网格,网格点可以作为商品流的流经点,点与邻近点之间的线段称作边。 在ILP 问题的模型中,网格的点和边作为变量用边和点的流量表示线网对边和点的使用情况，容量代表边和点上同时流经的最大的线网数量(在详细布线中一般取1)。目标函数为边上所有线网的流量与其相应布线代价的积的累加和。在约束条件下最小化目标函数可以获得布线的最短线长。其约束主要包含各个线网在点或边上的流量之和不超过点或边的容量约束、基于流量守恒定律的连通性约束等。\n整数线性规划 # 这类方法可以直接对所有线网布线（Concurrent Approach），并考虑交叉、拥塞等约束。算法提前生成端点之间可能的走线方案，并用一0-1变量 xij 表示是否选择本方案。问题随后转化为带约束的线性整数规划问题\n特点 #  Standard techniques to solve IP.  No net ordering. Give global optimum.  Can be extremely slow, especially for large problems.  To make it faster, a fewer choices of routing trees for each net can be used. May make the problem infeasible or give a bad solution.  Determining a good set of choices of routing trees is a hard problem by itself.\nHierarchical Approach # Hierarchical Approach reduces global routing to routing problems on a 2x2 grid\n先将网格划分为粗网格，找到粗网格间的布线，然后将网格细化，对每个子模块递归求解，每次求解规模均极小\n基于Steiner的算法 # This technique can be used in global or detailed routing problems\n对于某些多端net, 一般都采用最小斯坦纳（steiner)生成树方法。比如遵守水平垂直走线的Rectilinear Steiner Minimal Tree.一般生成树算法算法非常多，比如Kruskal，prime, spanning-graph[7],edge-substitution. 另外考虑实际布线中允许45，60度走线，也有对应八向斯坦纳最小生成树（octilinear steiner)方法[8].\n定义 # Steiner Node :\nFor a multi-pin net, we can construct a spanning tree to connect all the pins together\nSteiner Tree: A tree connecting all pins and some additional nodes (Steiner nodes).\nGrid graph:\n优化算法 # 布线从数学的角度来看是一个有约束的最优化问题。线网是指具有相同电位的一组引脚，很显然，这些引脚需要被连接在一起，但电路板上有着各种约束，代表性的便是一系列的匹配规则（比如对一部分版图设计初学者来说堪称莫名其妙的插指结构或重心匹配和热匹配），因此这是一个十分典型的复杂最优化问题。\n优化指标 # 一般来说，最优化的主要指标是线长，但在RF设计中，线与器件的距离等其它因素将因为互感效应和一些非线性效应变得异常重要。VLSI总体布线问题最初以线长最小化为优化目标,但随着制造工艺的不断发展和芯片特征尺寸的不断缩小,互连线延迟对芯片性能的影响越来越大,因此,时延和串扰等优化目标也需要在总体布线问题中考虑。同时,影响到芯片的可布性和可制造性的因素,包括溢出数、拥挤度、通孔数等优化目标,也是当今总体布线工作需要优化的指标。\n线长：线长影响了芯片的制造成本 ，且线长越长 ，线网的时延与电容越大 ，这会使芯片的稳定性下降、功耗增高\n布通率：完成连线/实际连线数\n通孔数量：越少越好，via具有更大延时，还会增加芯片制造失败率\n串扰和时延：线网间的电容电感等现象会在线网间产生串扰 ，增大时延。因此布线算法要对时延敏感线网及关键线网做出特殊设计，以降低芯片的总时延，提高芯片稳定性\n术语 # (1)网表:N={N,N。,，…},其中每个线网N，是一个引线端的集合,属于同一个线网的引线端将由布线工具把它们连接在一起,这里的网表则是提供电路的互连信息。 (2)布线容量:指考虑设计规则、布线区域的大小和线网的宽度,布线区域内的最大走线数。 (3)拥挤度:需要的布线资源与可用的布线资源之间的比值。 (4)溢出边:若一条边的布线资源需求量大于可用的布线资源,则该边被称为溢出边。 (5)总体布线图(GRG):在进行总体布线之前,根据电路的几何特征和电路结构,用网格将整个芯片按行和列划分为若干称为总体布线单元的区域,并通过总体布线器指定GRC以连接线网。由网格线及其交点所构成的图的对偶图称为总体布线图。 (6)局部线网:若一个线网所需要连接的所有引脚均在同一个GRC中,则称该线网为局部线网。 (7)全局线网:若一个线网所需要连接的部分或全部引脚分布在不同GRC中,则称该线网为全局线网。 (8)设计规则约束:目前布线问题中存在一些基本设计规则约束(DesignRules Constraint,DRC)违反情况,包括开路、短路、相邻金属线的间距不足等。 (9)3D总体布线和2.5D总体布线:多层总体布线类型分为3D和 2.5D 总体布线两种。 ① 3D总体布线:对于多层布线,采用3D布线直接在立体的总体布线图进行布线,这样得到的总体布线方案虽然比2.5D来得更准确且能取得多个更好的性能指标,但会带来巨大的时间和空间复杂度。由于EDA设计的原则是简单、快速、合理,所以3D布线的研究不能令人十分满意。 ② 2.5D总体布线:是将多层布线中各层的布线资源、引脚等映射到平面上，将3D布线转化成平面布线,这样进行平面总体布线可减少时间空间复杂度,在平面上完成总体布线后,再通过层分配将布线结果还原到3D布线,同时维持平面布线获得的溢出数且优化通孔数。\n标准 # LEF # lefdefref.pdf (ispd.cc)\nTools # Glogal Router # CUGR # CUGR is a detailed routability-driven global router and its solution quality is solely determined by the final detailed routing results\nDAC paper\ngithub\nDetail Router # Tritonroute # from openRoad\nincluding pin access analysis, track assignment, initial detailed routing, search and repair, and a DRC engine.\ngithub\n当前研究方法 # 结合AI：比如使用AI模型预测拥塞率，在顺序布线早期阶段减少拥塞，降低时间。比如利用强化学习，自行学习走线过程。\n布线-拆线：有点类似对抗生成网络**(GAN)**思想。Alpha-PD-Router有两个玩家，布线器（router）和拆线器（cleaner）。布线器以总线长为目标布线，而拆线器则拆线重布，以使布线器布线更容易为目标，如此往复下去。\n相关竞赛 # [ISPD24 Contest: GPU/ML-Enhanced Large Scale Global Routing | ISPD24_contest (liangrj2014.github.io)]( https://liangrj2014.github.io/ISPD24_contest/#:~:text=Global routing is a critical component)\n[ISPD 2008 Global Routing Contest]( https://www.ispd.cc/contests/08/ispd08rc.html#:~:text=Continuing the tradition of spirited competition,)\n[ISPD 2007 Global Routing Contest]( https://ispd.cc/contests/07/contest.html#:~:text=Continuing the tradition of spirited competition,)\n[Initial Detailed Routing Contest at ISPD 2018]( https://www.ispd.cc/contests/18/#:~:text=This proposed contest focuses on the)\n[Initial Detailed Routing Contest at ISPD 2019]( https://ispd.cc/contests/19/#:~:text=Detailed routing can be divided into)\n评价标准 Connectivity constraints LEF routing rules Routing preference metrics 参考 # 大规模集成电路布线算法设计简介 - 知乎 (zhihu.com)\n超大规模集成电路布线算法综述 (sciengine.com)\n非曼哈顿结构下超大规模集成电路布线理论与算法-目录，第一章绪论\n非曼哈顿结构下超大规模集成电路布线理论与算法-第三章X结构Steiner最小树算法\n超大规模集成电路布线设计理论与算法-目录，第一章绪论\n超大规模集成电路布线设计理论与算法\n"},{"id":9,"href":"/zh/docs/Digtal/Synthesis/synthesis/","title":"Synthesis","section":"Physical Design","content":" 基本概念 # 逻辑函数:二级逻辑和多级逻辑。二级逻辑又包含两种 规范式，分别称为与或两级规范形式(sum-of-products two-level form, SOP)和或 与两级规范形式(product-of-sums form, POS)[19]。其中或与形式的第一级均为或 项，第二级均为与项，而与或形式刚好相反。\nAIG\nAnd-Inverter Graphs)的文件格式的代称\nASCII格式的AIG文件第一行由字符串aag 开始，aag是ASCII AIG的缩写；然后是以空格分隔5个非负整数，分别由M, I, L, O, A 表示。\nM = 最大变量下标 maximum variable index I = 输入个数 number of inputs L = 锁存器个数 number of latches O = 输出个数 number of outputs A = 与门个数 number of AND gate\naag 3 2 0 1 1 2 input 0 4 input 1 6 output 0 6 2 4 AND gate 0 1\u0026amp;2\n相关文件格式 # .aiger # 逻辑综合步骤 # 第一步 (Translation)： # 转换过程，将RTL描述转换成为未优化的门级布尔描述(如与门，或门，触发器，锁存器等)。\n第二步 (Logic Optimization)： # 布尔优化过程，将一个非优化的布尔描述转化成一个优化的布尔描述的过程。\nNP完全问题, 常用启发式算法去求解, 通常计算机内实现的算法是Quine-McCluskey算法, 但是实际上还有许多表示形式如ESOP（E互斥或积之和表示式）和CDEC（条件解码器）\n对于这些多级的直接优化，用与非图AIG来描述组合逻辑电路，利用AIG的有向无环图的特性，一系列高效算法可以用于平衡、重写和重构这些AIG，从而最小化电路。基于AIG有一个主要的好处是，现在大多是的ASIC设计与FPGA设计，都是基于标准单元或者LUT实现的，往往有特定的输入输出引脚数目限制，AIG可以很好把这个限制反映在算法之中。\n时序逻辑优化（Sequential Logic Optimization）\n而考虑时序问题，逻辑综合中主要需要处理与寄存器、 状态机、时钟相关的问题。时序电路会有时钟频率限制，对组合逻辑的整体延时有最大最小值限制。重定时算法会移动寄存器在DAG网表的位置，将整个网表拆分成符合设计限制，合适的Retiming将有利于实现更加高频率的数字电路。有的Retiming算法侧重于缩短时钟周期，有的则侧重减少寄存器数目，如果变换寄存器的位置，会影响到部分控制逻辑，所以其实有一些约束条件的，这些约束条件大多可以转化为SAT（布尔可满足性）问题并且利用SAT专用求解器求解\n第三步 (Mapping)： # 门级映射过程，取出经优化的布尔描述，利用从工艺库中得到的逻辑和定时的信息生成门级网表，确保得到的门级网表能达到设计的性能和面积要求。\n标准单元库是一组相对完善的、符合某种生产或设计工艺标准的标准单元. 常见的标准单元有基本逻辑门（AND、OR、NOT、XOR\u0026hellip;）、Flip-Flop寄存器、MUX多路选择器加法器、时钟单元、延时缓冲（Delay Buffer）\n这样映射的目标通常是优化面积、延迟指标，实现这一目标通常是把问题转化为有向无环图覆盖问题。对于复杂的设计网表，这个问题同样是NP-hard\n如果模板和设计网表都是树，则该问题可以通过动态规划高效解决，所以一种解决方案就是把图动态划分成森林、同时结合基于树的算法，来解决相对复杂图的映射\n工具 # 开源 # Yosys\nYosys是Verilog RTL合成的综合，用作三个VTR前端之一，用于执行逻辑综合、细化和将Verilog硬件描述语言（HDL）的子集转换为BLIF网表。Yosys的设计是可扩展的，因此是实现专门任务的定制综合工具的良好基础。\n"},{"id":10,"href":"/zh/docs/Digtal/Verify/verify/","title":"verify","section":"Physical Design","content":" 背景 # 随着集成电路技术的迅速发展，电迁移（Electromigration, EM）和热迁移（Thermomigration, TM）已经成为影响现代集成电路互连线可靠性的两大主要问题。在电子设计自动化（Electronic Design Automation, EDA）的后端设计中，物理验证环节需要对EM和TM产生的应力进行评估，以确保电路符合可靠性规范。传统的应力计算方法依赖于复杂的偏微分方程（PDE）求解，不仅计算量大、耗时长，而且在处理大规模电路时往往难以保证精度。\n电迁移（Electromigration, EM） # 由于电子流动引起的现象 当导线中电子快速移动时，电子与金属原子间的动量交换会导致金属原子从阴极向阳极迁移。随着时间的推移，这种迁移会导致导线中的空洞（voids）或突起（hillocks），这种金属的分布不均导致了应力的产生。当应力达到一定阈值时，会导致导线断裂或短路，从而影响电路的可靠性，最终引发电路失效。 VLSI: 这种现象在小尺寸导线和高电流密度条件下尤为显著，特别是在纳米尺度的VLSI系统中。 热迁移（Thermomigration, TM） # 由导线中的温度梯度引起 当导线的不同区域存在温度差异时，高温区的金属原子会向低温区移动，这同样会导致导线中的应力积累和材料变形 VLSI: 随着半导体工艺的进步，集成电路的功率密度逐渐增大，热效应越来越严重，热迁移问题成为影响导线可靠性的重要因素。 相关研究 # EMGraph-First GNN-DAC-2021-GNN-University of California # background # 随着VLSI技术进入纳米级，EM已成为影响芯片可靠性的重要问题。电迁移主要通过应力来进行描述。传统的电迁移分析方法依赖于复杂的物理模型和数值求解，如有限元法，但这些方法计算成本高且难以扩展至大规模互连结构。 现有的生成对抗网络（GAN）在固定尺寸的图像上进行预测，但不能很好地适应复杂和动态变化的多段互连电路结构针对这一问题。EMGraph将多段互连电路结构建模成图结构，在节点和边上同时进行EM应力预测，有效地在多段互连结构上进行电迁移分析。 contribution # transferable knowledg first GNN in EM A novel graph convolution-decoder structure is employed Task # node-edge regression for EM stress\ndata # 数据由COMSOL,SPICE(生成电流密度)生成\nresulting dataset contains 2500 unique designs （2125/375）\nFeature\nnode：节点代表电路中的连接点 node_feature: 时间（什么时间？） edge: 导线段 edge_feature: 电流密度J、长度L、宽度W和时间t(老化时间) label is five sampling points’s stress\nmultisegment interconnect： 只有两两连接？\n有向图？\nchallenges # stress ranges from -2e+9 to 2e+9 Pa. Data rescale to -1 to 1 using min-max normalization method. impact the accuracy at the smaller ones as they may be considered noises by the model 然而，这种配置实际上有利于我们的目标，因为大应力点是可能导致可靠性问题的地方，需要更高的准确性 both node and edge features the accuracy of stress should be high. GCN is low model # 基于GraphSage\n其卷积由两部分组成\n将其邻域节点和连通边的信息聚合到一个节点中 将两个端节点的信息聚合到对应的边当中 整体框架\nNode and edge decoder ：\nnode2,3怎么实现聚合到1的？\nexperiment # env:\ndgl pytorch Linux server 2 Xeon E5-2699v4 2.2 GHz Nvidia Titan RTX GPU setting:\n5 layers with number of hidden features set to 8, 16, 32, 64 and 128 respectively. node and edge decoders: [128, 256, 1024, 256, 64, 1] and [128, 256, 1024, 256, 64, 5] Adam optimizer batch size is set to 32 learn rate = 10-4 cross validation technique root-mean-square error (RMSE) 与基于有限元法（SOTA）的传统解析方法和GAN方法相比 EMGraph预测的平均误差为1.5% EMGraph的推理速度极大提升。其推理时间为0.27毫秒，是GAN方法的14倍，传统数值方法的265倍。 可视化 大图知识迁移 question # 方向是怎么定的，怎么有多驱动的 -EM\u0026amp;TM+Attention-DATE-2024-SEU+CUHK # background # 随着VLSI技术的进步，EM问题变得越来越严重，而TM（由温度梯度引发的原子扩散）进一步加剧了EM应力的影响。传统方法如数值模拟（如COMSOL软件）计算复杂且耗时，因此论文提出一种基于图学习的解决方案。\nboundary junctions connect to standard cells.\nVertical branches are typically connected to boundary junctions at one end\nHorizontal branches are influenced by internal junction nodes at both ends\n温度梯度的引入改变了原子运动的状态。与仅考虑电磁效应相比，它在多段互连内带来了明显不同的应力分布.如(b)\nsoftware COMSOL predicts the hydrostatic stress in each segment by solving Korhonen’s PDE : 一个偏微分方程\nWhen employing traditional methods, the temperature term significantly escalates the overall solution’s complexity, especially when simulating stress in large-scale multi-segment interconnects.\ntask # node-edge regression for EM and TM stress\ncontribution # first TM\u0026amp;EM prediction use GNN an enhanced GAT: customized alternating aggregation method data # 构图方法与EMGraph中所描述方法相同\n相比上一篇EMGraph, 除了温度TE, 还多了CE, 和CN\n这里的图结构和EMGraph是有点不一样的，这里只有一条长水平线\nMin-Max normalization method to (0, 1) model # 整体还是和EMGraph一样的\nGAT based.节点特征的更新是通过一个注意力机制来完成的\n模型会计算每个节点与其邻居节点及相连边之间的注意力权重，根据这些权重来聚合邻居节点和边的特征，从而更新当前节点的嵌入表示。这样一来，节点不仅能够接收相邻节点的信息，还能融入连接边的特征，从而实现更精细的应力预测。\n设计了专门的边聚合机制: 双向交替聚合\nexperiment # env:\nan Intel Xeon CPU with 2.20GHz 4 NVIDIA Tesla V100 GPUs 精度对比实验 尤其是在200段以内的互连结构中，其平均误差率不到0.9%\n速度对比\n相比于COMSOL软件，本文模型在电迁移和热迁移应力的预测中实现了高达9037倍的速度提升。\n泛化能力 in VLSI\n为了进一步验证模型在VLSI上的适用性，论文使用了OpenRoad中的电源网格电路进行测试，最大电路包含10,807段导线。实验结果表明，在这些大规模电路中，本文模型依然能够保持不到**1.1%**的误差率，并且在应力预测速度上实现了9037倍的提升\n参考 # 专题解读 | GNN在EDA后端设计物理验证环节中验证应力的应用 "},{"id":11,"href":"/zh/docs/Other/Algorithms/","title":"Algorithms","section":"Other","content":" 整数规划 # 举例 # Combinatorial Optimization # 组合优化问题(COP)\n精确方法和近似方法 # 常见相关场景/问题 # TSP\n给定一系列城市和每对城市之间的距离，求解访问每座城市一次并回到起始城市的最短回路\nVRP\n给定一组客户点、车辆容量、车辆数量、起始点和终点，目标是找到使得所有客户点都被访问一次的最短路径方案。\nMVC(最小顶点覆盖问题)\nMDS(最小支配集)\nMIS(最大独立集)\n背包问题\nHeuristic algorithm # SA # Simulated Annealing\nGA # Genetic Algorithm\nGE # Grammatical Evolution\n基于NN和DL的方法 # 分类 # 特点 # 优点 # 缺点 # 经典模型 # Pointer Network # PointerNet 是基于 Sequence to Sequence 的 Attention 机制的改进\nPointerNet 引入了一种新的神经体系结构来学习输出序列的条件概率，其中元素是与输入序列中的位置相对应的离散标记\n模型 # 作者发现， $ A^i_j $ 经过softmax后，也可以直接作为针对原序列的指针进行训练；简单理解为，原来的 $ A^i_j $ 为原序列每一位的注意力，那么新的 $ A^i_j $ 可以作为原序列每一位放在此处的概率，最后选择概率最大的直接输出。\n编码器和解码器均为 LSTM\n训练的问题 # 强化学习进行训练 # graph theory # Tarjan算法提取强连通分量 # basic # 强联通图\n强联通分量\n在强连图图的基础上加入一些点和路径，使得当前的图不在强连通，称原来的强连通的部分为强连通分量。\n基本思路 # 对于每次搜索的点，我们都加入栈中，遇到回路时，在把栈中的元素逐个弹出，记录它们的起始结点，直到栈中弹出的元素正好是起始结点时，结束弹栈，继续搜索其它强连通分量\n在这个过程中，所有的点和都有的边都被遍历了一次，所以最终的时间复杂度为O ( N + E )\n流程举例 # 参考 # 图论——强连通分量（Tarjan算法)-CSDN博客\nmaze algorithm # 基本知识 # 曼哈顿距离：水平+垂直举例 欧几里得距离：直线距离 原理 # F=G+H\ndynamic programing # Tree algorithms # R-Tree # R-Tree是B-Tree的多维版\n核心思想 # 操作 # 搜索（query） # 插入（insert） # 删除（delete） # 参考 # 空间数据索引RTree完全解析-CSDN博客 LeetCode Note # Hash # 哈希表查表操作时间复杂度为1\n参考 # 力扣 (LeetCode) 全球极客挚爱的技术成长平台\n"},{"id":12,"href":"/zh/docs/Other/git/","title":"Git","section":"Other","content":" 基本指令 # add：将工作区中的更改添加到本地暂存区。\ncommit：将本地暂存区中的更改提交到地仓库，创建一个新的提交。 主要完成的内容就是创建一个新的提交，包括暂存区中的所有更改；每个提交都有一个唯一的哈希值，用于在版本历史中标识该提交。提交时，可以提供一条有意义的提交消息来描述更改的内容。\ncheckout：用于在本地仓库中切换分支或恢复历史版本。 主要操作是将Git版本库中的内容拿到工作区。例如回退版本，连续两天提交了版本，第三天的时候，想要将工作区的内容回退到第一天提交的版本，就需要checkout操作回退版本。 或者从一个分支切换到另一个分支，分支的概念看下文；\nclone：克隆远程仓库到本地，创建一个本地仓库的副本。 克隆操作其实就是一个粘贴复制，把远程的仓库完整的拷贝到本地仓库；通常是包含两步：\n创建本地仓库：首先，在本地创建一个新的空白目录或指定已存在的目录作为本地仓库。这一步是为了给克隆的项目提供一个位置，用于存储远程仓库的内容和版本历史。 克隆仓库：使用git clone命令，将远程仓库的内容复制到本地仓库中。克隆操作会自动将远程仓库的全部历史记录、分支信息和文件复制到新创建的本地仓库目录中，并为远程仓库设置一个别名（默认为“origin”）。 push：将本地仓库中的更改推送至远程仓库。 将本地的提交推送到远程仓库，更新远程仓库的分支和提交历史。\npull：从远程仓库拉取最新更改（相当于fetch + merge）。 其实也是两步；更新是从远程仓库（remote repository）到本地仓库（local repository），但实际的合并操作是将更改从本地仓库合并到工作区（working directory）和本地仓库的当前分支。\n创建版本库 # $ git init Git 仓库是用于版本控制的一个特殊目录（.git目录），它保存了项目的完整历史记录和元数据信息\n每当您在项目中添加、修改或删除文件时，Git 都会创建一个新的备份，称为提交（commit）。提交是代码修改的快照，并包含了作者、时间戳以及相关的元数据信息。\n通过这些提交，Git 可以帮助您追踪项目历史，查看特定版本的代码状态，甚至回滚到之前的某个状态。\n.git/ ├── HEAD ├── branches ├── config\t#包含了Git 仓库的配置选项，例如用户名、邮箱等。 ├── description ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── pre-merge-commit.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ ├── prepare-commit-msg.sample │ └── update.sample ├── info │ └── exclude ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags 分支 # 默认就是main/master分支\n在这个新的分支上，可以随意修改代码、添加新的功能、调试和测试，而不会对主分支上的代码产生任何影响\n基本指令分支 # git branch\t#查看分支。当前分支前面会有一个星号 *。 #另外，可以添加 -r 选项来查看远程仓库的分支 git branch name #创建分支 命令加上-b参数表示创建并切换 git switch -c \u0026lt;branch_name\u0026gt; #创建并切换到新分支， Git 2.23 版本之后 git branch -d \u0026lt;branch_name\u0026gt; #如果分支上还有未合并的更改，需要使用 -D 参数来强制删除。 分支合并 # 注意你在\ngit switch -c new_branch #some change git add ... git commit -m \u0026#34;...\u0026#34; git switch master/main git merge new_branch 查看版本库 # git log命令可以查看提交历史，包括每个提交的哈希值、作者、提交日期和提交消息等信息。默认以最新的提交开始显示，按照时间倒序排列。 git diff命令可以比较当前工作目录中的文件与最新提交之间的差异。它可以显示插入的内容、删除的内容以及修改的内容等信息。 git status命令可以查看工作目录中文件的状态，包括已修改、已暂存、未跟踪等状态。它会列出所有变更的文件以及它们所处的状态。 git show命令可以查看某个特定提交的详细信息，包括提交的更改内容和元数据。需要提供该提交的哈希值或其他引用（如分支名）。 命令版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。 版本回退 # git reset # git reset主要用于修改提交历史，并具有对索引和工作目录的不同影响。\ngit reset id #id 以后的log会消失 #本地文件不会变 其他 # git reset --soft 这个命令会将当前分支的 HEAD 指针指向指定的提交，同时保留之前的修改内容和暂存区的文件。 它不会改变工作目录的文件状态，也不会删除已提交的历史记录。 通过这个命令，你可以撤销之前的提交，将其作为未提交的修改保留下来，方便进行新的提交。 git reset --mixed 这个命令的行为与默认的 git reset 命令相同。 这个命令会将当前分支的 HEAD 指针指向指定的提交，同时将之前的修改内容放入工作目录，并取消暂存区的文件。 它会保留之前的修改作为未暂存的修改，需要重新添加和提交文件。 git reset --hard 这个命令会彻底丢弃当前分支的 HEAD 指向的提交以及之后的所有提交。 它会将当前分支的 HEAD 指针指向指定的提交，并将之前的修改内容从工作目录、暂存区和 Git 历史记录中全部移除。 执行这个命令后，之前的修改将无法恢复。 注意：在使用这个命令时，请谨慎操作，以免意外丢失重要的修改。 git checkout # git checkout主要用于切换分支、还原文件和查看历史版本，不会修改提交历史。\ngit checkout \u0026lt;commit_id\u0026gt; 切换回去之后，就开始没有关联任何分支了，相当于是把那个版本拿出来独立在分支之外了；\n也就是说，checkout会切换到旧版本，切换回去之后可以查看旧版本的状态，但是他并不能改变提交历史，也就是不管你怎么操作，都不会改变当前分支的提交记录和版本；\n如果要保留checkout之后的修改，可以创建一个新的分支；\n#加入现在git log显示有3个版本，要回到第二个版本上进行修改，不要第三个版本 git log #查看版本2 id git checkout version_2_id #此时会进入一个游离分支，本地文件也会变为回退版本的对应文件#如果git checkout main/master会回到原来main/master分支 #some change git add ...\t#注意add后不要commite git stash save \u0026#34;Your stash message\u0026#34; #保存修改到临时区 git checkout main/master git stash list #查看暂存区内容 git stash apply name# name 根据查看内容填, 一般是stash@{0}...#将暂存区的内容应用到当前分支 git commit -m \u0026#34;...\u0026#34; git stash drop \u0026lt;stash_id\u0026gt; #删除暂存， git stash apply换成git stash pop；git会在应用暂存的时候同时删除那个暂存； Tag # git tag tagname为最新的提交打标签\ngit tag tagname id 为以往版本打标签\ngit show \u0026lt;tagname\u0026gt;查看标签信息\ngit tag -d tagname即可完成标签的删除；\nPatch # 场景1：拿到一个项目的.patch文件，要把这个补丁打上 git apply xxx.patch 场景二：只对本地特定文件的修改生成.patch。 git diff file_name \u0026gt; xxx.patch Git 补丁 —— diff 和 patch 使用详解_diff \u0026ndash;git 内核打补丁-CSDN博客\nremote # download # git clone ... git clone 命令会克隆远程仓库的所有分支。但是，克隆下来的分支在本地仓库中会以远程分支的形式存在，并不会自动创建与每个远程分支对应的本地分支。\n你可以使用 git branch -r 命令查看克隆下来的所有远程分支，使用 git branch -a 命令查看所有本地分支和远程分支。\n要将远程分支创建为本地分支，可以使用以下命令： git checkout -b \u0026lt;本地分支名\u0026gt; \u0026lt;远程仓库名/远程分支名\u0026gt;\ngit pull origin main/master 首先，它会自动调用 git fetch 命令，从指定的远程仓库中获取最新的提交，但不会应用到本地分支。 然后，它会自动调用 git merge 命令，将获取的提交与当前分支进行合并 如果本地没有未提交的修改，git pull 会自动合并远程分支的更新到当前分支，并创建一个新的合并提交。 如果本地有未提交的修改，git pull 默认会尝试自动合并。如果合并过程中发生冲突，你需要手动解决冲突后再提交。 如果你想要强制执行 git pull，可以使用 git pull --force 命令。 拉取远程分支 # git clone https://github.com/steveicarus/iverilog.git iverilog_v11 cd iverilog_v11 #拉取远程分支 git branch -r #查看远程分支 git checkout --track -b v11-branch origin/v11-branch #切换到远程分支“origin/v11-branch”v11到本地， 本地命名为v11-branch git pull\t#拉取 upload # cd your project_file git init\t#这个命令可以把当前目录变成git可以管理的仓库。 git add file #git status\t#检查当前git状态 git commit -m \u0026#34;Update *** Files by ***\u0026#34; #复制仓库ssh连接 git remote add origin git@github.com:user/xxx.git #添加一个远程仓库，命名为origin #git remote set-url origin git@github.com:Pxx-X/ICEEC2024-5.git#添加文件到远程库 git push origin master#或者main #使用push指令进行上传,The authenticity of host \u0026#39;github.com (xxx)\u0026#39;can\u0026#39;t be established., 输入yes #第一次要加origin master， 后面之间git push 就行 相关报错： # ** Please tell me who you are. Run git config --global user.email 17875200128@163.com git config --global user.name PxmmmmGH to set your account\u0026#39;s default identity. Omit --global to set the identity only in this repository. fatal: unable to auto-detect email address (got \u0026#39;XXX@YYY.(none)\u0026#39;) #这时候的解决办法是，在进行`git add ./`操作的路径中，实际上已经生成了一个隐藏的.git文件夹。在该路径下输入指令`cd ./.git`便进入.git文件夹，使用gedit或vim打开文件config，在文件末尾加入内容： [user] email = your email name = your name fatal: remote origin already exists #说明远程仓库已经存在。这时候需要先删除origin仓库，然后再重新添加该远程仓库 git remote rm origin git remote add origin git@github.com:upcAutoLang/Framework-for-NACIT2017.git 有时候对新建的仓库进行push操作，会出现上传失败的情况。 通常出现这种情况的原因，是新建的仓库往往会有一个文件Readme.md文件，而本地仓库中没有这个文件，也就是说本地仓库与服务器端仓库没有实现同步。所以将这个Readme.md文件clone到本地，然后再commit提交，应该就没有问题了。 ! [rejected] master -\u0026gt; master (fetch first) error: failed to push some refs to \u0026#39;git@github.com:Pxx-X/ICEEC24-5.git\u0026#39; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., \u0026#39;git pull ...\u0026#39;) before pushing again. hint: See the \u0026#39;Note about fast-forwards\u0026#39; in \u0026#39;git push --help\u0026#39; for details. #强行上传 git push -u origin +master # 设置SSH Key # 由于本地的Git仓库与GitHub网站仓库之间的传输是通过SSH加密的，所以这时候需要设置SSH keys。\n创建SSH Key # ssh-keygen -t rsa -C \u0026#34;youremail@example.com\u0026#34; #其中，”youremail@example.com”是你的邮件地址，-C的字母为大写。 #后面可以一直回车。中间会让你输入密码，但整个SSH Key对笔者来说保密意义不大，所以不需要设置。SSH Key创建成功后，在笔者的主目录下就会生成/home/grq/.ssh文件夹，里面也会生成文件id_rsa与id_rsa.pub，它们是SSH Key的秘钥对。其中id_rsa是私钥，不能泄露，id_rsa.pub是公钥，可以告诉其他人。 在GitHub端设置SSH Key # 登录GitHub，点击右上角头像，Settings -\u0026gt; Personal settings -\u0026gt; SSH and GPG keys。在SSH Keys标签右方点击New SSH Key。\n弹出两个文本框。其中的Title，可以随意命名。笔者此处随便命名为grq-Ubuntu。\n另一个Key文本框，需要输入刚刚生成的id_rsa.pub文件中的内容。粘贴后点击Add SSH Key，即可生成SSH Key\nwindows下git安装 # Git Windows版的安装与使用（保姆级教程，附案例）_git for windows-CSDN博客\n参考 # Git使用教程（看完会了也懂了）-腾讯云开发者社区-腾讯云 (tencent.com)\n"},{"id":13,"href":"/zh/docs/Other/Hardware/","title":"Hardware","section":"Other","content":" 综述 # CPU # CPU类型 # 复杂指令集(CISC): x86, Zen\n精简指令集(RISC)：ARM，MIPS, PowerPC\n针对性更强，可以根据不同的需求进行专门的优化，能效更高 调用速度快 服务器上往往使用RISC 服务器CPU往往应用了最先进的工艺和技术，并且配备了一二三级缓存，运行能力更强，服务器CPU很早就用上了3级缓存，普通cpu是近几年才用上了缓存技术 ARM # 是一个**32位精简指令集（RISC）**处理器架构\n优势：价格低；能耗低\n由于节能的特点，ARM处理器非常适用于行动通讯领域，符合其主要设计目标为低耗电的特性。\n其广泛地使用在许多 嵌入式系统设计。\nx86/Atom # x86是英代尔Intel首先开发制造的一种 微处理器体系结构的泛称。 x86架构是重要地可变指令长度的CISC（复杂指令集电脑，Complex Instruction Set Computer）。\nIntel Atom（中文：凌动，开发代号：Silverthorne）是Intel的一个 超低电压处理器系列\nMIPS # 一种 RISC处理器\n核心和线程 # CPU可以想象成是一个银行，CPU核心就相当于柜员，而线程数就相当于开通了几个窗口，柜员和窗口越多，那么同时办理的业务就越多，速度也就越快。\n通常情况下，一个柜员对应的是一个窗口，通过超线程技术相当于一个柜员管理着两个窗口，使用左右手同时办理两个窗口的业务，大大提高了核心的使用效率，增加了办理业务的速度。\n#查看物理 cpu 数： cat /proc/cpuinfo| grep \u0026#34;physical id\u0026#34;| sort| uniq| wc -l #查看每个物理 cpu 中 核心数(core 数)： cat /proc/cpuinfo | grep \u0026#34;cpu cores\u0026#34; | uniq #查看总的逻辑 cpu 数（processor 数）： cat /proc/cpuinfo| grep \u0026#34;processor\u0026#34;| wc -l #查看 cpu 型号： cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c #判断 cpu 是否 64 位： #检查 cpuinfo 中的 flags 区段，看是否有 lm （long mode） 标识 2\n48\n96\nIntel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz\nThread(s) per core: 1\nlscpu 命令可以同时看到上述信息。比如：\nCPU(s): 24 On-line CPU(s) list: 0-23 Thread(s) per core: 2 Core(s) per socket: 6 Socket(s): 2\n核心（core) # 一开始，每个物理 cpu 上只有一个核心（a single core），对操作系统而言，也就是同一时刻只能运行一个进程/线程。\n总的逻辑 cpu 数 = 物理 cpu 数 * 每颗物理 cpu 的核心数 * 每个核心的超线程数\n同时多线程技术（simultaneous multithreading） # SMT\n超线程技术(hyper–threading/HT) # 可以认为HT是 SMT 的一种具体技术实现\n一般一个核心对应了一个线程，而intel开发出了超线程技术，1个核心能够做到2个线程计算，而6个核心则能够做到12个线程，超线程技术的好处就是无需增加物理核心就可以明显的进步CPU多线程功能，毕竟增加物理核心是需要占据非常大的核心面积，成本也随之增加\n多核CPU # GPU # GPU主要参数 # 结构 # 相关厂商和产品 # 英伟达 # 常见计算卡(AI生成) # 计算卡对比 # 对比维度：\n架构先进性: Hopper \u0026gt; Ada ≈ Ampere \u0026gt; Volta。 显存带宽: HBM3（H100） \u0026gt; HBM2e（A100） \u0026gt; GDDR6X（4090） \u0026gt; HBM2（V100）。 稀疏计算支持: H100/A100/4090显著优于旧架构。 多卡扩展: H100/A100支持NVLink，4090/3090仅支持PCIe。 综合来看：H100 \u0026gt; A100 ≈ A800 \u0026gt; RTX 4090 \u0026gt; A40 \u0026gt; V100 \u0026gt; RTX 3090 \u0026gt; A30\n实际场景中，H100/A100更适合企业级训练，4090/3090适合个人或小规模任务，A40/A30侧重推理和边缘计算\nH100 (Hopper架构) # 架构: Hopper (2022) 制程: 4nm 显存: 80GB HBM3 | 带宽 3TB/s 计算性能: FP32 60 TFLOPS | FP16/TF32 2,000 TFLOPS（稀疏） 核心数: 18,432 CUDA + 576 Tensor Core（第四代） 特性: 支持NVLink 4.0（900GB/s）、PCIe 5.0、Transformer引擎优化 功耗: 700W 定位: 超大规模模型训练、HPC 优势: Hopper架构 + 第四代Tensor Core + Transformer引擎，FP16稀疏算力高达 2,000 TFLOPS，HBM3显存带宽 3TB/s，支持NVLink 4.0，专为超大规模模型优化。 场景: 大规模训练（如GPT-4/LLaMA）、HPC。 A100 (Ampere架构) # 架构: Ampere (2020) 显存: 40GB/80GB HBM2e | 带宽 1.6TB/s 计算性能: FP32 19.5 TFLOPS | FP16/TF32 312 TFLOPS（稀疏） 核心数: 6,912 CUDA + 432 Tensor Core（第三代） 特性: NVLink 3.0（600GB/s）、多实例GPU（MIG） 功耗: 400W 定位: 主流AI训练、科学计算 A800 (Ampere架构) # 简介: A100的出口限制版，NVLink带宽降至400GB/s，其他参数与A100一致。 定位: 替代A100的中国市场专用型号。 A40 (Ampere架构) # 架构: Ampere (2021) 显存: 48GB GDDR6 | 带宽 696GB/s 计算性能: FP32 37.4 TFLOPS | FP16 149.8 TFLOPS 核心数: 10,752 CUDA + 336 Tensor Core 特性: 支持虚拟化、RT Core（光追）、被动散热 功耗: 300W 定位: 混合渲染与AI推理（如云游戏、虚拟化）。 优势: Ampere架构 + 第三代Tensor Core，FP16算力 149.8 TFLOPS，48GB GDDR6显存，支持虚拟化和光追。 局限: 显存带宽（696GB/s）低于HBM系列，适合混合渲染与推理。 场景: 云推理、虚拟化、轻量级训练。 V100 (Volta架构) # 架构: Volta (2017) 显存: 16GB/32GB HBM2 | 带宽 900GB/s 计算性能: FP32 14 TFLOPS | FP16 112 TFLOPS（Tensor Core） 核心数: 5,120 CUDA + 640 Tensor Core（第一代） 特性: NVLink 2.0（300GB/s） 功耗: 250W 定位: 经典深度学习卡，仍广泛用于推理和小规模训练。 优势: Volta架构 + 第一代Tensor Core，FP16算力 112 TFLOPS，HBM2显存带宽 900GB/s。 局限: 架构较老，稀疏计算支持有限。 场景: 经典推理任务、兼容性要求高的场景。 RTX 4090 (Ada Lovelace架构) # 架构: Ada Lovelace (2022) 显存: 24GB GDDR6X | 带宽 1TB/s 计算性能: FP32 82.6 TFLOPS | FP16 1321 TFLOPS（稀疏） 核心数: 16,384 CUDA + 512 Tensor Core（第四代） 功耗: 450W 定位: 单卡最强FP32性能，适合本地AI开发，但无ECC显存和NVLink。 优势: Ada架构 + 第四代Tensor Core，FP16算力 1,321 TFLOPS（稀疏），GDDR6X显存带宽 1TB/s，单卡FP32性能最强（82.6 TFLOPS）。 局限: 无ECC显存、不支持NVLink，显存容量（24GB）和带宽弱于H100/A100。 场景: 小规模训练、本地AI开发。 A30 (Ampere架构) # 架构: Ampere (2021) 显存: 24GB HBM2 | 带宽 933GB/s 计算性能: FP32 10.3 TFLOPS | FP16 82.5 TFLOPS 核心数: 3,584 CUDA + 112 Tensor Core 特性: 支持MIG、低功耗 功耗: 165W 定位: 高密度推理、边缘服务器。 优势: Ampere架构 + 第三代Tensor Core，FP16算力 82.5 TFLOPS，24GB HBM2显存，低功耗（165W）。 局限: 算力较低，适合高密度推理。 场景: 边缘服务器、批量推理。 架构 # 消费级显卡 # 国产 # CPU和GPU区别 # 集显和独显 # ASIC # TPU # NPU # DPU # 华为昇腾（Ascend） # FPGA # 参考 # AI芯片基础知识 "},{"id":14,"href":"/zh/docs/Other/linux/","title":"Linux","section":"Other","content":" .sh脚本 # shebang开头特殊行 # 这行告诉系统应该使用哪个解释器来执行脚本\n#!/bin/bash #! 是shebang的标识符，后面跟着解释器的路径\n对于Python脚本#!/usr/bin/env python3.使用 /usr/bin/env 是为了确保系统能够在任何安装了Python的位置找到Python解释器，而不是硬编码路径。\n设置参数 # #!/bin/bash verisim=/home/public/software/verisim/bin/verisim if [ \u0026#34;$1\u0026#34; == \u0026#34;--case\u0026#34; ]; then if [ -n \u0026#34;$2\u0026#34; ]; then Case=$2; else echo \u0026#34;Error! No case at provided after --case\u0026#34; exit 1 fi else echo \u0026#34;run without appoint testcase\u0026#34; #Case=../testcase/gate_2000_2000_100.v #Case=../testcase/gate_1000_1000_50.v #Case=../testcase/gate_500_500_50.v #Case=../testcase/gate_200_200_20.v #Case=../testcase/gate_100_100_20.v #Case=../testcase/gate_40_40_10.v #Case=../testcase/gate_30_30_10.v #Case=../testcase/gate_20_20_10.v Case=../testcase/gate_20_20_5.v fi export Case #设为环境变量，这样就可以在代码里面获得，eg: char *env_name = getenv(\u0026#34;Case\u0026#34;); //get case from env_var #以下是关于这个项目的编译的相关指令，无关 CFile=setUpSystemFunc_verisim.cpp PliMap=../code/systf.tab rm -rf verisim_history.db verisim.env verisim.db verisim_work verisim.log ${verisim} +acc+c ${Case} -P ${PliMap} ${CFile} -no-mold rm -rf verisim_history.zdb verisim.env verisim.zdb verisim_work verisim.log #eg: ./run.sh --case ../testcase/gate_100_100_20.v 输出重定向 # 循环 # #!/bin/bash export PATH=IVERILOG_PATH/bin:${PATH} VPI=myvpi # 定义一个包含所有测试案例的数组 cases=( \u0026#34;../testcase/test.v\u0026#34; \u0026#34;../testcase/gate_20_20_5.v\u0026#34; \u0026#34;../testcase/gate_20_20_10.v\u0026#34; \u0026#34;../testcase/gate_30_30_10.v\u0026#34; \u0026#34;../testcase/gate_40_40_10.v\u0026#34; \u0026#34;../testcase/gate_100_100_20.v\u0026#34; \u0026#34;../testcase/gate_200_200_20.v\u0026#34; \u0026#34;../testcase/gate_500_500_50.v\u0026#34; \u0026#34;../testcase/gate_1000_1000_50.v\u0026#34; ) # 循环遍历所有的测试案例 for Case in \u0026#34;${cases[@]}\u0026#34;; do echo \u0026#34;Running case: $Case\u0026#34; # 清理之前的文件 rm -rf *.vvp *.vpi obj_dir *.o myvpi.c # 触摸VPI的C文件 touch ${VPI}.c # 编译Verilog文件和VPI文件 iverilog \u0026#34;$Case\u0026#34; -o testcase.vvp iverilog-vpi -L. ${VPI}.c ./setUpSystemFunc_iverilog.cpp ./loopchecker.h -o testcase.vvp # 运行模拟 vvp -M. -m ${VPI} testcase.vvp # 清理生成的文件 rm -rf *.vvp *.vpi obj_dir *.o ${VPI}.c done echo \u0026#34;All cases have been run.\u0026#34; 提升权限直接运行 # #查看脚本权限 ls -l yourscript.sh #改变权限 chmod +x yourscript.sh chmod 755 yourscript.sh 7 代表 rwx（读、写、执行） 6 代表 rw-（读、写） 5 代表 r-x（读、执行） 4 代表 r\u0026ndash;（读）\n环境变量 # 程序（操作系统命令和应用程序）的执行都需要运行环境，这个环境是由多个环境变量组成的\n种类 # 系统环境变量：公共的，对全部的用户都生效。\n用户环境变量：用户私有的、自定义的个性化设置，只对该用户生效。\n永久环境变量：在环境变量脚本文件中配置，用户每次登录时会自动执行这些脚本，相当于永久生效。\n临时环境变量：使用时在Shell中临时定义，退出Shell后失效\n查看环境变量 # env\t#查看所有环境变量 env|grep relate_name #用grep筛选和relate_name相关的环境变量 #常用的 echo $LD_LIBRARY_PATH #C/C++语言动态链接库文件搜索的目录，它不是Linux缺省的环境变量，但对C/C++程序员来说非常重要 echo $LANG #Linux系统的语言、地区、字符集 echo $SHELL#用户当前使用的Shell解析器。通常为/bin/bash echo $HOSTNAME#106服务器是 user_super_server echo $HISTSIZE#保存历史命令的数目 echo $USER echo $PWD#当前工作目录 echo $CLASSPATH#JAVA语言库文件搜索的目录，它也不是Linux缺省的环境变量，但对JAVA程序员来说非常重要 设置环境变量 # export var var=\u0026#39;值\u0026#39; #或export var=\u0026#39;值\u0026#39; #在.bashrc等文件中写了后，需要source再能生效 如果环境变量的值没有空格等特殊符号，可以不用单引号包含。\n采用export设置的环境变量，在退出Shell后就会失效，下次登录时需要重新设置。如果希望环境变量永久生效，需要在登录脚本文件中配置。\n变量名=\u0026#39;值\u0026#39; export 变量名 或export 变量名=\u0026#39;值\u0026#39; 设置系统环境变量 # 在/etc/profile文件中设置 # 用户登录时执行/etc/profile文件中设置系统的环境变量。但是，Linux不建议在/etc/profile文件中设置系统环境变量。\n在/etc/profile.d目录下设置 # 可以对不同的项目用.sh/.csh文件设置环境变量\n这是Linux推荐的方法，不想要什么变量直接删除 /etc/profile.d下对应的 shell 脚本即可\n在/etc/bashrc文件中设置环境变量 # 该文件配置的环境变量将会影响全部用户使用的bash shell。但是，Linux也不建议在/etc/bashrc文件中设置系统环境变量。\n设置用户环境变量 # .bash_profile 当用户登录时执行，每个用户都可以使用该文件来配置专属于自己的环境变量。 但是现在没了？ .bashrc 当用户登录时以及每次打开新的Shell时该文件都将被读取，不推荐在里面配置用户专用的环境变量，因为每开一个Shell，该文件都会被读取一次，效率肯定受影响。 但是现在都这么做0.0 PATH # 可执行程序的搜索目录，可执行程序包括Linux系统命令和用户的应用程序。如果可执行程序的目录不在PATH指定的目录中，执行时需要指定目录。 PATH环境变量存放的是目录列表，目录之间用冒号:分隔 最后的圆点.表示当前目录(加入了当前补录到PATH),如果PATH变量中没有包含圆点.，执行当前目录下的程序需要加./或使用绝对路径 PATH缺省包含了Linux系统命令所在的目录（/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin），如果不包含这些目录，Linux的常用命令也无法执行（要输入绝对路径才能执行） /usr/bin里面有很多可执行文件 在用户的.bashrc文件中，会对PATH进行扩充 比如：export PATH=$PATH:$HOME/bin LD_LIBRARY_PATH # C/C++语言动态链接库文件搜索的目录\n与PATH的格式相同\n参考 # linux环境变量 - a龙 - 博客园 (cnblogs.com)\n安装方式的不同 # 使用apt：\n更新软件包列表：sudo apt update\n安装软件包：sudo apt install package_name\n卸载软件包：sudo apt remove package_name\n查看安装过的包：apt list --installed\n使用apt-get（较旧的Ubuntu版本中常用）：\n更新软件包列表：sudo apt-get update\n安装软件包：sudo apt-get install package_name\n卸载软件包：sudo apt-get remove package_name\n使用dpkg（直接操作.deb包）：\n安装.deb文件：sudo dpkg -i package_name.deb\n卸载软件包：sudo dpkg -r package_name\n使用pip（Python包管理工具）：\n安装Python包：sudo pip install package_name\n卸载Python包：sudo pip uninstall package_name\n使用make和源代码（用于安装从源代码编译的软件）：\n通常需要先./configure，然后make，最后sudo make install\npip和pip3 # pip install [package-name] # 安装名为[package-name]的包 pip install [package-name]==X.X # 安装名为[package-name]的包并指定版本X.X pip install [package-name] --proxy=代理服务器IP:端口号 # 使用代理服务器安装 pip install [package-name] --upgrade # 更新名为[package-name]的包 pip uninstall [package-name] # 删除名为[package-name]的包 pip list # 列出当前环境下已安装的所有包 远程方法 # xrdp # 利用xrdp实现Windows远程连接Kali Linux桌面-百度开发者中心 (baidu.com)\n日志输出在 /var/log/xrdp.log 和 /var/log/xrdp-sesman.log。\nsudo ufw allow from your_ip/24 to any port 3389\nvnc # windows环境安装VNC及远程连接linux(centos7) - 银河星光 - 博客园 (cnblogs.com)\nvnc和ssh的区别 # 主要区别：VNC服务器和SSH服务器有一些显著的区别。 首先，VNC服务器提供图形界面的远程访问和控制，可以让用户直观地操作计算机。 而SSH服务器主要用于远程命令行访问和文件传输，对于不需要图形界面的操作更为适用。 其次，VNC服务器在传输图形界面时消耗较多的网络带宽，因为它需要传输图像数据。 相比之下，SSH服务器的传输开销较小，因为它主要传输文本和命令。 此外，SSH服务器采用了加密和身份验证机制，提供了更高的安全性，而VNC服务器的安全性相对较弱，需要通过额外的措施来增强其安全性。 使用场景：VNC服务器适合需要通过图形界面进行远程操作的场景，例如远程协助、远程教学和讲座、远程演示等\nmobaxterm启用X server # WSL # MobaXterm上默认设置就好，根据提示在设置中开启一个东西。。\nMobaXterm的Xserver是在win上的，而WSL的ip和win不一样，所以不能通过直接设置DISPLAY=0.0或者DISPLAY=localhost:0.0来指定Xserver\n#bashrc export windows_host=`ipconfig.exe | grep -n4 WSL | tail -n 1 | awk -F\u0026#34;:\u0026#34; \u0026#39;{ print $2 }\u0026#39; | sed \u0026#39;s/^[ \\r\\n\\t]*//;s/[ \\r\\n\\t]*$//\u0026#39;` export DISPLAY=$windows_host:0 #也可以直接export DISPLAY=${window_ip}:0 #比如export DISPALY=192.168.1.28:0.0 # 192.168.1.28为windows当前ip，下次重连网络可能会变动 #还看到以下这个，没验证过 #export DISPLAY=$(awk \u0026#39;/nameserver / {print $2; exit}\u0026#39; /etc/resolv.conf 2\u0026gt;/dev/null):0 # in WSL 2 #export LIBGL_ALWAYS_INDIRECT=1 pycharm设置DISPLAY # 将本地文件复制到另一台服务器 # 【教程】通过SFTP将本地文件复制到另一台服务器\nbsub # bsub 是一个在许多 Unix-like 系统中用于提交作业到批处理系统（如 LSF、PBS 或 Slurm）的命令。它允许用户在后台运行程序，而不会占用终端。\nbsub \u0026lt; job_script.sh #提交任务 bsub -n 4 \u0026lt; job_script.sh\t#指定使用的节点数 bsub -R \u0026#34;span[hosts=1]\u0026#34; \u0026lt; job_script.sh #指定使用的CPU核心数 bkill \u0026lt;job_id\u0026gt; #终止 bjobs #查看作业状态 bjobs -l\t#详细信息 bqueues #查看队列状态 bhosts\t#查看系统资源 bsub -W 01:00 \u0026lt; job_script.sh #设置作业的运行时间限制 "},{"id":15,"href":"/zh/docs/Other/Literature/","title":"Literature","section":"Other","content":" 喜剧 # 夏洛特烦恼 年会不能停 三傻大闹宝莱坞 无厘头 # 欧洲性旅行 情景喜剧 # 生活大爆炸 爱情公寓(1-4s) 老友记 请回答1988 是，大臣 是，首相 笑傲江湖 龙门镖局 IT狂人 科幻 # 星际穿越\n三体\n彗星来的那一夜\nMoon\n安德的游戏\n文艺/剧情 # 走走停停 万箭穿心 天下无贼 漫长的季节 小巷人家 心灵捕手 时空恋旅人 爆裂鼓手 大佛普拉斯 同学麦娜丝 搏击俱乐部 风平浪静 错会半生 那山那人那狗 大象席地而坐 心灵捕手 破·地狱（The Last Dance） 超市夜未眠 何以为家 悬疑 # 福尔摩斯探案集 神探夏洛克 看不见的客人 消失的爱人 利刃出鞘 因果报应 历史/社会/生活 # 霸王别姬 泰坦尼克号 红高粱 我不是药神 茶馆 活着 山河故人 "},{"id":16,"href":"/zh/docs/Other/makefile/","title":"Makefile","section":"Other","content":" Makefile # xxx.mk 文件或者 Makefile 都统称为 Makefile 脚本文件\n功能：指导 Make 软件控制 arm-gcc 等工具链去编译工程文件最终得到可执行文件\n基础规则 # 目标：依赖条件 命令\t拓展\n#.mk-V0 #根据工作原理，如果只改变其中一个文件，就只会编译这个文件 hello: main.cpp printhello.cpp factorial.cpp g++ -o hello main.cpp printhello.cpp factorial.cpp #.mk-V1 #使用变量CXX、TARGET 、OBJ，同时采用不同的依赖分别编译 #根据工作原理，如果只改变其中一个文件，就只会编译这个文件 CXX = g++ TARGET = hello OBJ = main.o printhello.o factorial.o $(TARGET): $(OBJ) $(CXX) -o $(TARGET) $(OBJ) main.o: main.cpp $(CXX) -c main.cpp printhello.o: printhello.cpp $(CXX) -c printhello.cpp factorial.o: factorial.cpp $(CXX) -c factorial.cpp ##.mk-V2: ALL #makefile 默认第一个目标文件为终极目标，生成就跑路，这时候可以用 ALL 来指定终极目标。 CXX = g++ TARGET = hello OBJ = main.o printhello.o factorial.o ALL : $(TARGET) $(TARGET): $(OBJ) $(CXX) $(OBJ) -o $(TARGET) main.o: main.cpp $(CXX) -c main.cpp printhello.o: printhello.cpp $(CXX) -c printhello.cpp factorial.o: factorial.cpp $(CXX) -c factorial.cpp #.mk-V3: wildcard \u0026amp; patsubst src = $(wildcard ./*.c) #匹配当前工作目录下的所有.c 文件 obj = $(patsubst %.c, %.o, $(src)) # 将参数 3 中，包含参数 1 的部分，替换为参数 2 ### CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) main.o: main.cpp $(CXX) -c main.cpp printhello.o: printhello.cpp $(CXX) -c printhello.cpp factorial.o: factorial.cpp $(CXX) -c factorial.cpp $(TARGET): $(obj) $(CXX) $(obj) -o $(TARGET) #.mk-V4: clean src = $(wildcard ./*.c) #匹配当前工作目录下的所有.c 文件 obj = $(patsubst %.c, %.o, $(src)) # 将参数 3 中，包含参数 1 的部分，替换为参数 2 ### CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) main.o: main.cpp $(CXX) -c main.cpp printhello.o: printhello.cpp $(CXX) -c printhello.cpp factorial.o: factorial.cpp $(CXX) -c factorial.cpp $(TARGET): $(obj) $(CXX) $(obj) -o $(TARGET) clean : -rm -rf $(obj) $(TARGET)# “-” ：作用是，删除不存在文件时，不报错。顺序执行结束。 #.mk-V5: 三个自动变量 $@\t# 在规则的命令中，表示规则中的目标。 $^\t# 在规则的命令中，表示所有依赖条件。组成一个列表，以空格隔开，如果这个列表中有重复项，则去重 $\u0026lt;\t# 在规则的命令中，表示第一个依赖条件。如果将该变量应用在模式规则中，它可将依赖条件列表中的依赖依次取出，套用模式规则。 CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) main.o: main.cpp $(CXX) -c $\u0026lt; printhello.o: printhello.cpp $(CXX) -c $\u0026lt; factorial.o: factorial.cpp $(CXX) -c $\u0026lt; $(TARGET): $(obj) $(CXX) $^ -o $@ clean : -rm -rf $(obj) $(TARGET) #.mk-V6: 模式规则 #要添加一个.cpp文件，不需要在 makefile 里面增加这个文件的 -o 的部分 CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) %.o : %.c $(CXX) -c $\u0026lt; -o $@ $(TARGET): $(obj) $(CXX) $^ -o $@ clean : -rm -rf $(obj) $(TARGET) #.mk-V7: 静态模式规则？？ #使用静态模式规则，就是指定模式规则给谁用，这里指定模式规则给 obj 用，以后文件多了，文件集合会有很多个，就需要指定哪个文件集合用什么规则 CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) $(obj) : %.o : %.c $(CXX) -c $\u0026lt; -o $@ $(TARGET): $(obj) $(CXX) $^ -o $@ clean : -rm -rf $(obj) $(TARGET) #.mk-V8: 伪目标 #当前文件夹下有 ALL 文件或者 clean 文件时，会导致 makefile 瘫痪，此时使用.PHONY: clean ALL .PHONY: clean ALL CXX = g++ TARGET = hello src = $(wildcard *.cpp) obj = $(patsubst %.cpp, %.o, $(src)) ALL : $(TARGET) $(obj) : %.o : %.c $(CXX) -c $\u0026lt; -o $@ $(TARGET): $(obj) $(CXX) $^ -o $@ clean : -rm -rf $(obj) $(TARGET) #.mk-V9: 文件分类 #将上述 .cpp 文件都放到 src 目录中，.h 文件都放在 inc 目录中 CXX = g++ TARGET = hello src = $(wildcard ./src/*.cpp) obj = $(patsubst ./src/%.cpp, ./obj/%.o, $(src)) inc_path = ./inc CXXFLAGS = -Wall -c -I$(inc_path) ALL : $(TARGET) ./obj/%.o : ./src/%.cpp $(CXX) $(CXXFLAGS) $\u0026lt; -o $@ $(TARGET): $(obj) $(CXX) $^ -o $@ clean : -rm -rf $(obj) $(TARGET) .PHONY: clean make 的参数 # -n：模拟执行 make、 make clean 命令。仅输出执行过程中的命令序列，但并不执行。 -f：指定文件执行 make 命令。 xxxx.mk -j：可以并行构建多个目标，加快构建速度 -s‌ 或 ‌**\u0026ndash;silent‌ 或 ‌\u0026ndash;quiet**‌：不显示命令。 Makefile 语法 # 使用echo进行printf\n:=\t# 即时变量 = # 延时变量 ?= # 延时变量，如果是第 1 次定义才起效，如果在前面该变量已定义则忽略这句 += # 附加，他是即时变量还是延时变量取决于前面的定义，中间会有空格，加在后面\nMakefile 函数 # wildcard 函数 格式： $ (wildcard PATTENR) 展开指定的目录\nnotdir 函数 格式： $ (notdir $ (var) ) 去掉路径。\ndir 函数: $(dir ) 取出目录\npatsubst 函数:$(patsubst 原文件，目标文件，文件列表）替换\nforeach 函数: 格式：$（foreach ,,）功能:把参数 中的单词逐一取出放到参数 所指定的变量中，然后再执行 所包含的表达式。每一次 会返回一个字符串\n编译标志\n-O2：优化代码。 -g：包含调试信息。 -Wall：开启所有警告。 -std=c++11：指定使用 C++11 标准。 -I：指定包含（头文件）搜索路径。 -L：指定库文件搜索路径。 -l：指定链接时使用的库。 参考 # makefile文件基本语法-CSDN博客\nCMake # 用于生成make文件\n同类产品：XMake\ncmake_minimum_required (VERSION 2.8)#lowest version requirement project (learn_cmake) #project name add_executable(hello hello.cpp)#要生成的可执行文件名为hello，后面的参数是需要的依赖 aux_source_directory(./your_src_dir var)#把dir目录中的所有源文件都储存在var变量中, 用“${var}”替换上面的hello.cpp.如果分别在多个文件，那么可以多次使用aux_source_directory include_directories ( ./your_inc_dir )#他的作用是 自动去dir目录下寻找头文件，相当于 gcc中的 gcc -I dir cmake . #执行CMakeLists.txt #之后会生成Makefile make #执行Makefile 案例1 # PROJECT_BINARY_DIR是cmake系统变量，意思是执行cmake命令的目录，我们计划在build目录下执行cmake命令，所以这个变量也就等同于build目录 set_target_properties重新定义了库的输出名称，如果不使用set_target_properties也可以，那么库的名称就是add_library里定义的名称。具体可以参考官方文档 LIBRARY_OUTPUT_PATH 是cmake系统变量，项目生成的库文件都放在这个目录下。这里我指定库生成到lib目录。 场景2 # "},{"id":17,"href":"/zh/docs/Other/network/","title":"Network","section":"Other","content":" 基础知识 # IP # IP地址可唯一标识 IP 网络中的每台设备 每台主机（计算机、网络设备、外围设备）必须具有唯一的地址 网络地址 + 主机地址\n子网掩码 # 区分主机ID和网络ID 举例：当子网掩码=255.255.255.0时： 192.168.100.168（IP地址） = 192.168.1.0 (网络地址) + 0.0.0.168（主机地址） 用网线直接连接 或 通过 HUB（集线器）、普通交换机链接的计算机必须处于同一网络(网络地址) 并且主机地址必须不一样 才能通信。\n如何判断两个主机在同一网段 # 假设有两个主机A和B，它们的IP地址和子网掩码如下：\n主机A的IP地址：192.168.1.2\n主机A的子网掩码：255.255.255.0\n主机B的IP地址：192.168.1.5\n主机B的子网掩码：255.255.255.0\n步骤1：应用子网掩码 对于主机A：\nIP地址：192.168.1.2 转换为二进制是 11000000.10101000.00000001.00000010 子网掩码：255.255.255.0 转换为二进制是 11111111.11111111.11111111.00000000 进行AND运算：\n11000000.10101000.00000001.00000010 (IP地址) 11111111.11111111.11111111.00000000 (子网掩码) 11000000.10101000.00000001.00000000 (网络地址) 转换回十进制，网络地址为：192.168.1.0\n对于主机B：\nIP地址：192.168.1.5 转换为二进制是 11000000.10101000.00000001.00000101 子网掩码：255.255.255.0 转换为二进制是 11111111.11111111.11111111.00000000 进行AND运算：\n11000000.10101000.00000001.00000101 (IP地址) 11111111.11111111.11111111.00000000 (子网掩码) 11000000.10101000.00000001.00000000 (网络地址) 转换回十进制，网络地址为：192.168.1.0\n步骤2：比较网络地址 由于两个主机的网络地址都是192.168.1.0，因此它们在同一网段。\n结论 通过上述步骤，我们可以判断两个主机是否在同一网段。在这个例子中，主机A和主机B都在192.168.1.0/24这个网段中。\n##网关 连接两个不同的网络的设备都可以叫网关设备；网关的作用就是实现两个网络之间进行通讯与控制。 网关设备可以是 交互机（三层及以上才能跨网络）、路由器、启用了路由协议的服务器、代理服务器、防火墙等 网关地址就是网关设备的IP地址\n如果网络A中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络B的网关 只有设置好网关的IP地址，TCP/IP协议才能实现不同网络之间的相互通信 一台主机可以有多个网关。默认网关的意思是一台主机如果找不到可用的网关，就把数据包发给默认指定的网关，由这个网关来处理数据包。现在主机使用的网关，一般指的是默认网关。\nDHCP # Dynamic Host Configuration Protocol, 动态主机配置协议 自动设置就是利用DHCP（Dynamic Host Configuration Protocol, 动态主机配置协议）服务器来自动给网络中的计算机分配IP地址、子网掩码和默认网关 。 一旦网络的默认网关发生了变化时，只要更改了DHCP服务器中默认网关的设置，那么网络中所有的计算机均获得了新的默认网关的IP地址。这种方法适用于网络规模较大、TCP/IP参数有可能变动的网络。 另外一种自动获得网关的办法是通过安装代理服务器软件的客户端程序来自动获得，其原理和方法和DHCP有相似之处。\n两个主机通信 # 条件： # 知道对方ip 是否双方在同一网段下 在同一网段：arp广播 不同网段：找网关，若未配置，则无法通行 通信时是用自己的子网掩码与对方ip相与，因为通信时不知道对方子网掩码 举例： A的IP地址: 192.168.38.100 A的子网掩码: 255.255.255.128 B的IP地址: 192.168.38.200 B的子网掩码: 255.255.255.0 ① A \u0026ndash;\u0026gt; B 以A的子网掩码为基准 192.168.38.0110 0100 \u0026amp; 255.255.255.1000 0000=192.168.38.0 192.168.38.1100 1000 \u0026amp; 255.255.255.1000 0000=192.168.38.128 ip-A 与 ip-B分别与A主机子网掩码相与，不相同，则不在同一网段 ② B \u0026ndash;\u0026gt; A(以B的子网掩码为基准) 192.168.38.0110 0100 \u0026amp; 255.255.255.0000 0000=192.168.38.0 192.168.38.1100 1000 \u0026amp; 255.255.255.0000 0000=192.168.38.0 ip-A 与 ip-B分别与B主机子网掩码相与，相同，则在同一网段 ##DNS 我们访问一个网站的时候，往往使用的是域名（相对IP来说更加语义清晰、更加容易记忆，例如 www.baidu.com)。 然而计算机之间的通信网络通信是通过IP进行的， 因此需要将域名解析为对应的IP，DNS就是进行域名解析的服务器。 DNS 维护着 域名(domain name)和IP地址 (IP address)的对照表表，以解析消息的域名\n1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。\n2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。\n3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。\n4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。\n5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。\n6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机\n##路由器\n##防火墙 防火墙是一个网络安全产品，它是由软件和硬件设备组合而成，在内网和外网之间、专用网与公共网之间的一种保护屏障。\n软件防火墙和硬件防火墙 # 作用 # 虽然防火墙本身不充当防病毒软件，但它们通过确保只有授权的数据流经网络，确实有助于防止病毒的安装。 防止未经授权访问危险的网站。防火墙还可以阻止访问已知会在访问者的计算机上安装恶意软件和病毒的恶意站点。 阻止未经授权的访问 网关 # 客户端数据发出的，在同一网段没找到目标ip，那么就给网关找\n代理 # Clash # 特色功能 # 入站代理：支持 HTTP、HTTPS、SOCKS5 服务器、TUN 设备等。 出站代理：支持 Shadowsocks(R)、 VMess、 Trojan、Snell、SOCKS5、HTTP(S)、Wireguard 等。 基于规则的路由：可以根据动态脚本、域名、IP 地址、进程名称等规则进行路由。 虚假 IP DNS：可以减少对 DNS 污染的影响，提高网络性能。 透明代理：可以重定向 TCP 流量以及自动管理路由表和规则。 代理组：可以自动切换代理、负载均衡或测试延迟。 远程提供者：可以动态加载远程代理列表。 RESTful API：可以通过全面的 API 更新配置。 桥接和NAT # 桥接（Network Address Translation）\nSSH # SSH包含三个组件ssh,sftp,scp\nUnix、Linux 和 macOS 设备内置SSH客户端，允许从终端直接启动SSH连接，还可以使用SSH客户端（如PuTTY）启动连接。\nWindows 设备启动 SSH 连接，则必须使用 OpenSSH 或 PuTTY 等 SSH 客户端来启动连接\n在服务器端，需要安装 SSH 服务器包，并且需要安装并运行称为 SSH守护进程的服务器端组件，SSH 守护进程通过侦听 TCP 端口 22 上的所有连接来检查任何 SSH 连接请求\n如果使用的是 Linux/macOS设备或Windows设备上的SSH客户端，可以输入以下命令从设备终端启动到远程服务器的SSHl连接:ssh \u0026lt;user_name\u0026gt;@\u0026lt;host_name\u0026gt;\n通信步骤 # 从 SSH 客户端尝试 SSH 会话。 SSH 客户端会连接到目标服务器。 SSH 客户端从 SSH 服务器获取公钥，特别是从 .ssh/authorized_keys 文件中获取公钥。 客户端和服务器协商参数和加密方法，然后使用合适的密钥交换算法制定加密的会话密钥。 然后，用户使用适当的凭据进行身份验证并登录到目标服务器。 现在已建立安全连接，用户可以在服务器上执行操作。 认证方式 # 密码 # 密码身份验证是建立SSH连接时更广泛使用的身份验证方法，共享密钥和加密协商完成后，服务器会提示用户输入客户端正在尝试登录的用户账号的密码。\n密钥 # 使用SSH密钥的身份验证涉及公私非对称SSH密钥对，在对称加密之后，客户端生成密钥对 ID，服务器通过查找用户的.ssh/authorized_keys文件来验证这个ID，如果ID匹配，则使用公钥生成并加密随机数，然后客户端使用其私钥对其解密。\n然后，客户端在对称加密期间使用解密的号码和已建立的共享密钥对号码进行散列处理，并以 MD5 哈希值的形式将其发送回服务器，一旦服务器使用相同的共享密钥和数字自行计算 MD5 哈希值并确定其匹配项，身份验证就完成了。\n多层密钥的身份验证成为一种更安全的加密形式，因为不传输服务器的私钥，并且还需要共享密钥来篡改身份验证。\nOpenSSH # 提供ssh连接服务\n常用命令 # sudo apt-get install openssh-client#客户端 sudo apt-get install openssh-server#服务器 ssh [OPTION] [hostname]@[IP] #连接远程服务器 #可以增加-v打印详细星系 # 链接123.45.67.89这个IP的服务器，然后输入链接密码，验证成功后就可以登陆到服务器了。 $ ssh root@123.45.67.89 # 链接到github.com这个服务器，并且打印链接的详细信息。 $ ssh -v git@github.com #ssh-keygen命令用于生成、管理密钥。 Usage： ssh-keygen [-t rsa|ed25519] [-b bits] [-C comment] [-f output_keyfile] 生成新的密钥。 Or： ssh-keygen -c [-C comment] 修改密钥的备注信息。 -t rsa|ed25519 选择加密方式。有很多种，这里列举两种最常用的方法。更详细的加密方法件官方SSH手册。 -b bits指定密钥长度。对于 RSA密钥，最小要求768位，默认是2048位。DSA密钥必须恰好是1024位(FIPS 186-2 标准的要求)。 -C comment 给密钥添加备注。 -c 要求修改密钥的注释。输入选项后，程序会提示输入私钥文件名、密语（如果存在）、新注释。 -f output_keyfile 指定输出的文件。 #ssh-add 命令用于管理密钥。 Usage：ssh-add [key_file] 添加密钥到密钥管理器中。 or：ssh-add [OPTION]... eg: # 将下面三个文件传输到目标主机的home目录中。 $ scp a.cpp b.java c.py root@123.45.67.89:/home -l 展示出所有已经添加到密钥管理器其中的密钥对。 -d [key] 将 指定密钥对从密钥管理器中移除。 -D 移除密钥管理其中的全部密钥对。 #scp命令 #全称为“OpenSSH secure file copy”——基于OpenSSH的安全文件复制服务。主要用于终端设备之间的文件传输。 Usage：scp [FILE]... [HOST]:[DIR] 配置文件 # Windows系统：c:/ProgramData/ssh/sshd_config Linux系统：/etc/ssh/sshd_config sshd_config 中文手册 金步国\n应用 # 免密登录 # client:\nssh-keygen -t rsa -b 4096 -C \u0026#34;xxx\u0026#34; #生成一对密钥#请使用密钥的默认名字：id_rsa，即按三次回车即可 $ scp %homepath%/.ssh/id_rsa.pub root@123.45.67.89:~/.ssh #将上面生成的密钥中的==公钥==传输到你的Linux云服务器上 server:\nvim /etc/ssh/sshd_config#修改sshd_config #在该配置文件中，主要修改下面两个配置 #PubkeyAuthentication yes #AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2 sudo /etc/init.d/ssh restart#重启OpenSSH服务端 #修改公钥文件名称 cd /root/.ssh mv id_rsa.pub authorized_keys client\nssh root@123.45.67.89 与Git的远程仓库连接 # client:\nssh-keygen -t rsa -b 4096 -C \u0026#34;GithubKey\u0026#34;#请使用密钥的默认名字：id_rsa，即按三次回车即可 git:\n登陆你的Github，然后依次点击：Setting -\u0026gt; SSH and GPG keys -\u0026gt; New SSH Key\n点击 New SSH key 后，将 Step 1 中生成的公钥复制到文字框中，最后点击 Add SSH key 即可添加成功。\nclient:\nssh git@github.com 你在此时开着加速器，例如Steam++，运行命令后，你可能会收到如下的报错信息：\nkex_exchange_identification: read: Software caused connection abort banner exchange: Connection to 127.0.0.1 port 22: Software caused connection abort\n此时，只需要退出加速器即可恢复正常。\nsftp # 它使用SSH身份验证和加密功能来确保文件在传输过程中的安全\ntelnet # 也是同来远程登录服务器的，默认端口 23,一种不加密的明文传输协议，现在用的很少\nFTP # 进行文件传输时使用的协议，文件传输协议【明文传输不加密】默认端口21\nSFTP和FTP非常相似，都支持批量传输，文件移动，文件夹/目录创建，文件删除等. FTP 不提供任何安全通道来在主机之间传输文件；而SFTP协议提供了一个安全通道，用于在网络上的主机之间传输文件。\nX11 # X11（X Window System）是一种位图显示的视窗系统，X表示X协议，11是协议版本号。X 协议主要由 X server 和 X client 组成\n术语客户端-服务器——你的终端是\u0026quot;服务器\u0026quot;，而应用程序是 “客户端”——这一概念经常困扰X的新用户。本地的X显示程序提供显示服务，所以它扮演了服务器；远端应用程序使用了该服务，所以它是客户端。\n例如我通过ssh-X来启动X11 forwarding:连接到远程服务器，远程服务器有python程序调用 matplotlib绘制图形，那这个时候服务器端的程序就是X应用程序，他通过X协议告诉我们本地的 Xserver如何在我们本地的电脑上显示图形（如果我们本地安装有相应的X11实现的话）。\nSSL # "},{"id":18,"href":"/zh/docs/Other/Program/","title":"Program","section":"Other","content":" C/C++ # key word # extern # extern可以置于变量或者函数前,以标示变量或者函数的定义在别的文件中,提示编译器遇到此变量和函数时在其他模块中寻找其定义。此外extern也可用来进行链接指定\nregister # union # volatile # C++ only keywords # class # #include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; class Person { private://私有成员只能在类内部访问。 string name; int age; public://公有成员可以在类外部访问。 //static 关键字可以用于类成员变量或成员函数，表示它们属于类本身，而不是类的某个特定对象 static int totalPopulation; //构造函数是一种特殊的成员函数，用于初始化对象。它与类同名，没有返回类型，也不返回任何值。 Person(string n, int a) : name(n), age(a) { totalPopulation++; // 每次创建新对象时增加人数 } // 构造函数 virtual void display() const {//如果你想在派生类中重写基类的虚函数，基类的函数必须被声明为 virtual cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#34;, Age: \u0026#34; \u0026lt;\u0026lt; age \u0026lt;\u0026lt; endl; } friend void displayPerson(const Person \u0026amp;p);//友元函数是类外部的函数，可以访问类的私有和保护成员。 //操作符重载 Person\u0026amp; operator++() { // 前置++ ++age; return *this; } //操作符重载 Person operator++(int) { // 后置++ Person temp = *this; ++(*this); return temp; } //静态函数 static void displayTotalPopulation() { cout \u0026lt;\u0026lt; \u0026#34;Total population: \u0026#34; \u0026lt;\u0026lt; totalPopulation \u0026lt;\u0026lt; endl; } ~Person() { totalPopulation--; // 每次析构对象时减少人数 } // 析构函数用于在对象生命周期结束时进行清理工作。它与类同名，前面加上 ~，没有参数，也没有返回类型。 }; int Person::totalPopulation = 0; // 静态成员变量的初始化! void displayPerson(const Person \u0026amp;p) {//友元函数, 在类内声明过了，可以访问类的私有和保护成员。 cout \u0026lt;\u0026lt; \u0026#34;Name: \u0026#34; \u0026lt;\u0026lt; p.name \u0026lt;\u0026lt; \u0026#34;, Age: \u0026#34; \u0026lt;\u0026lt; p.age \u0026lt;\u0026lt; endl; } //继承 class Student : public Person { private: string school; public: Student(string n, int a, string s) : Person(n, a), school(s) {} void display() const override { Person::display(); cout \u0026lt;\u0026lt; \u0026#34;School: \u0026#34; \u0026lt;\u0026lt; school \u0026lt;\u0026lt; endl; } }; int main() { Person person(\u0026#34;Alice\u0026#34;, 30); person.display(); //通过基类指针或引用调用派生类 Person *p1 = new Person(\u0026#34;Alice\u0026#34;, 30); Person *p2 = new Student(\u0026#34;Bob\u0026#34;, 20, \u0026#34;MIT\u0026#34;); p1-\u0026gt;display(); p2-\u0026gt;display(); cout\u0026lt;\u0026lt; \u0026#34;total population = \u0026#34; \u0026lt;\u0026lt; Person::totalPopulation \u0026lt;\u0026lt;endl; Person::displayTotalPopulation(); delete p1; delete p2; ++person; person.display(); person++; person.display(); displayPerson(person);//友元函数 return 0; } //类模板允许你创建通用类，可以处理任何数据类型。 template \u0026lt;typename T\u0026gt; class Stack { private: std::vector\u0026lt;T\u0026gt; elements; public: void push(const T\u0026amp; element) { elements.push_back(element); } T pop() { T elem = elements.back(); elements.pop_back(); return elem; } }; int main() { Stack\u0026lt;int\u0026gt; intStack; intStack.push(1); intStack.push(2); std::cout \u0026lt;\u0026lt; intStack.pop() \u0026lt;\u0026lt; std::endl; // 输出 2 std::cout \u0026lt;\u0026lt; intStack.pop() \u0026lt;\u0026lt; std::endl; // 输出 1 return 0; } copy，move构造函数，\n左/右值引用 # 左值引用\u0026amp; # 右值引用\u0026amp;\u0026amp; # 一次性使用：右值引用只能绑定到右值上，一旦绑定，原始的右值就不能再被使用。 移动语义：右值引用允许你转移资源的所有权，而不是复制资源。这是通过移动构造函数和移动赋值运算符实现的。 临时对象：右值引用可以用来延长临时对象的生命周期，使其可以被多次使用。 完美转发：右值引用在模板编程中用于完美转发参数，这样可以保留参数的左值或右值性质。 指针 # 野指针和空指针 # 空指针: 如 int *p = NULL 这就定义了一个指针，通常NULL是一个零值，操作系统定义内存64kb以下的内存单元是不可访问的，所以像如 *p = 9 这样给他赋值是系统不允许的，将会发生内存报错。\n野指针: 如 int *p就是一个野指针，可以看到它在创建时没有赋初值，所以它的值是一个随机数，也就是乱指一气，通常都是指向了不合法的内存段，所以使用它也会内存报错。还有指针p被free或者delete之后也会成为野指针，因为它所指的内存空间被释放之后，变成了一个不合法内存段。野指针，它顾名思义它就是一个野指针，它是没有主人领养的野兽，凶猛残暴，用它你就得自食其果。\n指针的魅力 # 场景1：使一个字符串颠倒顺序 # void reverse(char *_str,int _l) //反转函数,_l指要反转字串的长度 { char *p=_str,*q=_str+_l-1,temp;\t//指针直接得到值 while(q\u0026gt;p) { temp=*p; *p=*q; *q=temp; p++; q--; } } void reverse(char *_str,int _l) //反转函数,_l指要反转字串的长度 { int i=0,j=_l-1,temp; while(j\u0026gt;i) { temp=str[i]; str[i]=str[j]; str[j]=str[i]; i++; j--; } } 这样并不比上面用迭代器的情况好，而且要糟很多，因为这样用str[i]，str[j]的下标的方式访问元素时，需要先对str所存的数组首地址进行一次加减运算才能正确得到第i个、第j个值（读者可在任何一款编译器上进行反汇编查看），上面一共出现了5次下标访问str元素，情况可想而知。\n场景2：函数传递 # typedef struct structType { int i; char arr[100]; }structType; //一个print函数的定义： void print0(const structType data) { //printf something about data } //另一个print函数的定义： void print1(const structType *pdata) { //printf something about data } print1比print0有明显的效率优势，因为print0是值传递，当值传进去时，必须要开辟一个structType那么大的内存空间来乘装这些值，这就要相当大的一部分资源消耗，而print1是指针传递，传进去的是地址，一个地址只需4字节内存空间，使用时解析其指针即可，因此它比print0更高效更实用。\n场景3 # 在C++中，使用std::vector存储类对象时，你可以选择存储对象的实例（直接存储变量）或者对象的指针。这两种方式各有优缺点：\n直接存储对象（对象实例） # 优点：\n简单易用：不需要管理内存，std::vector会自动管理对象的生命周期。 性能：不需要额外的间接寻址，直接访问对象。 安全性：对象生命周期由std::vector管理，减少了内存泄漏的风险。 缺点：\n拷贝开销：当对象较大时，复制对象可能会有性能开销。 灵活性：如果需要存储不同类型的对象，可能需要使用虚函数和基类指针。 存储对象指针 # 优点：\n灵活性：可以存储不同类型的对象，只要它们继承自同一个基类。 性能：对于大型对象，存储指针可以避免复制开销。 缺点：\n内存管理：需要手动管理对象的内存，容易出错。 间接寻址：访问对象属性或方法时需要额外的间接寻址，可能会有轻微的性能开销。 复杂性：代码复杂度增加，需要考虑对象的创建和销毁。 选择建议 # 如果对象较小且不需要存储多种类型的对象，直接存储对象实例通常更简单、更安全。 如果对象较大或需要存储多种类型的对象，存储指针可能更合适，但需要小心管理内存。 vector\u0026amp;数组\u0026amp;链表与栈\u0026amp;堆 # 数组 # 用来存储固定大小的同类型元素的序列\n特点 # 固定大小：创建时需要指定数组的大小，之后无法更改。 随机访问：可以直接通过索引快速访问任何元素，时间复杂度为 O(1)。 高效的内存利用：由于连续的内存分配，数组在内存利用和访问速度方面非常高效。 插入/删除操作耗时：在数组中间插入或删除元素通常需要移动其他元素，因此这些操作的时间复杂度较高。 数组的限制：数组的大小在声明时必须确定，且不能改变，数组不提供检查越界的机制，访问无效索引可能导致未定义行为。 vector # 向量（Vector，如 std::vector）随机访问快，时间复杂度为 O(1)，插入/删除操作慢，在末尾快，但在中间或开始较慢，内存动态分配，可以根据需要改变大小，但可能涉及复制整个数组到新的内存位置。适用场景：当需要动态数组，即数组大小可以改变的场景，需要随机访问，但也会有在末尾添加或删除元素的操作场景。\n特点 # 动态大小：向量可以在运行时根据需要扩展或缩减其大小。 随机访问：与数组一样，向量支持通过索引的快速随机访问。 自动管理内存：向量在内部管理内存，自动扩展和缩减存储空间。 可能的重新分配开销：当向量扩展到超过当前分配的内存时，它可能需要重新分配整个内存块来存储元素。 由于动态扩容，向量的内存使用可能不如静态数组高效， 在频繁扩容的情况下，性能可能受到影响。 链表 # 链表是一种由节点组成的数据结构，每个节点包含数据和指向下一个节点的指针，链表中的元素不必在内存中连续存储，这种情况下频繁插入和删除时，链表会更加高效，但是不支持随机访问，访问特定索引的元素需要从头开始遍历，效率较低。\nC++ 标准库提供了两种链表类型：std::list：双向链表 和 std::forward_list：单向链表\nstd::forward_list 提供了单向链表的实现，适合于需要频繁在头部插入或删除元素的场景。由于其单向特性，它在内存使用上比 std::list 更高效，但也牺牲了一些灵活性，如无法直接访问前一个元素。\n特点 # 动态大小：链表的大小可以根据需要动态变化。 高效的插入和删除：可以在任何位置快速地插入或删除节点，不需要移动其他元素。 无随机访问：访问链表中的元素需要从头开始遍历，时间复杂度为 O(n)。 额外的内存开销：每个节点需要额外的存储空间来存储指针。 智能指针 # 内存泄漏\u0026amp;悬空指针 # 举例 # void foo(int n) { int* ptr = new int(42); ... if (n \u0026gt; 5) { return; } ... delete ptr; } void other_fn(int* ptr) { ... }; void bar() { int* ptr = new int(42); other_fn(ptr); // ptr == ? } 在foo函数中，如果入参n \u0026gt; 5, 则会导致指针ptr的内存未被正确释放，从而导致内存泄漏。\n在bar函数中，我们将指针ptr传递给了另外一个函数other_fn，我们无法确定other_fn有没有释放ptr内存，如果被释放了，那ptr将成为一个悬空指针，bar在后续还继续访问它，会引发未定义行为，可能导致程序崩溃。\nunique_ptr # 在超出作用域时，会自动释放所管理的对象内存\n#include \u0026lt;memory\u0026gt; #include \u0026lt;iostream\u0026gt; class MyClass { public: MyClass() { std::cout \u0026lt;\u0026lt; \u0026#34;MyClass constructed\u0026#34; \u0026lt;\u0026lt; std::endl; } ~MyClass() { std::cout \u0026lt;\u0026lt; \u0026#34;MyClass destroyed\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { std::unique_ptr\u0026lt;MyClass\u0026gt; ptr1(new MyClass); return 0; } MyClass constructed MyClass destroyed\nshared_ptr # shared_ptr是C++11提供的另外一种常见的智能指针，与unique_ptr独占对象方式不同，shared_ptr是一种共享式智能指针，允许多个shared_ptr指针共同拥有同一个对象，采用引用计数的方式来管理对象的生命周期。当所有的 shared_ptr 对象都销毁时，才会自动释放所管理的对象。\nBugs # 1. # vector var1[m][n];//不行 vector\u0026lt;vector\u0026lt;vector\u0026raquo; var2[m][n]；//可以\n//当wire_max_level和wire_max_sublevel较大(1000）时，初始化第258和259行的 “IntVec dst[wire_max_level][wire_max_sublevel];IntVec dst_ports[wire_max_level][wire_max_sublevel];”会报错：Segmentation fault\n在C++中，这两种声明方式涉及到多维向量的初始化和存储方式，它们之间存在一些关键的差异：\nvector var1[m][n]; 这种声明方式试图在栈上创建一个二维数组，其中每个元素是一个 vector。这种声明是非法的，因为标准C++不支持非静态数组大小的非固定大小数组（non-POD types，即包含构造函数、析构函数、虚函数等的类型）作为数组元素。std::vector 是一个非POD类型，因为它有动态内存管理和其他资源管理的需求。\n问题： 栈溢出：如果 m 和 n 较大，这种声明可能会因为栈空间不足而导致编译错误或运行时错误（如段错误）。 未定义行为：在C++标准中，这种用法是未定义的，因为 vector 需要动态内存分配，而数组的静态内存分配无法满足这一需求。\nvector\u0026lt;vector\u0026lt;vector\u0026raquo; var2[m][n]; 这种声明方式创建了一个三维向量，其中最外层是一个数组，每个元素是一个二维 vector 的向量。尽管这种声明在语法上是合法的，但它仍然存在效率和安全性问题。\n特点： 堆分配：尽管 vector 通常在堆上分配内存，但这种声明方式实际上在栈上创建了一个指向 vector 的指针数组，每个指针指向一个在堆上分配的 vector。 内存管理：这种方式需要手动管理内存，因为数组中的每个 vector 指针都需要适当地构造和析构。 性能问题：每次访问 var2[i][j] 时，实际上涉及到两次内存访问：一次是从数组中获取指针，另一次是从 vector 中访问数据。\n参考 # C++学习之智能指针中的unique_ptr与shared_ptr_C 语言_脚本之家 (jb51.net)\n堆栈(Stack)和堆(Heap) # 内存分配 # 程序的内存布局和组织可能会根据所使用的操作系统和体系结构而有所不同。然而，一般来说，内存可以分为以下几个部分:\n全局段（ Global segment ）：负责存储全局变量和静态变量，这些变量的生命周期等于程序执行的整个持续时间。 代码段（ Code segment ）：也称为文本段，包含组成我们程序的实际机器代码或指令，包括函数和方法。 堆栈（ Stack ）：用于管理局部变量、函数参数和控制信息（例如返回地址） 堆（ Heap ）：提供了一个灵活的区域来存储大型数据结构和具有动态生命周期的对象。堆内存可以在程序执行期间分配或释放 注意：值得注意的是，内存分配上下文中的堆栈和堆不应与数据结构堆栈和堆混淆，它们具有不同的用途和功能。\n堆栈(Stack) # 堆栈简称为栈。\n堆栈存储器的主要特点 # 固定大小： 当涉及到堆栈内存时，其大小保持固定，并在程序执行开始时确定。\n速度优势： 堆栈内存帧是连续的。因此，在堆栈内存中分配和释放内存的速度非常快。这是通过操作系统管理的堆栈指针对引用进行简单调整来完成的。\n控制信息和变量的存储： 堆栈内存负责容纳控制信息、局部变量和函数参数，包括返回地址。\n有限的可访问性： 请务必记住，存储在堆栈内存中的数据只能在活动函数调用期间访问。\n自动管理： 堆栈内存的高效管理由系统本身完成，不需要我们额外的工作。\n举例 # 堆栈段为空\n1共 9 个\n为主函数创建一个新的堆栈帧\n2共 9 个\n在 main 函数的堆栈帧中，局部变量 x 现在的值为 5\n3共 9 个\n调用 add 函数，实际参数为 (5, 10)\n4共 9 个\n控制权转移到 add 函数，为 add 函数创建一个新的堆栈帧，其中包含局部变量 a、b 和 sum\n5共 9 个\nadd 函数的堆栈帧上的 sum 变量被分配 a + b 的结果\n6共 9 个\nadd 函数完成其任务并且其堆栈帧被销毁\n7共 9 个\n具有可变结果的主函数的堆栈帧存储从 add 函数返回的值\n8共 9 个\n在显示结果值（此处未显示）后，主功能块也被销毁，并且堆栈段再次为空\n堆(Heap) # 也称为动态内存\n是内存分配的野孩子。程序员必须手动管理它。堆内存允许我们在程序执行期间随时分配和释放内存。它非常适合存储大型数据结构或大小事先未知的对象。\n举例 # 栈段和堆段为空\n1共 7 个\n为主函数创建一个新的堆栈帧\n2共 7 个\n局部变量值被赋予值 42\n3共 7 个\n在堆上分配了一个指针变量ptr，指针ptr中存放的是分配的堆内存的地址（即0x1000）！\n4共 7 个\nvalue变量中存储的值（即42）被赋值给ptr指向的内存位置（堆地址0x1000）\n5共 7 个\n堆上地址 0x1000 处分配的内存被释放\n6共 7 个\nmain函数的栈帧从栈中弹出（显示result的值后），栈段和堆段再次清空\n7共7 个\n第 3 行： main 调用该函数，并为其创建一个新的堆栈帧。 第 5 行： 堆栈帧上的局部变量 value 被赋值为 42 。 第 8 行： ptr 使用关键字为堆上的单个整数动态创建的内存分配给指针变量 new 。我们假设堆上新内存的地址为 0x1000。分配的堆内存的地址（0x1000）存储在指针中。 ptr 。 第 11 行： 将整数值 42 分配给 ptr （堆地址 0x1000）所指向的内存位置。 第 12 行：( ptr )指向的内存位置存储的值 42 被打印到控制台。 第 15 行： 使用关键字释放在堆上地址 0x1000 处分配的内存 delete 。在此行之后， ptr 成为悬空指针，因为它仍然保存地址 0x1000，但该内存已被释放。然而，对于这个重要的讨论，我们不会详细讨论悬空指针。 第17行： main函数返回0，表示执行成功。 第 18 行： 从堆栈中弹出主函数的堆栈帧，并释放所有局部变量 ( value 和)。 ptr 注意：C++ 标准库还提供了一系列智能指针，可以帮助自动化堆中内存分配和释放的过程。\n特征 # 大小的灵活性： 堆内存大小可以在程序执行过程中发生变化。 速度权衡： 在堆中分配和释放内存速度较慢，因为它涉及寻找合适的内存帧和处理碎片。 动态对象的存储： 堆内存存储具有动态生命周期的对象和数据结构，如 new Java 或 C++ 中使用关键字创建的对象和数据结构。 持久数据： 存储在堆内存中的数据将一直保留在那里，直到我们手动释放它或程序结束。 手动管理： 在某些编程语言（例如C和C++）中，必须手动管理堆内存。如果处理不当，可能会导致内存泄漏或资源使用效率低下。 对比 # 大小管理： 堆栈内存具有在程序执行开始时确定的固定大小，而堆内存是灵活的，可以在程序的整个生命周期中更改。 速度： 堆栈内存在分配和释放内存时具有速度优势，因为它只需要调整引用。相反，由于需要定位合适的内存帧并管理碎片，堆内存操作速度较慢。 存储目的： 堆栈内存指定用于控制信息（例如函数调用和返回地址）、局部变量和函数参数（包括返回地址）。另一方面，堆内存用于存储具有动态生命周期的对象和数据结构，例如 new Java 或 C++ 中使用关键字创建的对象和数据结构。 数据可访问性： 堆栈内存中的数据只能在活动函数调用期间访问，而堆内存中的数据在手动释放或程序结束之前仍然可以访问。 内存管理： 系统自动管理堆栈内存，优化其使用，以实现快速高效的内存引用。相比之下，堆内存管理是程序员的责任，处理不当可能会导致内存泄漏或资源使用效率低下。 数据结构 # 堆栈(Stack) # 堆栈简称为栈。一种线性表数据结构，是一种只允许在表的一端进行插入和删除操作的线性表\n我们把栈中允许插入和删除的一端称为 「栈顶（top）」；另一端则称为 「栈底（bottom）」。 表中没有任何数据元素时，称之为 「空栈」。 栈的插入操作又称为「入栈」或者「进栈」 栈的删除操作又称为「出栈」或者「退栈」。 栈是一种 「后进先出（Last In First Out）」 的线性表，简称为 「LIFO 结构」。 堆栈的基本操作 # 初始化空栈：创建一个空栈，定义栈的大小 size，以及栈顶元素指针 top。\n判断栈是否为空：当堆栈为空时，返回 True。当堆栈不为空时，返回 False。一般只用于栈中删除操作和获取当前栈顶元素操作中。\n判断栈是否已满：当堆栈已满时，返回 True，当堆栈未满时，返回 False。一般只用于顺序栈中插入元素和获取当前栈顶元素操作中。\n插入元素（进栈、入栈）：相当于在线性表最后元素后面插入一个新的数据元素。并改变栈顶指针 top 的指向位置。\n删除元素（出栈、退栈）：相当于在线性表最后元素后面删除最后一个数据元素。并改变栈顶指针 top 的指向位置。\n获取栈顶元素：相当于获取线性表中最后一个数据元素。与插入元素、删除元素不同的是，该操作并不改变栈顶指针 top 的指向位置。\n堆(Heap) # 参考 # 堆栈与堆（Stack vs Heap）：有什么区别？图文并茂拆解代码解析！_内存_存储_函数 (sohu.com)\n静态和动态链接 # 编译分三步：\n预处理（宏、#include、预编译指令#ifdef等）生成.i文件 编译，生成.s汇编文件 汇编，将汇编语言翻译为二进制机器语言 ​ 静态链接和动态链接两者最大的区别就在于链接的时机不一样，静态链接是在形成可执行程序前，而动态链接的进行则是在程序执行时，下面来详细介绍这两种链接方式。\n静态链接 # 原理 # 将所有.c/cpp文件独立编译生成的.o进行链接从而形成可执行程序\n​ 我们知道，链接器在链接静态链接库的时候是以目标文件为单位的。比如我们引用了静态库中的printf()函数，那么链接器就会把库中包含printf()函数的那个目标文件链接进来，如果很多函数都放在一个目标文件中，很可能很多没用的函数都被一起链接进了输出结果中。由于运行库有成百上千个函数，数量非常庞大，每个函数独立地放在一个目标文件中可以尽量减少空间的浪费，那些没有被用到的目标文件就不要链接到最终的输出文件中。\n优缺点 # 浪费空间\n另一方面就是更新比较困难，因为每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。\n在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。\n动态链接 # 将程序按照模块拆分成各个相对独立的部分，程序运行到时才链接\n假设现在有两个程序program1.o和program2.0，这两者共用同一个库lib.o,假设首先运行程序program1，系统首先加载program1.0，当系统发现program1.o中用到了lib.0，即program1.o依赖于lib.o，那么系统接着加载lib.o，如果program1.o和lib.o还依赖于其他目标文件，则依次全部加载到内存中。当program2运行时，同样的加载program2.0，然后发现program2.o依赖于lib.o，但是此时lib.o已经存在于内存中，这个时候就不再进行重新加载，而是将内存中已经存在的lib.o映射到program2的虚拟地址空间中，从而进行链接(这个链接过程和静态链接类似)形成可执行程序。\n动态链接的优点显而易见，就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；另一个优点是，更新也比较方便，更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。但是动态链接也是有缺点的，因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。\n​ 据估算，动态链接和静态链接相比，性能损失大约在5%以下。经过实践证明，这点性能损失用来换区程序在空间上的节省和程序构建和升级时的灵活性是值得的。\n参考 # 多线程 # C++11及以后标准才有 进程与线程的区别 # 进程是正在运行的程序的实例，是可以执行的程序或文件(例如: exe)；而线程是是进程中的实际运作单位，指的是进程的指定单元,也叫执行路径\n一个程序有且只有一个进程，但可以拥有至少一个的线程\n不同进程拥有不同的地址空间，互不相关，而不同线程共同拥有相同进程的地址空间\n线程是CPU调度和分配的基本单位，可以理解为CPU只看得到线程；进程是操作系统进行资源分配的最小单位\n当你执行这个程序时，CPU响应为该进程分配资源对其进行处理，但是CPU看不到\u0026quot;进程\u0026quot;， 看到的是由很多个线程组成的一个网络（就是一个进程），于是CPU开始为这些线程利用时间分配算法来循环执行任务。\n# ubuntu下查看电脑CPU核数，CPU个数，最大线程数(逻辑CPU的数量) ## CPU个数 more /proc/cpuinfo |grep \u0026#34;physical id\u0026#34;|uniq|wc -l # 1 ## 查看CPU核数 cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq # 6 ## 查看最大线程数(逻辑CPU的数量) more /proc/cpuinfo |grep \u0026#34;physical id\u0026#34;|grep \u0026#34;0\u0026#34;|wc -l # 12 并发和并行 # 并发： 指的是两个(或以上)的线程同时请求执行，但是同一瞬间CPU只能执行一个，于是CPU就安排他们交替执行，我们看起来好像是同时执行的，其实不是。并发可认为是一种逻辑结构的设计模式。你可以用并发的设计方式去设计模型，然后运行在一个单核系统上，通过系统动态地逻辑切换制造出并行的假象。\n并发在生活中随处可见，单核CPU边听歌边写代码\n并行： 指的是两个(或以上)的线程同时执行。\n特点 # 线程是在thread对象被定义的时候开始执行的，而不是在调用join函数时才执行的，调用join函数只是阻塞等待线程结束并回收资源 线程会在函数运行完毕后自动释放，不推荐利用其他方法强制结束线程，可能会因资源未释放而导致内存泄漏。 没有执行join或detach的线程在程序结束时会引发异常 std::thread性能分析 # 在C++中，std::thread（标准线程）的性能主要受以下几个因素影响：\n线程创建和销毁的开销（Overhead of Thread Creation and Destruction）：每次创建或销毁线程都会带来一定的开销。这是因为操作系统需要为每个线程分配和回收资源，如栈空间、线程局部存储等。因此，频繁地创建和销毁线程可能会导致性能下降。 线程切换的开销（Overhead of Thread Switching）：操作系统通过线程调度器来管理多个线程的执行。当一个线程的执行被暂停，另一个线程被唤醒时，就会发生线程切换。线程切换会带来一定的开销，因为需要保存和恢复线程的执行环境。 线程同步的开销（Overhead of Thread Synchronization）：在多线程环境中，通常需要使用同步机制（如互斥锁、条件变量等）来协调线程的执行。这些同步操作也会带来一定的开销。 为了减少这些开销，我们可以采取以下策略：\n线程池（Thread Pool）：通过预先创建一定数量的线程，并重复使用这些线程，可以减少线程创建和销毁的开销。 减少线程切换（Reduce Thread Switching）：通过合理地设计程序，减少不必要的线程切换，可以提高性能。 减少锁的使用（Reduce Lock Usage）：通过使用无锁数据结构或者减少锁的粒度，可以减少线程同步的开销。 多线程真的能加速？ # 线程的调度是根据cpu的算法，如果线程的运算量不大，cpu 算法调度线程不一定会平均分配给每个内核的\n测试代码创建了四个线程，四个线程都遍历一百万次。通过使用JDK自带监控工具：Visual VM 查看线程的执行过程\npublic class ThreadTest { private static final int num = 1000 * 1000; public static void main(String[] args) throws InterruptedException { new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; num; i++) { System.out.println(i); } },\u0026#34;线程1\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; num; i++) { System.out.println(i); } },\u0026#34;线程2\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; num; i++) { System.out.println(i); } },\u0026#34;线程3\u0026#34;).start(); new Thread(()-\u0026gt;{ for (int i = 0; i \u0026lt; num; i++) { System.out.println(i); } },\u0026#34;线程4\u0026#34;).start(); } } 发现，多个线程根本没有并发执行，而是不断的在线程之间 上下文切换！也就是说，4个线程都是在单个内核执行，其他的内核并没有工作\nthis_thread # #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;atomic\u0026gt; using namespace std; atomic_bool ready = 0; // uintmax_t ==\u0026gt; unsigned long long void sleep(uintmax_t ms) { this_thread::sleep_for(chrono::milliseconds(ms)); } void count() { while (!ready) this_thread::yield(); for (int i = 0; i \u0026lt;= 20\u0026#39;0000\u0026#39;0000; i++); cout \u0026lt;\u0026lt; \u0026#34;Thread \u0026#34; \u0026lt;\u0026lt; this_thread::get_id() \u0026lt;\u0026lt; \u0026#34; finished!\u0026#34; \u0026lt;\u0026lt; endl; return; } int main() { thread th[10]; for (int i = 0; i \u0026lt; 10; i++) th[i] = thread(::count); sleep(5000); ready = true; cout \u0026lt;\u0026lt; \u0026#34;Start!\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 10; i++) th[i].join(); return 0; } 多个线程操作同一个变量 # std::mutex\n一个线程将mutex锁住时，其它的线程就不能操作mutex，直到这个线程将mutex解锁\nmutex很好地解决了多线程资源争抢的问题，但它也有缺点：太……慢……了…… #include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; using namespace std; int n = 0; mutex mtx; void count10000() { for (int i = 1; i \u0026lt;= 10000; i++) { mtx.lock(); n++; mtx.unlock(); //去掉mtx，输出的n就不正确了 } } int main() { thread th[100]; for (thread \u0026amp;x : th) x = thread(count10000); for (thread \u0026amp;x : th) x.join(); cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; endl; return 0; } std::atomic\n比mutex快\nstd::atomic_int只是std::atomic\u0026lt;int\u0026gt;的别名\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;thread\u0026gt; // #include \u0026lt;mutex\u0026gt; //这个例子不需要mutex了 #include \u0026lt;atomic\u0026gt; using namespace std; atomic_int n = 0; void count10000() { for (int i = 1; i \u0026lt;= 10000; i++) { n++; } } int main() { thread th[100]; for (thread \u0026amp;x : th) x = thread(count10000); for (thread \u0026amp;x : th) x.join(); cout \u0026lt;\u0026lt; n \u0026lt;\u0026lt; endl; return 0; } async # 大多数情况下使用async而不用thread # async可以根据情况选择同步执行或创建新线程来异步执行，当然也可以手动选择。对于async的返回值操作也比thread更加方便。\n注：std::async定义在future头文件中。\napi # 举例 # 使用std::future获取线程的返回值 # 定义了一个对象val，它的类型是std::future\u0026lt;int\u0026gt;，这里的int代表这个函数的返回值是int类型。在创建线程后，我们使用了future::get()来阻塞等待线程结束并获取其返回值\n// Compiler: MSVC 19.29.30038.1 // C++ Standard: C++17 #include \u0026lt;iostream\u0026gt; // #include \u0026lt;thread\u0026gt; // 这里我们用async创建线程 #include \u0026lt;future\u0026gt; // std::async std::future using namespace std; template\u0026lt;class ... Args\u0026gt; decltype(auto) sum(Args\u0026amp;\u0026amp;... args) { // C++17折叠表达式 // \u0026#34;0 +\u0026#34;避免空参数包错误 return (0 + ... + args); } int main() { // 注：这里不能只写函数名sum，必须带模板参数 future\u0026lt;int\u0026gt; val = async(launch::async, sum\u0026lt;int, int, int\u0026gt;, 1, 10, 100); // future::get() 阻塞等待线程结束并获得返回值 cout \u0026lt;\u0026lt; val.get() \u0026lt;\u0026lt; endl; return 0; } Out: 111\nvoid特化std::future # // Compiler: MSVC 19.29.30038.1 // C++ Standard: C++17 #include \u0026lt;iostream\u0026gt; #include \u0026lt;future\u0026gt; using namespace std; void count_big_number() { // C++14标准中，可以在数字中间加上单 // 引号 \u0026#39; 来分隔数字，使其可读性更强 for (int i = 0; i \u0026lt;= 10\u0026#39;0000\u0026#39;0000; i++); } int main() { future\u0026lt;void\u0026gt; fut = async(launch::async, count_big_number); cout \u0026lt;\u0026lt; \u0026#34;Please wait\u0026#34; \u0026lt;\u0026lt; flush; // 每次等待1秒 while (fut.wait_for(chrono::seconds(1)) != future_status::ready) cout \u0026lt;\u0026lt; \u0026#39;.\u0026#39; \u0026lt;\u0026lt; flush; cout \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;Finished!\u0026#34; \u0026lt;\u0026lt; endl; return 0; } 如果你运行一下这个代码，你也许就能搞懂那些软件的加载画面是怎么实现的。\n多线程与核心 # # ubuntu下查看电脑CPU核数，CPU个数，最大线程数(逻辑CPU的数量) ## CPU个数 more /proc/cpuinfo |grep \u0026#34;physical id\u0026#34;|uniq|wc -l # 1 ## 查看CPU核数 cat /proc/cpuinfo| grep \u0026#34;cpu cores\u0026#34;| uniq # 6 ## 查看最大线程数(逻辑CPU的数量) more /proc/cpuinfo |grep \u0026#34;physical id\u0026#34;|grep \u0026#34;0\u0026#34;|wc -l # 12 speedup # 分析工具 # 总结 # 使用const 使用inline 避免频繁的内存分配和释放：使用对象池技术预先分配对象？ 使用引用传递而非指针传递：在某些情况下，使用引用可以避免对象的复制，提高性能 减少函数调用次数 使用位运算替代算术运算：在低级代码中，位运算通常比算术运算更快 使用编译器优化选项：如-O2或-O3，让编译器进行更多的优化 选择合适的数据结构：例如，使用std::vector而不是std::list可以提高内存局部性，减少访问时间 优化算法：选择高效的算法和数据结构，如使用哈希表进行快速查找 使用std::move进行容器转移：移动语义可以避免不必要的复制，提高效率？ 使用局部静态变量和成员变量 使用作用域限定：限定变量的作用域，避免不必要的变量生命周期延长 预先使用reserve优化容器：减少动态数组类型的容器在运行时的内存分配次数？ 减少除法运算：将除法运算转换为乘法运算，以提高效率？ 使用多线程：对于可以并行处理的任务，使用多线程可以显著提高性能 减少值传递，多用引用传递：避免在函数调用时复制整个对象，特别是对于大型对象 避免不同数据类型相互操作：减少数据类型转换，以提高效率 使用内存访问优化：例如，使用指针直接访问数组元素，而不是使用.at()方法 直接使用现有的封装函数很方便，但是效率不是最好的，简单的功能实现，最好还是自己写源码 Boost # 简介 # Boost是一个流行的、开源的C++库集合，提供了各种功能强大的库和工具，扩展了C++语言的能力，并为开发者提供了更高级别的抽象和工具。Boost库经过广泛的使用和测试，被认为是C++社区的事实标准之一\nBoost库包含了多个模块，每个模块都提供了不同领域的功能和工具，覆盖了诸如字符串操作、数据结构、算法、日期时间处理、文件系统、线程、网络、正则表达式等各个方面。以下是一些常用的Boost库：\n1.Boost.Asio：提供了异步I/O操作的网络编程库，支持TCP、UDP、串口等网络协议。\n2.Boost.Smart_Ptr：提供了智能指针类，如shared_ptr和weak_ptr，用于方便地进行内存管理。\n3.Boost.Filesystem：提供了对文件系统的访问和操作，包括文件和目录的创建、删除、遍历等。\n4.Boost.Regex：提供了正则表达式的功能，用于进行文本匹配和搜索操作。\n5.Boost.Thread：提供了跨平台的多线程编程接口，简化了线程的创建、同步和通信等操作。\n6.Boost.Serialization：提供了对象的序列化和反序列化功能，可以将对象以二进制或XML格式进行存储和传输。\n7.Boost.Math用于数学计算\n8.Boost.Graph用于图论算法 Chapter 31. Boost.Graph\n9.Boost.Algorithm - 提供了包括排序、搜索等在内的各种算法。\n10.Boost.Numeric - 提供了用于数值计算的库，如用于线性代数、随机数生成等\n参考 # 【C++】开源：Boost库常用组件配置使用-腾讯云开发者社区-腾讯云 项目Github地址：https://github.com/boostorg/boost Boost库在线书籍：https://wizardforcel.gitbooks.io/the-boost-cpp-libraries/content/0.html 官方文档：The Boost C++ Libraries ODB # ODB（Object-Relational Mapping）是一个C++库，用于将C++对象映射到关系数据库中。\nbuglist # #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;array\u0026gt; using namespace std; int main() { int a = 10; int b = 3; const size_t wire_max_level = a; const size_t wire_max_sublevel = b; array\u0026lt;array\u0026lt;vector\u0026lt;array\u0026lt;int, 2\u0026gt;\u0026gt;, wire_max_level\u0026gt;, wire_max_sublevel\u0026gt; dst; } SystemC # 环境配置 # EDA Playground # Local # SystemC 学习之 Linux 安装 SystemC（一）_systemc如何安装-CSDN博客\nother # Sign Up - Stack Overflow\nComplexity # Time Complexity # 算法运行所花费的时间量化为与输入长度有关的函数\n随着输入的量级增加，低阶项相对无关紧要，因此仅采用最高阶项\n举例 # 假设给定数组array A，在array A中找出是否存在一组pair(x,y)使其和为x+y=z，array A中有N个元素\nfor(int i = 0;i \u0026lt; n;i++) for(int j = 0;j \u0026lt; n;j++) if(i!=j \u0026amp;\u0026amp; a[i]+a[j] == z) return true return false 分析算法的时候通常考虑最差的情况，也就是说上面算法的时间复杂度为O(N2)\ncount = 0 i = N while(i \u0026gt; 0): for j in range(i): count+=1 i /= 2 count+=1总共运行次数为N + N/2 + N/4+…+1= 2 * N，因此时间复杂度为O(N)\nSpace Complexity # 算法运行所占用的空间量化为与输入长度有关的函数\n复杂度分类 # P问题(Polynomial Time) # 可以在确定性多项式时间内解决的决策问题集合\n常见P问题有计算最大公约数；寻找最大匹配(maximum matching)；线性规划的决策版本\nNP问题(Non-deterministic Polynomial Time) # NP问题是机器可以在非确定性多项式时间内解决的决策问题的集合\n常见NP问题有布尔可满足性问题 (Boolean Satisfiability Problem SAT)，哈密顿路径问题，图着色问题\nNP-hard问题 # NP-hard问题至少要和NP问题中最难的一类一样难，代表所有NP问题都能在多项式时间复杂度内归约(reduction)到的问题\n归约：我们现在遇到了个问题，可以把它转化到一个某个已解决的问题上，而不是一定要直接解决这个问题。\n如果给出了一个NP-hard 问题的解，验证也需要很长时间\n常见的NP-hard问题有停机问题(Halting problem)，TSP\nNP-complete问题 # 如果一个问题既是 NP 问题又是 NP-hard问题，那么它就是NP-complete问题\nNP-complete问题是 NP 中的难题。\n常见NP-complete问题有0/1背包问题，哈密尔顿回路，顶点覆盖(Vertex cover)\n参考 # 时间和空间复杂度及复杂度分类(P,NP,NP-hard,NP-complete)_np-hard np-complete-CSDN博客\nPython # print # print(f\u0026#34; pin:{self.connecting_pins[0]}\u0026#34;) class # basic # class PIN: def __init__(self, value_=PIN_VALUE_X): self.value = value_ def func0(self): ... def __str__(self): return f\u0026#34;value={self.value}\\n\u0026#34; reset # def __init__(self, ...) super().__init__() ... self.reset()#调用的是当前类中的 reset 方法。这个方法通常用于重置对象的状态到初始状态。 __init__.py # 包初始化：当一个目录包含 __init__.py 文件时，Python 解释器会将其视为一个包，允许你使用 import 语句导入该目录下的模块。 初始化代码：__init__.py 文件可以包含包的初始化代码。这些代码在包被导入时执行，可以用来执行一些初始化操作，比如设置包的属性、定义函数或类等。 命名空间管理：__init__.py 文件允许你控制包的命名空间。你可以通过这个文件来定义哪些模块或对象应该被暴露给包的使用者。 避免命名冲突：如果你的包中包含的模块名与标准库或其他第三方库的模块名相同，通过在 __init__.py 中明确导入和导出特定的模块或对象，可以避免命名冲突。 向后兼容性：在 Python 3.3 之前，__init__.py 文件是必须的，以将目录标记为包。从 Python 3.3 开始，PEP 420 允许隐式命名空间包，这意味着即使没有 __init__.py 文件，也可以将目录作为包使用。但是，使用 __init__.py 仍然是一种良好的实践，因为它提供了上述的好处。 运行包：如果 __init__.py 文件中包含 if __name__ == \u0026quot;__main__\u0026quot;: 块，那么当包作为脚本直接运行时，该块中的代码将被执行。 mypackage/ │ ├── __init__.py ├── module1.py └── module2.py # mypackage/__init__.py from .module1 import my_function from .module2 import MyClass import mypackage mypackage.my_function() mypackage.MyClass() *args 和 **kwds # def func(*args, **kwds): for arg in args: print(arg) for key, value in kwds.items(): print(f\u0026#34;{key} = {value}\u0026#34;) func(1, 2, 3, a=4, b=5) # 输出: # 1 # 2 # 3 # a = 4 # b = 5 Pytorch # ema # 指数加权移动平均（Exponential Moving Average, EMA）是一种用于平滑时间序列数据的技术，它通过对历史数据赋予不同的权重来实现平滑。与简单移动平均（SMA）不同，EMA对最近的数据赋予更大的权重，从而能够更敏感地反映数据的近期变化趋势\nclass ExponentialMovingAverage(torch.optim.swa_utils.AveragedModel): \u0026#34;\u0026#34;\u0026#34;Maintains moving averages of model parameters using an exponential decay. ``ema_avg = decay * avg_model_param + (1 - decay) * model_param`` `torch.optim.swa_utils.AveragedModel \u0026lt;https://pytorch.org/docs/stable/optim.html#custom-averaging-strategies\u0026gt;`_ is used to compute the EMA. \u0026#34;\u0026#34;\u0026#34; def __init__(self, model, decay, device): def ema_avg(avg_model_param, model_param, num_averaged): return decay * avg_model_param + (1 - decay) * model_param super().__init__(model, device, ema_avg) DGL # with g.local_scope(): #\nTensorflow # 基本操作 # pytorch函数mm() mul() matmul()区别_torch.mm matmul区别-CSDN博客\ntf.Variable(initial_value=1.) tf.constant([[1., 2.], [3., 4.]]) tf.zero tf.square() 操作代表对输入张量的每一个元素求平方 tf.reduce_sum() 操作代表对输入张量的所有元素求和 tf.random.uniform print(A.shape) # 输出(2, 2)，即矩阵的长和宽均为2 print(A.dtype) # 输出\u0026lt;dtype: \u0026#39;float32\u0026#39;\u0026gt; print(A.numpy()) 自动求导 # import tensorflow as tf x = tf.Variable(initial_value=3.) with tf.GradientTape() as tape: # 在 tf.GradientTape() 的上下文内，所有计算步骤都会被记录以用于求导 y = tf.square(x) y_grad = tape.gradient(y, x) # 计算y关于x的导数 print(y, y_grad) tf.GradientTape() 是一个自动求导的记录器。只要进入了 with tf.GradientTape() as tape 的上下文环境，则在该环境中计算步骤都会被自动记录。比如在上面的示例中，计算步骤 y = tf.square(x) 即被自动记录。离开上下文环境后，记录将停止，但记录器 tape 依然可用，因此可以通过 y_grad = tape.gradient(y, x) 求张量 y 对变量 x 的导数。 X = tf.constant([[1., 2.], [3., 4.]]) y = tf.constant([[1.], [2.]]) w = tf.Variable(initial_value=[[1.], [2.]]) b = tf.Variable(initial_value=1.) with tf.GradientTape() as tape: L = tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y)) w_grad, b_grad = tape.gradient(L, [w, b]) # 计算L(w, b)关于w, b的偏导数 print(L, w_grad, b_grad) 模型与层 # 简单粗暴 TensorFlow 2 | A Concise Handbook of TensorFlow 2 — 简单粗暴 TensorFlow 2 0.4 beta 文档 (tf.wiki)\nKeras 在 tf.keras.layers 下内置了深度学习中大量常用的的预定义层，同时也允许我们自定义层\nkeras.layers.Dense\nunits ：输出张量的维度； activation ：激活函数，对应于 中的 ，默认为无激活函数（ a(x) = x ）。常用的激活函数包括 tf.nn.relu 、 tf.nn.tanh 和 tf.nn.sigmoid ； use_bias ：是否加入偏置向量 bias ，即 中的 。默认为 True ； kernel_initializer 、 bias_initializer ：权重矩阵 kernel 和偏置向量 bias 两个变量的初始化器。默认为 tf.glorot_uniform_initializer 1 。设置为 tf.zeros_initializer 表示将两个变量均初始化为全 0； 该层包含权重矩阵 kernel = [input_dim, units] 和偏置向量 bias = [units] 2 两个可训练变量 tf.keras.layers.Conv2D\ntf.keras.layers.MaxPool2D\ntf.keras.layers.Reshape\ntf.keras.layers.LSTMCell\n我们可以通过继承 tf.keras.Model 这个 Python 类来定义自己的模型\n在继承类中，我们需要重写 __init__() （构造函数，初始化）和 call(input) （模型调用）两个方法，同时也可以根据需要增加自定义的方法。\n实例化类 model = Model() 后，可以通过 model.variables 这一属性直接获得模型中的所有变量\n自定义层 # tf.keras.models.Sequential() 提供一个层的列表，就能快速地建立一个 tf.keras.Model 模型并返回\nmodel = tf.keras.models.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(100, activation=tf.nn.relu), tf.keras.layers.Dense(10), tf.keras.layers.Softmax() ]) 变量的恢复和保存 # TensorFlow常用模块 — 简单粗暴 TensorFlow 2 0.4 beta 文档 (tf.wiki)\n训练过程可视化 # GPU使用 # 分布式训练 # TPU训练 # install # 使用 pip 安装 TensorFlow (google.cn)\nTensorFlow安装与环境配置 — 简单粗暴 TensorFlow 2 0.4 beta 文档 (tf.wiki)\n#需要使用 Python 3.6-3.9 和 pip 19.0 及更高版本 sudo apt update sudo apt install python3-dev python3-pip python3-venv python3 --version pip3 --version #enter vir env #从 TensorFlow 2.1 开始，pip 包 tensorflow 即同时包含 GPU 支持，无需通过特定的 pip 包 tensorflow-gpu 安装 GPU 版本 pip install --upgrade tensorflow#install #指定版本号 pip install tensorflow==2.6.0 reference # 简单粗暴 TensorFlow 2 | A Concise Handbook of TensorFlow 2 — 简单粗暴 TensorFlow 2 0.4 beta 文档 (tf.wiki)\ncollections # defaultdict # from collections import defaultdict # 创建一个默认值为int的defaultdict，int类型的默认值为0 dd = defaultdict(int) # 访问一个不存在的键，会自动创建该键，并将值设置为默认值0 print(dd[\u0026#39;foo\u0026#39;]) # 输出: 0 # 手动设置一个键的值 dd[\u0026#39;foo\u0026#39;] = 1 # 再次访问该键，返回设置后的值 print(dd[\u0026#39;foo\u0026#39;]) # 输出: 1 NameTuple # 元组 tuple 一样，NamedTuple 也是不可变数据类型，创建之后就不能改变内容\nNamedTuple 不像数组那样使用下标读写，反而和类相似，使用 . 来读写。\ncollections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None) # 导包 from collections import namedtuple # 创建普通元组 point = (22, 33) print(point) # 输出：(22, 33) # 创建命名元组 Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y\u0026#39;)#我们先用 namedtuple 创建了一个名为 Point，有两个字段 x、y 的子类，然后将这个类赋给 Point 变量。 point_A = Point(22, 33)#相当于 new print(point_A) # 输出：Point(x=22, y=33) #三种风格 Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y\u0026#39;) Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x,y\u0026#39;) Point = namedtuple(\u0026#39;Point\u0026#39;, [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;]) #取值 print(point_A[0]) print(point_A[1]) print(point_A.x) print(point_A.y) #创造一个对象 point1 = Point(x=1, y=2) 【Python 高级特性】深入 NamedTuple 命名元组-CSDN博客\nmap # map()传入的第一个参数是f，即函数对象本身。由于结果r是一个 Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list。你可能会想，不需要map()函数，写一个循环，也可以计算出结果。但是，map要比循环更快，更稳健。\ndef Fun(x) : # 计算平方数 return x + 2 data = [1, 4, 9, 16, 25] outdata = list(map(Fun, data)) #结果：outdata=[3, 4, 6, 7, 10, 12] #lambda rewards = list(map(lambda s: s.reward, batch))#get reward from batch TCL # 基本知识 # list # 一组单词或者使用双引号或大括号可以用来表示一个简单的列表\n#!/usr/bin/tclsh set myVariable {red green blue} puts [lindex $myVariable 2] set myVariable \u0026#34;red green blue\u0026#34; puts [lindex $myVariable 1] blue green\n关联数组 # #!/usr/bin/tclsh set marks(english) 80 puts $marks(english) set marks(mathematics) 90 puts $marks(mathematics) 80 90\n参考 # TCL数据类型 - Tcl教程 (yiibai.com)\nCUDA # 简介 # 什么是CUDA # CUDA建立在NVIDIA的GPU上的一个通用并行计算平台和编程模型\nGPU性能指标 # 核心数：为GPU提供计算能力的硬件单元，核心数量越多，可并行运算的线程数量也就越多 GPU显存容量 GPU计算峰值：代表GPU的最大计算能力 显存带宽：运算单元与显存之间的通信速率 下图由GPT生成：\n架构 # 控制器： 算数逻辑单元 缓存器 动态随机存取储存器 开发环境 # 可以用C++或python\ncommand # nvidia-smi\n显存存满了GPU不一定在高速工作\nnvidia-smi -q:\n显示显卡的详细信息\nnvidia-smi -q -i 0:多卡下，看具体是哪一块显卡\nnvidia-smi -q -i 0 -d MEMORY:具体看MEMORY的信息\nbasic # 核函数(Kernel function) # 主机对设备的调用是通过核函数进行的\n__global__和void的书写和函数是两个重要的规则\n核函数只能访问GPU内存 CPU与GPU是无法相互直接访问各自内存的 通过PCIE进行相互访问 核函数不能使用变长参数 核函数不能使用静态变量 核函数不能使用函数指针 核函数具有异步性 CPU主机无法控制GPU设备的执行 CPU主机不会等待核函数执行完毕 所以我们需要显示的调用同步函数同步主机CPU 核函数不支持C++的iostream, 要使用printf来显示 为什么可以使用printf? 一个helloworld核函数 //声明 __global__ void hello_from_gpu() { printf(\u0026#34;Hello World from the the GPU\\n\u0026#34;); } //调用 hello_from_gpu\u0026lt;\u0026lt;\u0026lt;1, 1\u0026gt;\u0026gt;\u0026gt;(); //\u0026lt;\u0026lt;\u0026lt;grid_size, block_size\u0026gt;\u0026gt;\u0026gt;指定线程块和线程数量 同步 # 使用原因：CPU主机不会等待核函数执行完毕\ncudaDeviceSynchronize() 线程模型 # grid-\u0026gt;block-\u0026gt;thread\n线程分块是逻辑上的划分， 物理上线程不分块 最大允许线程块大小： 1024 最大允许网格大小： 231 - 1 （针对一维网格） 一维线程模型 # 8个线程helloworld # #include \u0026lt;stdio.h\u0026gt; __global__ void hello_from_gpu() { const int bid = blockIdx.x; const int tid = threadIdx.x; const int id = threadIdx.x + blockIdx.x * blockDim.x; printf(\u0026#34;Hello World from block %d and thread %d, global id %d\\n\u0026#34;, bid, tid, id); } int main(void) { hello_from_gpu\u0026lt;\u0026lt;\u0026lt;2, 4\u0026gt;\u0026gt;\u0026gt;(); cudaDeviceSynchronize(); return 0; } Hello World from block 1 and thread 0, global id 4 Hello World from block 1 and thread 1, global id 5 Hello World from block 1 and thread 2, global id 6 Hello World from block 1 and thread 3, global id 7 Hello World from block 0 and thread 0, global id 0 Hello World from block 0 and thread 1, global id 1 Hello World from block 0 and thread 2, global id 2 Hello World from block 0 and thread 3, global id 3\n多维线程模型 # cuda最多3维度\ngridDim和blockDim没有指定的维度默认为1：\n线程块总数不能超过1024\n线程index计算 # nvcc # 简介 # 类似gcc, 用于编译.cu文件\n原理 # nvcc分离全部源代码为： （1） 主机代码 （2） 设备代码 nvcc先将设备代码编译为PTX（Parallel Thread Execution） 伪汇编代码， 再将PTX代码编译为二进制的cubin目标代码 在将源代码编译为 PTX 代码时， 需要用选项**-arch=compute_XY指定一个虚拟架构**的计算能力，用以确定代码中能够使用的CUDA功能。 在将PTX代码编译为cubin代码时， 需要用选项**-code=sm_XY指定一个真实架构**的计算能力， 用以确定可执行文件能够使用的GPU。 PTX # PTX（ Parallel Thread Execution） 是CUDA平台为基于GPU的通用计算而定义的虚拟机和指令集 可以适配更多的GPU，C/C++源码转化为PTX这一步骤与GPU硬件无关 flow # command # nvcc -arch=compute_x1 -code=sm_x2 file.cu -o file_binary -run -o 输出binary\n-arch=compute_XY\nXY： 第一个数字X代表计算能力的主版本号， 第二个数字Y代表计算能力的次版本号 可以理解为对显卡版本的最低要求 -code=sm_XY\nXY： 第一个数字X代表计算能力的主版本号， 第二个数字Y代表计算能力的次版本号\n二进制cubin代码， 大版本之间不兼容 ，必须对应自己的GPU\n指定真实架构计算能力的时候必须指定虚拟架构计算能力\n定的真实架构能力必须大于或等于虚拟架构能力\n真实架构小版本之间是兼容的\n-gencode arch=compute_XY –code=sm_XY\n使得编译出来的可执行文件可以在多GPU中执行 执行上述指令必须CUDA版本支持7.0计算能力， 否则会报错 -arch=sm_XY\n计算能力 # 不同版本CUDA编译器在编译CUDA代码时， 都有一个默认计算能力\nGPU架构 # 不同的GPU架构之间, GPU指令集会有较大的差异，因此编译出的二进制可执行文件在不同的架构之间是不可以混用的\n例如为帕斯卡GPU编译的扩大应用程序，很可能无法在福特GPU上运行 torch # ATen库\n性能对比 # LLTM上的对比:\ntutorial # 1. Introduction # While the CPU is designed to excel at executing a sequence of operations, called a thread, as fast as possible and can execute a few tens of these threads in parallel, the GPU is designed to excel at executing thousands of them in parallel (amortizing the slower single-thread performance to achieve greater throughput).\nGPU专门用于高度并行计算，因此设计了更多的晶体管用于数据处理，而不是数据缓存和流量控制。\n整体架构还是一样的，只是各个模块的量不一样？\nGPU缓存较少，浮点计算单元较多\nApplications with a high degree of parallelism can exploit this massively parallel nature of the GPU to achieve higher performance than on the CPU.\nA Scalable Programming Mode # At its core are three key abstractions — a hierarchy of thread groups, shared memories, and barrier synchronization — that are simply exposed to the programmer as a minimal set of language extensions.\n2. Programming Model # Kernels # install # wsl下的安装 CUDA C++ Programming Guide CUDA 所有相关官方文档 An extensive description of CUDA C++ is given in Programming Interface. 参考 # sangyc10/CUDA-code NP问题 # 基本概念： # 约化：\n多项式\nP问题 # 定义:一个可以在多项式时间复杂度内解决的问题。 例如:n个数的排序问题(不超过0(n^2^))\nNP问题 # 定义:可以在多项式的时间里验证一个解的问题。即给出一个答案，可以很快地(在多项式时间内)验证这个答案是对的还是错的，但是不一定能在多项式时间内求出正确的解。\n举例：\n1.数独问题：\n2.hamilton问题：\nNP-hard # 定义:任意NP问题可以在多项式时间内约化成该问题即为了解决NP问题A，先将问题A约化为另一个问题B，解决问题B同时也间接解决了问题A。问题B就是一个NP难问题\n举例：旅行商最短路径问题\n设一个推销员需要从香港出发，经过广州，北京，上海，…，等n个城市，最后返回香港。 任意两个城市之间都有飞机直达，但双向的票价不等。求总路费最少的行程安排。\n分析:想要知道所有方案中花费最少的，必须检查所有可能的旅行安排才能找到，即**(n-1)!种方案，很显然这不是P问题（不是多项式）。给出任意一个行程安排，你能算出它的总路费，但无法在多项式时间内验证这条路是否是最短路**。所以不是NP问题。（下图纯绿色部分）\nNP-Complete问题 # 定义:所有既是NP问题，又是NP难问题的问题 即一个NP问题，任意的NP问题可以约化到它:\nNPC问题只能暴力求解？\n举例：\n旅行商问题（限制花费）\n设一个推销员需 要从香港出发，经过广州，北京，上海，…，等n个城市，最后返回香港。 任意两个城市之间都有飞机直达，但双向的票价不等。现在假设公司给报销C块钱问是否存在一个行程安排，使得他能遍历所有城市，而且总的路费小于C?\npython和c/c++的区别 # 主要区别 # 1. 性能 # C++ 性能优势 # 编译型语言\n：\nC++ 是编译型语言，代码在执行前被编译成机器码，因此运行时不需要额外的翻译步骤，执行速度非常快。 手动内存管理\n：\nC++ 提供对内存的直接控制（如 new/delete 或 malloc/free），允许开发者优化性能。 零运行时开销\n：\nC++ 不依赖虚拟机，运行时没有垃圾回收器等额外的开销。 硬件亲和性\n：\nC++ 可以直接控制硬件资源（如寄存器、指令级优化），这在需要高性能的场景（如嵌入式系统、游戏引擎）中非常重要。 Python 性能劣势 # 解释型语言\n：\nPython 是解释型语言，代码需要在运行时由解释器（如 CPython）逐行翻译成机器码，这会显著降低运行速度。 动态类型系统\n：\nPython 的动态类型检查在运行时执行，增加了额外的开销。 垃圾回收\n：\nPython 使用自动垃圾回收器（如引用计数和标记清除），虽然减少了内存管理的复杂性，但增加了运行时负担。 全局解释器锁 (GIL)\n：\nPython 的多线程性能受限于 GIL，无法充分利用多核 CPU，影响计算密集型任务的效率。 典型性能对比 # 计算密集型任务：C++ 通常比 Python 快 10~100 倍。 I/O 密集型任务：差距较小，但 C++ 仍略占优势。 优化潜力：C++ 提供更低级别的优化工具，性能可以进一步提升。 2. 开发效率 # Python 优势\n：\n简洁的语法，开发效率高。 动态类型和丰富的标准库适合快速原型开发。 C++ 劣势\n：\n语法复杂（如模板、指针管理）。 手动内存管理增加开发难度。 3. 类型系统 # C++：静态类型语言，变量类型在编译时确定，提供更好的错误检查和性能优化。 Python：动态类型语言，变量类型在运行时确定，灵活性高但容易导致运行时错误。 4. 内存管理 # C++：支持手动内存分配和释放，适合需要精准控制内存的场景，但容易出现内存泄漏或悬挂指针问题。 Python：自动垃圾回收，降低了内存管理复杂性，但会带来性能损耗。 5. 库支持 # C++：广泛支持高性能库（如 STL、Boost），适合底层开发。 Python：丰富的第三方库，尤其在数据科学（NumPy、Pandas）、机器学习（TensorFlow、PyTorch）领域占据主导地位。 6. 使用场景 # C++ 适用场景 # 高性能需求：游戏开发、嵌入式系统、操作系统、实时应用。 硬件控制：与硬件交互的系统。 Python 适用场景 # 快速开发：脚本工具、原型开发。 数据科学和机器学习：开发速度比性能更重要。 自动化任务：如 Web 爬虫和测试。 性能优化方法 # 1. Python 提高性能的方法 # 使用 JIT 编译器（如 PyPy）代替 CPython。 关键代码用 C/C++ 编写，并通过扩展（如 Cython、SWIG）调用。 使用并行库（如 multiprocessing）绕过 GIL。 2. C++ 提高开发效率的方法 # 使用现代 C++（如 C++11/14/17）特性（如智能指针、自动类型推导）。 借助库（如 Boost）减少手动开发复杂性。 总结 # 特性 C++ Python 性能 高，适合高性能需求 较低，适合快速开发 开发效率 较低，语法复杂 高，语法简洁 类型系统 静态类型，编译时检查 动态类型，运行时检查 内存管理 手动管理，精准控制 自动管理，简单易用 生态系统 底层开发库丰富，适合高性能应用 第三方库广泛，适合数据科学与快速开发 适用场景 游戏开发、嵌入式系统、实时应用 数据分析、机器学习、脚本工具 对于需要高性能或与硬件交互的任务，C++ 是更好的选择；而 Python 则适合对开发效率要求较高的场景，如快速原型、数据分析和机器学习。\n"},{"id":19,"href":"/zh/docs/Other/Tools/","title":"Tools","section":"Other","content":" WSL # cmd # wsl -l -v wsl --shutdown\t#关闭 wsl --list --verbose # 查看已安装的发行版、WSL 版本信息和当前状态 wsl --set-default \u0026lt;DistroName\u0026gt; # 重新指定默认发行版 wsl --export Ubuntu-22.04 e:\\Ubuntu-22.04.tar#导出 wsl --unregister Ubuntu-22.04 #注销并卸载 wsl --import Ubuntu-22.04 E:\\ubuntu2204 E:\\Ubuntu-22.04.tar#导入 wsl --set-default \u0026lt;DistroName\u0026gt; # 重新指定默认发行版 环境配置 # windows 设置打开： 适用于 Linux 的 Windows 子系统 和 虚拟机平台 Linux 内核更新包：https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi\nwsl --list --verbose # 查看已安装的发行版、WSL 版本信息和当前状态 wsl --set-default \u0026lt;DistroName\u0026gt; # 重新指定默认发行版 Windows 11：WSL 2 安装和管理指南，3 种方法任你选 - 系统极客 (sysgeek.cn)\nWin11 安装 Docker Desktop 和 WSL2 并进行安装位置迁移_windows 11 wsl 修改安装位置-CSDN 博客\n常见问题 # VmmemWSL 占用 CPU 或内存资源过高 # Vmmem 进程(WSL)占用 CPU 或内存资源过高的解决办法-CSDN 博客\n代理问题 # WSL2 如何解决 clash 代理问题 - VariantConst\nC/C++ # sudo apt install build-essential sudo apt -y install gcc g++ gdb conda # 基本命令 # conda create --name myenv python=3.8 conda activate myenv conda deactivate conda list\t#命令来查看当前环境中安装的包。 conda env remove --name myenv\t#删除 conda info --envs\t#查找所有虚拟环 conda install [package-name] # 安装名为[package-name]的包 conda install [package-name]=X.X # 安装名为[package-name]的包并指定版本X.X conda update [package-name] # 更新名为[package-name]的包 conda remove [package-name] # 删除名为[package-name]的包 conda list # 列出当前环境下已安装的所有包 conda search [package-name] # 列出名为[package-name]的包在conda源中的所有可用版本 conda create --name [env-name] # 建立名为[env-name]的Conda虚拟环境 conda activate [env-name] # 进入名为[env-name]的Conda虚拟环境 conda deactivate # 退出当前的Conda虚拟环境 conda env remove --name [env-name] # 删除名为[env-name]的Conda虚拟环境 conda env list # 列出所有Conda虚拟环境 环境配置 # wget https://repo.anaconda.com/miniconda/Miniconda3-py38_23.5.2-0-Linux-x86_64.sh bash Miniconda3-py38_23.5.2-0-Linux-x86_64.sh 安装以后要重启才能生效！\n常见问题 # 安装以后要重启才能生效！\npycharm 无法添加 conda 环境时无法找到对应环境的 python.exe 文件 Conda Executable 是 conda 的执行文件，不是填环境的 python 解释器 0.0\n看错两次了\ncuda 驱动，cuda-toolkit, cudnn # 环境配置 # Windows 11/10 WSL2 Ubuntu 20.04 下配置 Cuda 及 Pytorch_win11 的 cuda 和 ubuntu 对比-CSDN 博客\n安装 WSL Cuda 驱动 # cudatoolkit # CUDA Toolkit 12.6 Update 1 Downloads | NVIDIA Developer\ncudnn # cuDNN Archive | NVIDIA Developer\n重装 # CUDA 的正确安装/升级/重装/使用方式 - 知乎 (zhihu.com)\npytorch, dgl, PyG # PyTorch\nDeep Graph Library (dgl.ai)\nPyG\nconda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia conda install -c dglteam/label/th24_cu124 dgl conda install pyg -c pyg #test python -c \u0026#34;import torch; print(torch.cuda.is_available())\u0026#34; python -c \u0026#34;import torch; print(torch.version.cuda)\u0026#34; docker # 使用 dockerfile # dockerfile # Dockerfile 是一个文本文件，包含一系列指令来组装 [Docker 镜像]( https://so.csdn.net/so/search?q=Docker 镜像\u0026amp;spm=1001.2101.3001.7020)。每个指令执行一个特定动作，例如安装包、复制文件或定义启动命令。\ndocker pull ubuntu:20.04 #下一个镜像 docker run --rm ubuntu:22.04 nproc#安装，并查看cpu核心数 docker run -it ubuntu:22.04 bash #进入交互模式,这种情况在能用、 docker run -it --name my_centos7 -v /path/on/host:/path/in/container centos:7#如果需要将数据保存到宿主机上，可以挂载一个目录， 同时指定名字， 注意exit退出容器后容器还会存在，使用docker ps -a 才能看到 docker start \u0026lt;container_name\u0026gt; #重新启动暂停的容器 docker exec -it \u0026lt;container_name\u0026gt; bash #重新进入容器 apt install, 注意update docker ps #查看运行的容器 docker ps -a#查看运行的容器,包括暂停的 #docker下 的gui显示也可以安装通过设置DISPLAY环境变量来处理 docker commit \u0026lt;容器ID或名称\u0026gt; \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; #保存容器为镜像 docker images #查看保存的镜像 docker rm \u0026lt;container_name\u0026gt;#删除容器 docker rmi -f \u0026lt;镜像ID或名称\u0026gt; #删除镜像 docker exec -it my_container bash #对同一个docker容器开启多个终端 docker run -v \u0026lt;主机目录\u0026gt;:\u0026lt;镜像目录\u0026gt; -it \u0026lt;镜像名称\u0026gt;:\u0026lt;标签\u0026gt; bash #挂载 container 内的C++项目debug # linux下vscode支持的调试器为gdb\n安装vs code 插件： Dev Container\n安装gdb:apt-get install build-essential gdb\n运行：Attach to Running Container\n在vscode中打开工程目录，并添加launch文件\n用g++或者用task.json生成binary可执行文件，注意编译的时候加上-g，-g意思就是编译出带调试信息的可执行文件，如果少了这个-g，生成的可执行文件就不能够调试了\n然后点三角形就行。\n参考 # VSCode调试docker中的程序(C++) 和离线安装VSCode插件的方法_vs code docker插件dev container下载-CSDN博客 launch.json官方教程https://go.microsoft.com/fwlink/?linkid=830387 launch.json教程 VScode 调试教程 tasks.json和launch.json的设置（超详细）-CSDN博客 centos 容器无法联网问题 # Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=7\u0026arch=x86_64\u0026repo=os\u0026infra=container error was 14: curl#6 - \u0026ldquo;Could not resolve host: mirrorlist.centos.org; Unknown error\u0026rdquo;\n#还是不行。。。 修改vscode docker容器内终端没有颜色 # 自定义优化VsCode终端样式（提示高亮）_vscode终端颜色设置-CSDN博客\ninstall # Ubuntu 安装 Docker_ubuntu 重新安装 docker-CSDN 博客\nCmake # basic # 基本内置宏变量 # PROJECT_SOURCE_DIR\t使用cmake命令后紧跟的目录，一般是工程的根目录 PROJECT_BINARY_DIR\t执行cmake命令的目录 CMAKE_CURRENT_SOURCE_DIR\t当前处理的CMakeLists.txt所在的路径 CMAKE_CURRENT_BINARY_DIR\ttarget 编译目录 EXECUTABLE_OUTPUT_PATH\t重新定义目标二进制可执行文件的存放位置 LIBRARY_OUTPUT_PATH\t重新定义目标链接库文件的存放位置 PROJECT_NAME\t返回通过PROJECT指令定义的项目名称 CMAKE_BINARY_DIR\t项目实际构建路径，假设在build目录进行的构建，那么得到的就是这个目录的路径 常用文件结构 # inc目录下存放头文件 src目录下存放源文件 lib目录下存放生成的库 bin目录下存放可执行文件 build目录下存放构建项目相关的文件 command # include_directories(headpath)\nadd_executable(app ${SRC_LIST})\n案例 # . |-- CMakeLists.txt |-- bin | `-- binary |-- build | |-- CMakeCache.txt | |-- CMakeFiles | | |-- 3.27.0 | | |-- CMakeConfigureLog.yaml | | |-- CMakeDirectoryInformation.cmake | | |-- CMakeScratch | | |-- Makefile.cmake | | |-- Makefile2 | | |-- TargetDirectories.txt | | |-- binary.dir | | |-- cmake.check_cache | | |-- pkgRedirects | | |-- progress.marks | | `-- src_dyn_lib_so.dir | |-- Makefile | `-- cmake_install.cmake |-- lib | |-- libsrc_dyn_lib_so.so | `-- libsrc_sta_lib_a.a `-- src |-- db | |-- func.cpp | `-- func.h |-- main.cpp |-- network |-- test `-- utils message(\u0026#34;run cmake...\u0026#34;) # 设置二进制文件的名称 set(BINARY_NAME \u0026#34;binary\u0026#34;) set(PROJECT_DIR \u0026#34;/root/cmake_test\u0026#34;) set(BIN_DIR \u0026#34;${PROJECT_DIR}/bin\u0026#34;) set(SRC_DIR \u0026#34;${PROJECT_DIR}/src\u0026#34;) set(LIB_DIR \u0026#34;${PROJECT_DIR}/lib\u0026#34;) # set(LIBRARY_OUTPUT_DIRECTORY ${LIB_DIR}) # 动态库(.so) 输出路径 # set(ARCHIVE_OUTPUT_DIRECTORY ${LIB_DIR}) # 静态库(.a) 输出路径 set(EXECUTABLE_OUTPUT_PATH ${BIN_DIR}) #设置可执行文件位置 # 设置CMake的最低版本 cmake_minimum_required(VERSION 3.10) # 项目名称 project(MyProject) # 设置C++标准 set(CMAKE_CXX_STANDARD 11) # 获取所有子目录下的源文件 file(GLOB_RECURSE SOURCES \u0026#34;${SRC_DIR}/db/*.cpp\u0026#34; \u0026#34;${SRC_DIR}/network/*.cpp\u0026#34; \u0026#34;${SRC_DIR}/utils/*.cpp\u0026#34; ) # 获取所有头文件 file(GLOB_RECURSE HEADERS \u0026#34;${SRC_DIR}/db/*.h\u0026#34; \u0026#34;${SRC_DIR}/network/*.h\u0026#34; \u0026#34;${SRC_DIR}/utils/*.h\u0026#34; ) #静态库和动态库 # add_library(src_sta_lib_a STATIC ${SOURCES}) add_library(src_dyn_lib_so SHARED ${SOURCES}) # set_target_properties(src_sta_lib_a PROPERTIES ARCHIVE_OUTPUT_DIRECTORY ${LIB_DIR})# 静态库(.a) 输出路径 set_target_properties(src_dyn_lib_so PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${LIB_DIR})# 动态库(.so) 输出路径 # link_directories(${LIB_DIR})# 通过命令指定出要链接的动态库的位置，指定静态库位置使用的也是这个命令 #如果该静态库不是系统提供的（自己制作或者使用第三方提供的静态库）可能出现静态库找不到的情况，此时可以将静态库的路径也指定出来 # link_libraries(src_sta_lib_a)# 链接静态库 #用于设置全局链接库，这些库会链接到之后定义的所有目标上 #可以是全名 libxxx.a #也可以是掐头（lib）去尾（.a）之后的名字 xxx # 创建可执行文件 add_executable(${BINARY_NAME} ${SRC_DIR}/main.cpp ${SOURCES}) #链接动态库 target_link_libraries(${BINARY_NAME} src_dyn_lib_so)#用于指定一个目标（如可执行文件或库）在编译时需要链接哪些库#支持指定库的名称、路径以及链接库的顺序。#动态库的链接具有传递性 # 设置头文件目录 # 必须放到add_executable后面 add # 指定包含目录，以便编译器在编译源文件时能够找到所需的头文件 target_include_directories(${BINARY_NAME} PRIVATE ${SRC_DIR}/db ${SRC_DIR}/network ${SRC_DIR}/utils ) set(CMAKE_BUILD_TYPE \u0026#34;Debug\u0026#34;) # set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -Wall -O3 -march=native\u0026#34;) message(\u0026#34;cmake done...\u0026#34;) 动态库和静态库 # 有些时候我们编写的源代码并不需要将他们编译生成可执行程序，而是生成一些静态库或动态库提供给第三方使用，下面来讲解在cmake中生成这两类库文件的方法。\n静态库 # .a\n静态库会在生成可执行程序的链接阶段被打包到可执行程序中，所以可执行程序启动，静态库就被加载到内存中了。cmake中指定要链接的动态库的时候，应该将命令写到生成了可执行文件之后\nadd_library(库名称 STATIC 源文件1 [源文件2] ...) add_library(calc STATIC ${SRC_LIST})\n这样最终就会生成对应的静态库文件libcalc.a。\n动态库 # .so\n动态库在生成可执行程序的链接阶段不会被打包到可执行程序中，当可执行程序被启动并且调用了动态库中的函数的时候，动态库才会被加载到内存\nadd_library(calc SHARED ${SRC_LIST})\n这样最终就会生成对应的动态库文件libcalc.so。\n动态库的链接具有传递性，如果动态库 A 链接了动态库B、C，动态库D链接了动态库A，此时动态库D相当于也链接了动态库B、C，并可以使用动态库B、C中定义的方法\nadd_library(库名称 SHARED 源文件1 [源文件2] ...) target_link_libraries(A B C) target_link_libraries(D A)\n场景 # debug宏定义 # #include \u0026lt;stdio.h\u0026gt; #define NUMBER 3 int main() { int a = 10; #ifdef DEBUG printf(\u0026#34;我是一个程序猿, 我不会爬树...\\n\u0026#34;); #endif for(int i=0; i\u0026lt;NUMBER; ++i) { printf(\u0026#34;hello, GCC!!!\\n\u0026#34;); } return 0; } 在测试的时候去把它定义出来，其中一种方式就是在gcc/g++命令中去指定，如下： gcc test.c -DDEBUG -o app 在gcc/g++命令中通过参数 -D指定出要定义的宏的名字，这样就相当于在代码中定义了一个宏，其名字为DEBUG。\n在CMake中我们也可以做类似的事情，对应的命令叫做add_definitions\nadd_definitions(-D宏名称)\nvscode C++ cmake debug # 目录结构\n. |-- LICENSE |-- README.md |-- build | |-- CMakeCache.txt | |-- CMakeFiles | |-- Makefile | |-- POST9.dat | |-- POWV9.dat | |-- cmake_install.cmake | |-- compile_commands.json | |-- debug.guide | `-- iccad19gr |-- data |-- drcu |-- ispd18eval | |-- README | |-- ispd18eval.sh | |-- ispd18eval.tcl | |-- ispd18eval.w | `-- ispd18eval_bin |-- ispd19eval | |-- README | |-- ispd19eval.sh | |-- ispd19eval.tcl | |-- ispd19eval.w | `-- ispd19eval_bin |-- lib |-- mybenchmarks | |-- aes_cipher_top | |-- ispd18_test1 | `-- ispd19_test3 |-- myoutput | |-- flow.log | `-- ispd18_test1 |-- rsyn | |-- LICENSE | |-- README.md | |-- include | |-- lib | `-- src |-- run | |-- POST9.dat | |-- POWV9.dat | |-- __pycache__ | |-- build.py | |-- debug.sh | |-- drcu | |-- flow.py | |-- gprof2dot.py | |-- iccad19gr | |-- ispd18eval | |-- ispd19eval | |-- lefRWarning.log | |-- rebuilt.sh | |-- run.py | `-- run_base.py |-- scripts | |-- build.py | |-- gprof2dot.py | |-- run.py | `-- run_base.py |-- src | |-- CMakeLists.txt | |-- db | |-- flute | |-- global.h | |-- gr_db | |-- main.cpp | |-- multi_net | |-- single_net | `-- utils `-- test.sh ######### # Setup # ######### # Specify the minimum version for CMake cmake_minimum_required(VERSION 2.8) # Message message(STATUS \u0026#34;ICCAD19 GR CUHK\u0026#34;) message(STATUS ${CMAKE_CURRENT_SOURCE_DIR}) message(STATUS ${PROJECT_SOURCE_DIR}) # Find includes in the build directories set(CMAKE_INCLUDE_CURRENT_DIR ON) # Project\u0026#39;s name project(iccad19gr) # Set the output folder where your program will be created set(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR}) set(LIBRARY_OUTPUT_PATH ${CMAKE_BINARY_DIR}) set(CMAKE_CXX_STANDARD 14) set(PATH_RSYN ${CMAKE_CURRENT_SOURCE_DIR}/../rsyn) set(PATH_ICCAD19 ${CMAKE_CURRENT_SOURCE_DIR}) ################### # Warnings/Errors # ################### set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -Werror=return-type\u0026#34;) ###################### # Check Dependencies # ###################### # uncommment this line if you are using self-compiled boost lib set(Boost_USE_STATIC_LIBS ON) find_package(Boost COMPONENTS system filesystem program_options REQUIRED) # find_package(Threads) ############### # Source Code # ############### file(GLOB_RECURSE SRC_FILES_RSYN ${PATH_RSYN}/src/*.cpp ${PATH_RSYN}/src/*.cc ${PATH_RSYN}/src/*.c) file(GLOB_RECURSE SRC_FILES_ICCAD19 ${PATH_ICCAD19}/*.cpp ${PATH_ICCAD19}/*.c) set(SRC_FILES ${SRC_FILES_RSYN} ${SRC_FILES_ICCAD19}) ################# # Library Paths # ################# # Need to come before target is created. if(${CMAKE_SYSTEM_NAME} MATCHES \u0026#34;Linux\u0026#34;) link_directories(${PATH_RSYN}/lib/linux) endif() if(${CMAKE_SYSTEM_NAME} MATCHES \u0026#34;Darwin\u0026#34;) link_directories(${PATH_RSYN}/lib/macosx) endif() ########### # Targets # ########### add_executable(iccad19gr ${SRC_FILES}) ####################### # Include Directories # ####################### include_directories(${PATH_RSYN}/src) include_directories(${PATH_RSYN}/src/rsyn/export) include_directories(${PATH_RSYN}/include) include_directories(${PATH_ICCAD19}) ################# # Linker Flags # ################# # TODO: set static under release mode only set_target_properties(iccad19gr PROPERTIES LINK_FLAGS \u0026#34;-static -Wl,--whole-archive -rdynamic -lpthread -Wl,--no-whole-archive\u0026#34;) # LEF/DEF target_link_libraries(iccad19gr lef) target_link_libraries(iccad19gr def) # Boost target_include_directories(iccad19gr PUBLIC ${Boost_INCLUDE_DIR}) target_link_libraries(iccad19gr ${Boost_LIBRARIES}) #进行debug编译\ncmake src/ -B build -DCMAKE_BUILD_TYPE=Debug\n测试指令：\ncp run/PO* build/. cd build ./iccad19gr -lef ../mybenchmarks/ispd18_test1/ispd18_test1.input.lef -def ../mybenchmarks/ispd18_test1/ispd18_test1.input.def -output debug.guide --thread 8 c_cpp_properties.json\n{ \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Linux\u0026#34;, \u0026#34;includePath\u0026#34;: [ \u0026#34;/root/cu-gr/src/\u0026#34; ], \u0026#34;defines\u0026#34;: [], \u0026#34;compilerPath\u0026#34;: \u0026#34;/usr/bin/gcc\u0026#34;, \u0026#34;cStandard\u0026#34;: \u0026#34;c17\u0026#34;, \u0026#34;cppStandard\u0026#34;: \u0026#34;gnu++14\u0026#34;, \u0026#34;intelliSenseMode\u0026#34;: \u0026#34;linux-gcc-x64\u0026#34;, \u0026#34;configurationProvider\u0026#34;: \u0026#34;ms-vscode.cmake-tools\u0026#34; } ], \u0026#34;version\u0026#34;: 4 } launch.json\n{ \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;(gdb) Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;/root/cu-gr/build/iccad19gr\u0026#34;, \u0026#34;args\u0026#34;: [], \u0026#34;stopAtEntry\u0026#34;: false, \u0026#34;cwd\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;environment\u0026#34;: [], \u0026#34;externalConsole\u0026#34;: false, \u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;, \u0026#34;setupCommands\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true }, { \u0026#34;description\u0026#34;: \u0026#34;Set Disassembly Flavor to Intel\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;-gdb-set disassembly-flavor intel\u0026#34;, \u0026#34;ignoreFailures\u0026#34;: true } ] } ] } 一个相关bug\napt-get install gdb\n参考 # c++程序的 cmake编译+vscode来 debug 方法和步骤(ubuntu)_ubuntu c++ debug-CSDN博客\n参考 # CMake 保姆级教程（上） | 爱编程的大丙\ninstall # # 以v3.25.1版本为例 git clone -b v3.25.1 https://github.com/Kitware/CMake.git cd CMake # 你使用`--prefix`来指定安装路径，或者去掉`--prefix`,安装在默认路径。 ./bootstrap --prefix=\u0026lt;安装路径\u0026gt; \u0026amp;\u0026amp; make \u0026amp;\u0026amp; sudo make install # 验证 cmake --version Latex # latex in vscode # texlive2023+vscode安装与配置（简洁版） - 知乎 Visual Studio Code (vscode)配置LaTeX - 知乎 Hugo # 参考 # 如何用 GitHub Pages + Hugo 搭建个人博客 · KrislinBlog\n代理 # windows11 搭建 WSL2 运行环境（2024）-CSDN 博客\n"},{"id":20,"href":"/zh/docs/Other/window/","title":"Window","section":"Other","content":" vscode # remote-ssh # Host ISMC_Server_106 HostName your.ip Port 22 User pengxuan 系统重装 # 下载ISO # Windows 11 ISO Download – Official Direct Download Links - TechPP\n原版软件 (itellyou.cn)\n制作PE # 纯净无广告，又强又趁手的维护工具，FirPE使用和DIY指南_哔哩哔哩_bilibili\nFirPE:默认,全新制作\n跳过联网 # （Fn+）Shift+F10快捷键调出命令提示符窗口\n输入：OOBE\\BYPASSNRO\nwindows激活\u0026amp;office激活 # power shell 下打开输入irm win.zyqq.top | iex,然后根据提示\n初始化设置 # 使用dism++\n系统备份及还原方法 # win11一键备份还原系统方法_系统之家一键重装系统官网 (163987.com)\n成为管理员 # 无法打开WindowApps # 【快速解决】WindowsApps拒绝访问的问题_windowsapps文件夹拒绝访问-CSDN博客\nwin11家庭版升级为专业版 # cmd指令 # D: #进入d盘 cd .. dir "},{"id":21,"href":"/zh/docs/Other/Writing-PPT-Presentation/","title":"Writing Ppt Presentation","section":"Other","content":" Main Points # 某问题对推动科学发展或工程应用很重要，可通过多篇引用体现； 现有方法有A、B、C，但它们存在一定缺点； 本文提出一个新方法X。X是否第一次被提出？带来哪些影响？有无惊人结果？ 和现有方法相比，X在理论和实验中有更强的优势； X存在某弱点，我们计划在未来工作中如何改进。 Paper Structure # Title # ⽤用⼀一句话概括你所做的⼯工作\n考虑搜索引擎的影响，包含关键词\n可以适当地别出⼼心裁\nAbstract # 概括[Main Points](#Main Points)\n用语要简单，让外行能看懂\n避免技术术语、数学公式、和技术细节；\n不需要标注引用；\n需要对工作的新颖性和影响力进行强调；\n接在**”In this paper“**后面的一句最重要，它是对全文主要贡献的概括。\n常用结构举例：\nIntroduction # 更详细地概括[Main Points](#Main Points)\n要点是充分论证你所做⼯工作的必要性和重要性， 要让审稿⼈人认同并迫不及待想往下看\n避免技术术语、数学公式、和技术细节\n应假定读者不了解本文研究的具体问题，且不知道该问题的相关工作\n介绍为什么这是个重要的研究问题\n工作的创新点(3个及以上)\n最后一段通常是介绍论文的结构安排，举例\nThe rest of the paper is organized as follows. In Section 2, we discuss previous work on ... In Section 3, we describe ... In Section 4, we show ... In Section 5, we conclude the whole paper. 突出本文贡献，举例：\nTo the best of our knowledge, our work ... Related Works # 通常按发表时间顺序介绍各相关工作\n目的是向读者展示作者已经对相关工作有很深的认识和理解\n指明作者提出的工作和现有相关工作的不同之处\n注意你对这些相关工作的评价，因为审稿人很有可能是这些相关工作的作者:)\n传承与创新\n有时候会有Problem Definition\ne.g.\nProposed Method # 全文避免很深的层次结构，即避免subsubsection（如1.1.1） 第一小节可用于介绍论文通篇主要使用的数学符号，并全文保持符号和术语一致性 每小节第一段要简要介绍本节内容，每段第一句应是本段主题句，多用简单句 当需要提出新的定义、理论、方法、公式、参数时，解释这么做的动机 对重点内容要多次强调 注意前后呼应？ Experiments # 实验细节、对比结果、和讨论\nConclusions # 总结全文和未来工作 [Main Points](#Main Points)内容进行再次概括，对工作的新颖性和影响力进行更精准细致的强调 Acknowledge # 对审稿人、合作机构的致谢； 由什么项目/基金资助； Reference # 最好引用几篇你要投的会议/期刊中已经发表了的论文，免得说你主题不符； Writing Standard # TEXT # Italic \u0026amp; Orthography(正体) # 正斜体总的原则是变量（矢量，张量）等用斜体，数字、确定符号、词汇缩缩、单位等用正体\n正体一般表示常量，运算或说明，斜体一般表示变量\n详见参考 [2,3]\nBold \u0026amp; Thin # 加粗表示向量和矩阵，不加粗表示标量\nUppercase \u0026amp; Lowercase # 大写英文字母一般表示矩阵，小写英文字母表示变量或向量\nScalar \u0026amp; Vector # 标量符号用小写拉丁字母表示。为避免混淆字母 l 和数字 1 ，字母 l 可用 \\ell 替代。\n有结构的值，如句子、树、图等，用 \\boldsymbol（e.g. ）。\n向量值小写加粗。拉丁字母用\\mathbf（e.g. ），希腊字母用\\boldsymbol（e.g. ）。\n矩阵大写加粗。拉丁字母用\\mathbf（e.g. ），希腊字母用\\boldsymbol（e.g. ）。\n\\boldsymbol{x} 组成的集合用\\mathcal{X}（），a 组成的集合用 A（a A）。\n数域用\\mathbb{R}（），\\mathbb{Z}（）。\nEquation # 各种细节可看参考 [6]\n使用 align 表示一组公式，一般情况下以等号对齐会更好看。对齐方式：每个公式的等号处加 \u0026amp;。公式中的 softmax，proj，enc 等，超过一个字母的变量或符号，要用正文字体，即写成 \\textrm{softmax} 或 \\textit{FFN}。很多函数有现成的符号，例如：\\arg，\\max，\\sin，\\tanh。公式中的括号，要用\\left，\\right 进行标记。如 \\left(\\right)，\\left{ \\right}。\u0026lt;\u0026gt;、|| 这种括号也是一样的。括号中的分割可以搭配\\middle。\nGraph Design # 图片内部的字体应统一且跟正文文字大小一致\n整张图片两侧尽量不要有空白，保持紧凑\n图片通常在每一页的最上方或中间，而不是最下方\nTable Design # ![image-20240806164448901](C:\\Users\\Pxmmmm.DESKTOP-G18CTQU\\AppData\\Roaming\\Typora\\typora-user-images\\image-202408061644489 Academic English Writing # 工具 # 工具库 # www.yanweb.top\n语法检查，文章润色工具： # grammarly, writefull. [火山写作](快来尝试火山写作，一起体验写作的神奇能力！ https://www.writingo.net/invitation?key=yD22g%23YDyyH5)[【工具】论文润色工具 (yuque.com)]( https://ismc.yuque.com/kldg3t/wgf7g4/pbmveog10wolhabv) 批改网www.pigai.org(简单的批改，学术方面不行) citexs-赛特新思科研助手(主要是生物的) 画图工具 # drawio Prism - GraphPad PPT插件 # latex-ppt\nLesson # 一般使用第三人称被动语态 tips # a,an,the\nChglish # The Most Common Habits from more than 200 English Papers written.pdf · 华南理工大学微电子学院智能存储与计算研究小组 (yuque.com))\nTenses(时态) # Abstract：一般现在时 Introduction：一服现在时+现在完成时，没有过去时 Related Work：一服现在时+现在完成时+少量过去时 Method：一般现在时 Evaluation：一般现在时 Conclusion：一般现在时 Useful Sentence Pattern # 对审稿人和读者可能提出的问题，可以自问自答（One might wonder that \u0026hellip;/One might argue that \u0026hellip;） i.e. 即。 eg: Timing closure requires that the delay of each timing path must satisfy some constraints, i.e., be less than a single clock cycle. e.g. 例如 w.r.t. 关于 一般不要用etc. 要用such as words should avoid # obvious \u0026ndash;\u0026gt;straightforward always \u0026ndash;\u0026gt; generally never \u0026ndash;\u0026gt; rare avoid \u0026ndash;\u0026gt;alleviate etc. \u0026ndash;\u0026gt; such as about -\u0026gt; approximately, estimated thought不能句首，只能用although get worse \u0026ndash;\u0026gt; deteriorate make easier \u0026ndash;\u0026gt; facilitate do better \u0026ndash;\u0026gt; improve How to Research # Choosing a Research Project # You must be enthusiastic about it. Solving the problems it entails must be worthy of a Ph.D. It must be within sight of the state of the art, i.e. it must be ‘do-able\u0026rsquo; in three years. There must be someone in the department willing to supervise it. Pitfalls for Postgraduate Students # researchers_bible.pdf (jdl.link)\nSolving the World\nManna from Heaven\nComplete an initial electronic literature search in your chosen topic/field Use electronic sources - papers published on the WWW and through subscriptions to relevant News Groups. Read the literature. Talk to people. Tackle a simplified version of your problem Write down your ideas in a working paper Give a seminar to your research group Computer Bum\nYour work must be explainable at a higher level than code, Undertake some of Einstein\u0026rsquo;s \u0026rsquo;thought experiments'.\nMicawberism(空想乐天主义)\nIvory Tower\nKeep in touch with the state of the art in related fields\nMisunderstood Genius\nAmbition Paralysis\nMethodology does not make a thesis\nIf your view is so wildly radical that you really need to spend fifty pages expounding it, it may be slightly suspect.\nSidetracks\nThe Development Trap\nResearch Methodology # have a question in mind classify paper you read with degree of association with your topic Rebuttal # 【技巧】关于Rebuttal (yuque.com)\nPPT Design # 演讲者视图 # text # 通过母版设置整体中英字体 白底黑字 size一般不要小于18 标题使用微软雅黑，正文用宋体和Times New Roman 重点使用加粗和红色 使用虚线在同一页对不同的内容进行分割 注意对齐 graph # 封面包括：标题、作者（通讯作者后加*）、作者机构、会议信息、日期、机构图标、会议图标 多个图注意长宽设计，最好 矢量图（没法使用矢量图则需要） table # Presentation # Reference # 1.论文格式细节整理汇总 - 知乎 (zhihu.com)\n2.科技论文写作规范：字母正斜体_万维书刊 (eshukan.com)\n3.科技论文书写规范之正斜体问题_公式中的正斜体使用规则-CSDN博客\n4.论文公式中字体的意义 - 知乎 (zhihu.com)\n5.论文写作注意细节总结_向量和矩阵都用加粗-CSDN博客\n译学术论⽂文 写作⽅方法和技巧-刘洋\n6.Paper-Writing-Tips: MLNLP社区用来帮助大家避免论文投稿小错误的整理仓库。 Paper Writing Tips (github.com)\n7.\u0026ldquo;How to Research\u0026rdquo; Summary-Decheng Chen\n8.国际学术会议英文口头报告(Oral presentation)常用语句 - 凯鲁嘎吉 - 博客园 (cnblogs.com)\n# "},{"id":22,"href":"/zh/docs/","title":"介绍","section":"介绍","content":" 你好！ # 一些记录\n"}]