[{"id":0,"href":"/zh/docs/example/","title":"Example Site","section":"Docs","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret Est simul fameque tauri qua ad # Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol # Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo; Trepident sitimque # Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"},{"id":1,"href":"/zh/docs/mydocs/","title":"Mydocs","section":"Docs","content":"Mydocs\nIntroduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret Est simul fameque tauri qua ad # Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol # Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo; Trepident sitimque # Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"},{"id":2,"href":"/zh/docs/Digtal/","title":"Physical design","section":"Docs","content":" Physical design # "},{"id":3,"href":"/zh/docs/mydocs/sub0/","title":"Sub0","section":"Mydocs","content":"Sub0\n"},{"id":4,"href":"/zh/docs/mydocs/sub0/subsub0/","title":"Subsub0","section":"Sub0","content":"Subsub0\n"},{"id":5,"href":"/zh/docs/example/table-of-contents/with-toc/","title":"With ToC","section":"Table of Contents","content":" Caput vino delphine in tamen vias # Cognita laeva illo fracta # Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\nTe at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit Natus quaerere # Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\nPhrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\nLimitibus misere sit # Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua # Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta # Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"},{"id":6,"href":"/zh/docs/mydocs/sub1/","title":"Sub1","section":"Mydocs","content":"Sub1\n"},{"id":7,"href":"/zh/docs/mydocs/sub0/subsub1/","title":"Subsub1","section":"Sub0","content":"Subsub1\n"},{"id":8,"href":"/zh/docs/example/table-of-contents/without-toc/","title":"Without ToC","section":"Table of Contents","content":" At me ipso nepotibus nunc celebratior genus # Tanto oblite # Lorem markdownum pectora novis patenti igne sua opus aurae feras materiaque illic demersit imago et aristas questaque posset. Vomit quoque suo inhaesuro clara. Esse cumque, per referri triste. Ut exponit solisque communis in tendens vincetis agisque iamque huic bene ante vetat omina Thebae rates. Aeacus servat admonitu concidit, ad resimas vultus et rugas vultu dignamque Siphnon.\nQuam iugulum regia simulacra, plus meruit humo pecorumque haesit, ab discedunt dixit: ritu pharetramque. Exul Laurenti orantem modo, per densum missisque labor manibus non colla unum, obiectat. Tu pervia collo, fessus quae Cretenque Myconon crate! Tegumenque quae invisi sudore per vocari quaque plus ventis fluidos. Nodo perque, fugisse pectora sorores.\nSumme promissa supple vadit lenius # Quibus largis latebris aethera versato est, ait sentiat faciemque. Aequata alis nec Caeneus exululat inclite corpus est, ire tibi ostendens et tibi. Rigent et vires dique possent lumina; eadem dixit poma funeribus paret et felix reddebant ventis utile lignum.\nRemansit notam Stygia feroxque Et dabit materna Vipereas Phrygiaeque umbram sollicito cruore conlucere suus Quarum Elis corniger Nec ieiunia dixit Vertitur mos ortu ramosam contudit dumque; placabat ac lumen. Coniunx Amoris spatium poenamque cavernis Thebae Pleiadasque ponunt, rapiare cum quae parum nimium rima.\nQuidem resupinus inducto solebat una facinus quae # Credulitas iniqua praepetibus paruit prospexit, voce poena, sub rupit sinuatur, quin suum ventorumque arcadiae priori. Soporiferam erat formamque, fecit, invergens, nymphae mutat fessas ait finge.\nBaculum mandataque ne addere capiti violentior Altera duas quam hoc ille tenues inquit Sicula sidereus latrantis domoque ratae polluit comites Possit oro clausura namque se nunc iuvenisque Faciem posuit Quodque cum ponunt novercae nata vestrae aratra Ite extrema Phrygiis, patre dentibus, tonso perculit, enim blanda, manibus fide quos caput armis, posse! Nocendo fas Alcyonae lacertis structa ferarum manus fulmen dubius, saxa caelum effuge extremis fixum tumor adfecit bella, potentes? Dum nec insidiosa tempora tegit spirarunt. Per lupi pars foliis, porreximus humum negant sunt subposuere Sidone steterant auro. Memoraverit sine: ferrum idem Orion caelum heres gerebat fixis?\n"},{"id":9,"href":"/zh/docs/example/table-of-contents/","title":"Table of Contents","section":"Example Site","content":" Ubi loqui # Mentem genus facietque salire tempus bracchia # Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice # Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); Placabilis coactis nega ingemuit ignoscat nimia non # Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; } Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":10,"href":"/zh/docs/Digtal/flow/EDA4PR/","title":"Eda4 Pr","section":"Physical design","content":" 研究背景 # **典型的芯片设计流程是先做前端、后端设计，再去验证性能、功耗和面积。**但由于流程太长，在前端设计的时候，无法保证后端设计的效果，所以很多时候需要进行跨环节建模，在早期设计环节预测后续环节的求解质量，这当中就很适合AI算法来进行辅助。\n除了建模之外，另外一个关键问题是优化。EDA中经常要求解各种各样的组合优化问题。这些问题往往是 NP难题，比如经典的旅行商问题。传统上，我们会通过一些启发探索的方法来求解。但随着规模不断增大、设计约束越来越多，这种探索往往遇到效率瓶颈，所以我们需要通过机器学习技术进行辅助，寻找有效策略，提高效率。\n难点 # 大图\u0026ndash;\u0026gt; 数据集\u0026ndash;\u0026gt; 泛化能力\u0026ndash;\u0026gt; 非DAG? route: 3D，45°，30° 先进的工艺：7nm 很多Placer and Router还是有很多人工定义的超参数？（不general） 现在真的还有必要把Router分成Global 和Detail 吗？ GR: total maze routing GR: Consider timing and power consumption 研究方向 # Cross-Stage Prediction # routing congestion prediction # background # Routing congestion can overwhelm routing resources and lead to low cell utilization and routing detours\ncongestion is not known accurately until late in the design cycle, after placement and routing.\nMany modern placement and synthesis tools leverage congestion estimation in their cost analysis in order to minimize the effects of congestion in the final physical design\nIt is known that the total net length can be a good proxy for congestion\nA simple approximation for congestion prediction is to use the size of the local neighborhood\n和fan-in, fan-out强相关\nPrecise congestion prediction from a placement solution plays a crucial role in circuit placement\nMultiple previous works have attempted to predict detailed routing congestion in the placement step in an effort to optimize routability of the placement solution: RUDY, POLAR 2.0. All these techniques are implemented in the placement step and need the position information of cells .\nTo avoid the high computation cost of placement, it is more useful to be able to predict congestion in the logic synthesis phase.\ncongestion prediction problem can be frame as node regression problem\nwith the growth of circuit scale and complexity, time consumption tends to be unacceptable when utilizing a global router in the placement cycle to obtain the congestion map.\nCurrent machine learning models commonly follow a two-phase workflow. First, based on domain knowledge, human experts generate various local features on the circuit using predefined functions on netlist. Then, based on the generated features, a specific model, e.g. convolution neural network (CNN) model is designed to predict either the routing demand map or the congestion map\nthe emergence of Graph Neural Network (GNN) triggered applications of undirected homogeneous graphs models on routing congestion prediction, since a VLSI circuit can be naturally represented by a graph\nRouteNet-DRC Hotspot Prediction-ICCAD-2018-CNN # background:\nEvery chip design project must complete routing without design rule violation before tapeout. However, this basic requirement is often difficult to be satisfied especially when routability is not adequately considered in early design stages.\nIn light of this fact, routability prediction has received serious attention in both academic research and industrial tool development. Moreover, routability is widely recognized as a main objective for cell placement\nCNN and Transfer Learning\nCNN learns more abstract patterns from images Our RouteNet transfers such state-of-the-art ability in image pattern recognition to circuits for capturing the patterns about routability. RouteNet predicts routability based on a pretrained ResNet architecture Fully Convolutional Network (FCN): outputs an image with size equal to or smaller than input. many FCNs have both deep and shallow paths in one network. RUDY(Rectangular Uniform wire DensitY)\n它被用作我们RouteNet的输入特征，因为它与路由拥塞部分相关，获取速度快，可以直接表示为与RouteNet相吻合的图像 challenge of macros\nThe orange circles in Figure 3 indicate a strong tendency for hotspots to aggregate at the small gap between neighboring macros Blue dashed circles indicate the remaining sparsely distributed hotspots 有macro，线性程度低 task:\npredict overall routability (DRC count), 分类任务，预测总的#DRV predict DRC hotspot locations.DRC hotspots mean the specific locations with high density of DRVs. like an end-to-end object detection task, which is more difficult to solve. GCell内#DRV超过设定值则为DRC hotspot contribution:\nmixed-size macros first systematic study on CNN-based routability prediction high accuracy and high speed flow:\nmodel\n#DRV prediction\nResNet18-based\npreprocess\nResNet是一个固定输入（224*224）的模型，为了使用知识迁移，将输入 通过插值的方法变成 。具体怎么插？\nhotspot prediction\ndata:\ndataset:\nISPD 2015 benchmarks\ndifferent placement made by “obstacle-aware macro placement\u0026quot; algorithm [5].\neach floorplan is placed and routed by Cadence Encounter v14.20 [2]\nexperiment:\nwe compare the TPR of all methods under the same FPR (error under 1%)\nCongestionNet-predict congestion hotspots-IFIP-2019-GNN(GAT)-nvidia # a graph-based deep learning method for predicting routing congestion hotspots from a netlist before placement. Predict the detail routed lower metal layer congestion values\nwhy low layer? 因为较低金属层上的拥塞主要是由局部逻辑结构驱动的，而不是由无关逻辑簇之间的较长互连驱动的，后者往往在较高金属层上运行. predicting lower metal layer congestion is not only more important for the underlying task of identifying congested logic structures, but also simplifies the task for our graph based network\ncontribution:\n阶段早,只使用网表 由于该模型仅基于网表的逻辑结构而不是任何特定的单元布局进行预测，因此它消除了基于布局的方法中存在的次优布局的伪影 can be done without any physical information GNN, 快 the first work exploring the use of graph based deep learning for physical design problems 数据:\nroughly 5000 distinct cell types\nwe project our per cell predictions back onto their respective 2D grid (using the final ground truth physical placement) and average all cells within each grid cell to come up with a predicted value that can be compared to the original ground truth grid value.\n模型参数:\nan 8 layer Graph Attention Network (GAT) with size 16 intermediate (or hidden) state\n无向图, each node corresponds to a cell\n节点特征: length 50 for each cell type and each cell’s logic description as well as the pin count and cell size of that cell\n实验:\nreport correlation values using the Kendall ranking coefficient\n实际效果可视化\n对比实验\n消融实验\ncell type or function is an essential part of our predictions.\ncell type 不是没起作用吗\n缺点:\nmodel needs to be retrained for every new process technology, since the embeddings are over cell types specific to a process technology. it occasionally over predicts congestion in areas of low to moderate congestion, such as in most failing parts of Partition A due to the graph based nature of the model, it sometimes makes overly soft decision boundaries the CongestionNet uses informative cell attributes (cell size and pin count) alone as the input to the GAT and does not use any embedding encoding the netlist structure 可改进的点:\n-Congestion prediction + embedding + matrix factorization + partition-arXiv-2021-GNN(Sage)- # background\npredicting cell congestion due to improper logic combination can reduce the burden of subsequent physical implementations. previous work: require informative cell features Although the global routing result provides a good estimation of routing congestion [6], [19], an awareness of high congestion areas at an early design stage is of great importance to provide fast feedback and shorten design cycles Multiple works have attempted to predict detailed routing congestion in the placement step in an effort to optimize routability of the placement solution task\nduring the logic synthesis stage\n到底是什么时候的congestion数据? Routing后的真实值还是预测plcament后的congestion RUDY预测值? 应该是Global Routing后的:强调了congestion value = wiring demand/routing capacity\ncontrbution\ndata\nDAC2012 contest benchmark\nhttp://archive.sigda.org/dac2012/contest/dac2012_contest.html\nOpenROAD dataset\nplace via DREAMPLACE\nMacros and terminals are removed from the graph\nNets with degree more than 10 are excluded from the final graph as they introduce cliques too large to work with efficiently.\nnode features (pin number, cell size) , This follows the flow of CongestionNet\nflow:\ncongestion value for each grid cell computed as the wiring demand divided by the routing capacity , The output along the z-axis is reduced by a max function,\nOur focus is on predicting congestion due to local logic structure, which manifests itself on lower metal layers. Therefore, we use congestion labels from the lower half of the metal layers to train and evaluate the model\n推理的时候取所有cell的预测平均值\nprinciple\n提出相连越近的节点相似度越高,\n提出structural node similarity\nSub-graph partition ? METIS? ClusterGCN?\nMatrix Factorization ?\nmodel\nThe key difference between this approach and CongestionNet lies in embedding pipeline\ngraph is undirected complete circuit is too large for direct matrix factorization and must be partitioned into clusters, use METIS partitioning tool in ClusterGCN\nSub-graph partition: clusters of ≈ 5000 nodes each\nMatrix Factorization ?\nexperiment\nthree metrics of correlation to measure performance: Pearson, Spearman, Kendall\nBefore evaluation, both the prediction and the label have some (very low) noise added to them.\nPGNN-DRVs prediction+Pin Proximity Graph-ICCAD-2022-GNN+UNet(CNN)-Korea # background\n(1) pin accessibility and (2) routing congestion are two major causes of DRVs (design rule violations)\nParticularly, the complex design rules put so much burden on physical design, demanding lots of iterations on the time-consuming process of cell placement and net routing to clean up all DRVs (design rule violations) before tapping out . Thus, at the placement stage, if we were able to identify, with high confidence, DRC (design rule check) hotspots that would be likely to occur at the routing stage, we can pay more attention\nshortcoming of image based:\nlocal pin accessibility cannot be accurately modeled by pin pattern image alone\nusing high-resolution pin pattern images incur significant additional run-time as well as memory overhead to the prediction models\nto optimize the placement before routing.\ntask\na novel ML based DRC hotspot prediction technique,\nGNN is used to embed pin accessibility information, U-net is used to extract routing congestion information from grid-based features placement 分割为grid, 长宽=G-Cell DRVs are extracted as the ground-truth after detailed routing contribution\nGNN model, base pin proximity graph model\nPGNN can adopt pin proximity graph as well as grid-based feature map as input feature\nPin Proximity Graph :\n无向图， 同构图 U-Net:\nfeatrue:\n整体模型:\n数据集:\n以后也可以这么做, 同一个benchmark不同的config参数就有不同的数据\nexperiment\nNangate 15nm library\n9 groups are used for training and the remaining 1 group for test. K折验证\npositive 和 negative是什么意思?\n可视化:\n消融实验:\n以后也可以这样用特征消融?\n对比实验(F1-score):\n注意不需要GR!\nGR-Cong is obtained from ICC2 after global routing stage, and grids with high routing congestion are classified as DRC hotspot. 商用\nRouteNet和J-Net都是相关的学术工作\n时间对比:\nLHNN-CongestionPrediction-DAC-2022-GNN-CUHK+Huawei+YiboLin # background\n图的节点的设置很新颖 with the growth of circuit scale and complexity, time consumption tends to be unacceptable when utilizing a global router in the placement cycle to obtain the congestion map. due to the need for the \u0026ldquo;shift-left\u0026rdquo; in circuit design, researchers begin to seek alternative solutions in machine learning [4] [5] to achieve accurate and fast congestion map prediction task\ntwo related tasks, routing demand regression and congestion classification data\nregard each G-cell as a node and add an edge between two nodes if the respective two G-cells are adjacent.\nhypergraphs and heterogeneous graph , 两种节点：G-cell和G-net\nfeature：\nISPD 2011 [16] and DAC 2012 [17] contest benchmarks ,\nmodel\n他这里说congestion map是一个二值化(0/1?)的数据集， 所以是分类任务, 但是为了利用数据，同时防止routing demand的信息丢失， 还设置了一个预测routing demand的任务？\nexperiment\n15benchmarks: 10 for training and 5 for testing\nrun DREAMPlace [18] on each of the designs to generate placement solutions\nNCTU-GR 2.0 [2] to attain horizontal/vertical routing demand maps , and set the congestion maps as a binary indicator according to whether the horizontal/vertical routing demand of the G-cell exceeds the circuit’s capacity\n对比实验：\n可视化：\n消融实验：\n-NN Robustness improve-arXiv-2024- -UC- # background:\n最近的工作已经证明神经网络通常是容易受到精心选择的输入小扰动的影响 Our definition of imperceptibility is characterized by a guarantee that a perturbation to a layout will not alter its global routing recent work [10, 18] has demonstrated that image classifiers can be fooled by small, carefully chosen perturbations of their input task\ndesign two efficient methods for finding perturbations that demonstrate brittleness of recently proposed congestion predictors one potential approach to address the issues by modifying the training procedure to promote robustness contribution\nPainting on PIacement-predict the routing congestion-ACM-2019-GAN-\n-DRC Hotspot Prediction-ISCAS-2021-CNN\n-Routing Congestion Prediction-ASPDAC-2020-GAN\nslice FPGACong_ASPDAC20 (yibolin.com) -predict #DRV, a macro placer-DATE-2019-CNN\nTiming Prediction # Pre-Routing Timing Prediction # background # relate work # TimingGCN-STA prediction-DAC-2022-GNN\nthe first work！ opensource still relies on local net/cell delay prediction as auxiliary tasks no optimization, not fit the real-world scenario where timing optimization is taken into account PreRoutGNN-STA prediction-AAAI-2024-GNN\nopensource [Multimodal Fusion-Restructure tolerant+CNN+Endpoint-wise Masking4Layout -DAC-2023-GNN+CNN-7nm RISCV](D:\\MyNotes\\EDA\\Timing\\Multimodal Fusion-Pre Route Timing Prediction-DAC-2023-GNN-7nm RISCV.pdf)\nslice\nRestructure：预测终点的延时，但是Timing Opt会改变网表结构(end point不变）。对一个Pre-routing任务来说，输入的网表和最终的网表不一样\nnetlist restructuring causes a mismatch between local input features and ground-truth features in the restructured sub-regions\nAs a result, prior local-view models can only be trained on the unchanged regions in a semi-supervised manner.\nIn other words, the better the models fit on labeled (unreplaced) net/cell delays, the worse they fit on replaced regions and eventually on endpoint arrival time\n数据集：基本信息和Timing优化导致的网表变化\naverage 40% nets and 21% cells are replaced during timing optimization timing optimization brings an average change of 59.6% to net delays and 33.3% to cell delays 为什么用layout信息：Since most timing optimization techniques include gate insertion or gate sizing, placement should reserve space for subsequent timing optimization. In other words, the timing optimizer’s efficacy is tied closely to global layout information. The layout information plays a dominant role in determining the timing optimizer’s impact since most optimization techniques need space to be applied\n整体模型\n组成：GNN+CNN+Endpoint-wise Masking\nNetlist(GNN): 和 TimingGCN-STA prediction-DAC-2022-GNN很像(没发现不同)\nLayout(CNN+Endpoint-wise Masking)\n三个特征：cell density, rectangular uniform wire density (RUDY), and macro cells region\nEndpoint-wise Masking\n对比实验：\nrun time实验\nother # Ahead RC network-STA prediction-DAC-2022-?\nTSteiner-STA prediction and refinement\u0026amp;steiner point refinement-DAC-2023-GNN-Yibo Lin\nDoomed Run Prediction-TNS prediction-ACM-2021-GNN+RNN\nnot DL # The two-stage approaches [2], [3] first predict localnet/cell delays and then apply PERT traversals [5] to evaluate the global timing metrics, i.e., endpoint arrival time.\nOptimization # Timing # TSteiner - Steiner Points Opt-DAC-2023-GNN-CUHK\nbackground\n对于multi-pin net需要构建steiner tree来进行routing，故steiner tree中steiner points也会影响routing\nFLUTE[ 3]是常用的生成steiner tree的算法。在生成steiner tree后，我们可以通过近一步优化steiner point来优化timing\nthe previous early-stage timing optimization works only focus on improving early timing metrics. 提出了诸如net加权和可微分时间目标等策略来优化时间, only focus on improving pre-routing timing metrics, which may have a considerable gap to signoff timing performance. 斯坦那点更加靠近布线阶段(和布线更加相关)\nall the aforementioned works are not directly targeted at sign-off timing performance due to its high acquisition cost\n任务:\nIn this paper, we focus on explicit sign-off timing optimization at the pre-routing stage to reduce the turnaround time\noptimization framework is built to adjust Steiner point positions for better sign-off timing performance iteratively\nThe most popular Steiner minimum tree construction algorithms aim to minimize wirelength. Moreover, the Steiner point refinement is introduced to update the generated Steiner point positions for specific objectives, e.g., sign-off timing performance, while maintaining the two-pin net connections\n启发:\nwe surprisingly find that the signoff timing performance could be significantly affected even by a random disturbance on Steiner point positions, as shown in Fig. 2.\nNevertheless, the impact of random moving is considerately unstable, and its average performance is slight (with a ratio close to 1.0). 所以启发找到一个好的方法来更新斯坦纳点来降低TNS\n在最广泛使用的技术节点中，与路径长度最相关的定时度量——净延迟，并不能解释大部分的整体定时性能. 这里用的初始化斯泰纳树的方法的优化目标都是路径长度最短\ncontribution:\nfirst earlystage timing optimization framework via Steiner point refinement GNN TSteiner framework is fully automated with an adaptive stepsize scheme and the auto-convergence scheme improves 11.2% and 7.1% on average (up to 45.8% and 43.9%) for WNS and TNS 模型:\nSteiner tree construction decomposes each multi-pin net into a set of two-pin nets via additional Steiner points before global routing to reduce the problem complexity\nThe proposed framework can be divided into two stages, sign-off timing gradient generation (Section III-A) and concurrent Steiner point refinement (Section III-B)\n和TimingGCN相比就是多了Steiner 节点, 然后吧第一部分的的node embedding部分加上了steiner的部分\n实际是: 优化的指标, WNS和TNS的加权\n根据优化指标对斯泰纳点坐标参数做梯度下降\n相比简单的梯度下降，只是减小了对不同benchmark的手动学习率微调\n数据\n实验\nMarco Placement # -marco placement-nature-2021-RL+GNN-google\nPlacement # -Pin Accessibility+DRV prediction-DAC-2019-CNN-NTU # background:\nStandard cells on the lower metal layers severely suffer from low routability due to high pin density, low pin accessibility, and limited routing resources.\nIt can be observed that the access points of pin B are blocked by the metal 2 (M2) routing segments routed from Pin A and Pin C, so an M2 short design rule violation (DRV) will be induced when dropping a via12 on Pin B. pin accessibility is not only determined by cell layout design but also strongly affected by adjacent cells\n对于传统方法，两个缺点：\nCell libraries provided by foundries should not be considerably redesigned because the optimized cell performance and manufacturability may be highly sensitive to cell layouts Deterministic approaches based on human knowledge have been shown to be less effective in advanced nodes for optimization problems such as DRV prediction and minimization because of the extremely high complexity through the overall design flow It can be observed that most of the congested regions in the layout do not have DRVs, while some regions with DRVs are not so congested. 但是我感觉还是有相关性的。他是想说明congestion出现的地方不一定有DRV，但是没congestion的地方可能因为poor pin accessibility导致DRV\n也是说明：congestion出现的地方不一定有DRV，但是没congestion的地方可能因为poor pin accessibility导致DRV the two M2 shorts occur at the locations having the same pin pattern in the top cell-row and mid cell-row task:\nDRV prediction, 二分类\npin accessibility optimization, 给一个合法化后的布局结构，通过算法进行减少bad pin accessibility的detailed placement\n其实也是一个预测模型，一个优化模型\ncontribution:\nfirst work to apply pin pattern as the input features of DRV prediction models. flow:\nmodel:\nPPR\u0026amp;DFPPR:\nModel-guided Detailed Placement :\nDynamic Programming-based Placement Blockage Insertion\n还会改方向？ Cell Displacement Refinement\ndata:\nBoth the width and height of each pixel are set as the minimum spacing of the M1 layer in order to prevent a pixel from being occupied by two different pins.\n没看见关于benchmark的描述\nexperiment:\nshortcoming:\nflow need routed designs to train, time The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries 对于VLSI，一行一行，一对一对进行，很慢？ -Pin Accessibility+activ-ISPD-2020- -NTU+Synopsys # background:\nWith the development of advanced process nodes of semiconductor, the problem ofpin accesshas become one of the major factors to impact the occurrences of design rule violations (DRVs) due to complex design rules and limited routing resource\nsupervised learning approaches extract the labels of training data by generating a great number of routed designs in advance, giving rise to large effort on training data preparation. the pre-trained model could hardly predict unseen data\nUnlike most of existing studies that aim at design-specific training, we propose a library-based model which can be applied to all designs referencing to the same standard cell library set.\nDue to the shrinking of modern process nodes of semiconductor, the pin access problem of standard cells has become more harder to be coped with, especially on the lower metal layers.\n在这种placement下，Metal1 pin A/B由于各自左右两边在Metal2有pin，而且只能在黄色track下横向绕线，（Metal1不能绕线？），那么Pin A/B通过Via12后必定会短路\n19年工作[5]的两个缺点\nflow need routed designs to train, time The trained model is not necessarily applicable to other designs using different cells or different reference cell libraries contribution:\nfirst work of cell library-basedpin accessibility prediction (PAP), which can be applied to predict other designs referencing to the same cell library set applies active learning to train a PAP model the proposed cell library-based PAP model can be trained at the earlier stage in a process development flow: once the cell libraries are provided. Placement Optimization with Deep Reinforcement Learning- -ISPD-2020-RL+GNN-Google # PL GNN-Affinity Aware for ICC2- ISPD-2021-GNN-Atlanta # background:\nPlacement is one of the most crucial problems, placement directly impacts the final quality of a full-chip design\nmultiple placement iterations to optimize key metrics(WL, timing), which is time-consuming and computationally inefficient, VLSI\nthe logical affinity among design instancesdominates the quality of the placement\nlogical affinity 源于这篇文章？\nperforming placement guidance requires in-depth design-specific knowledge,which is only achievable by experienced designers who knows the underlying data flows in Register-Transistor Level (RTL) well\nK-means基础：\ntask:\n基于网表数据，和floorplan结果（marco已经放好） placement guidance(grouping information) for commercial placers ICC2, by generating cell clusters based on logical affinity and manually defined attributes of design instances our framework will determine the cell clusters in an unsupervised manner which serve as placement guidance in order to guide commercial placers to optimize the key metrics such as wirelength, power, and timing by placing cells with a common cluster together flow:\nTwo stages:\nGNN do unsupervised node representation learning, (it is generalizable to any design)\nweighted K-means clustering algorithm [3] to group instances into different clusters。To find the optimal number of groups for clustering, we introduce the Silhouette score [19] and perform sweeping experiments to find the sweet spot\nK-means算法的基本思想是：通过迭代的方式，将数据划分为K个不同的簇，并使得每个数据点与其所属簇的质心（或称为中心点、均值点）之间的距离之和最小。\ndata\ntwo multi-core CPU designs：\nnf\ndesign hierarchy : 根据网表层级. top/inst1/sky130_INV/A. (同时zero-padding)\nlogical affinity of memory macros ：logical levels to memory macros 𝑀 as features. because the logic to memory paths are often the critical timing paths\nef:\nmodel\nGraphSAGE-based， two layers\nLoss Function:\nSilhouette score\n用于评估分类结果，扫描分类数目，选择最高的分的\nexperiment:\nenv:\n2.40𝐺𝐻𝑍 CPU NVIDIA RTX 2070 16𝐺𝐵 memory. PyTorch Geometric setting:\nthe placement of memory macros is achieved manually based on design manuals provided by the design-house Adam result\nLouvain：比较实验对比模型\nQuestion:\nbenchmark少\n扫描到的就适用所有？\n开环？\n-Innovus PPA placement optimize-Neurips-2021-RL # contribution:\n-GP Routability Opt-DAC-2021-FCN-CUHK(SitingLiu BeiYu)+Yibo Lin # background\nflow\nthree input features are extracted from the cell placement solution Through the inference of the pre-trained routability prediction model, we get the predicted congestion map. take mean squared Frobenius norm of this congestion map as the congestion penalty data\nmodel\nRouting # global routing # backeground # gr\ndrc\nPROS-Routability Optimization-ICCAD-2020-FCN-CNHK+Cadence # background\ntask\ncongestion predictor and parameter optimizer only the data from the placement it can optimize the cost parameters before the first routing iteration of GR and thus can give a better GR solution with less congestion. contribution\nwith negligible runtime overhead plug-in can be embedded into the state-of-the-art commercial EDA tool (Cadence Innovus v20.1) model\ndata\n19 different industrial designs\n通过不同的placement参数和旋转（CNN原理），一共有1664 design cases in total.\nFeature Extraction\nHorizontal/Vertical track capacity map\nCell density map\nFlip-flop cell density map\nFixed cell density map\nCell pin density map\nPin accessibility map\nHorizontal/Vertical net density map\nSmall/Large-net RUDY map\nPin RUDY map\na combination of cell pin density map and large-net RUDY map\nLabel Generation\nPROS does not need very detailed congestion map\ntwo-step smoothening process to convert raw data to desirable congestion labels\nhelp to make the prediction task easier\nif there are at least six congested G-cells out of the eight in the surrounding of a center G-cell д, д will be labeled as congested\n优化原理\n这两个值在cadence怎么改的? cadence企业内部自己弄的（这是cadence的文章）？\nmodel\nexperiment\nPROS 2.0 - Routability Opt+Route WL estimation-Trans-2023-CNN-CNHK+Cadence # background\nthe amount of routing resources on a design is limited. The quality of a GR solution has a great impact on that of the resulted DR routing solution Congestion in a GR solution is one of the major causes of DRC violations in the DR solution since most of DRC violations are due to overcrowded wires and vias [1], [2] a better GR solution with less congestion is needed to lower the probability of getting DRC violations in advance. if the initial GR solution is not good and has a lot of congestion, the GR tool can hardly tackle the problem by rip-up and reroute. placement engines [3]–[5] which take routing congestion into consideration are applied FCN:FCN常用于图像中的每像素分类问题。采用任意输入大小，并产生大小完全相同的输出。GR拥塞预测也可以被视为任意大小的芯片设计上的像素二进制分类问题（拥塞与否）。因此，基于FCN的预测器可以自然地应用于PROS。 task:\nstage: post-placement, pre-route FCN based GR congestion predictor, use the predicted GR congestion to optimize the cost parameters of GR. predictor based parameter optimizer to generate a better GR solution. GR tools are driven by the cost parameters stored in each G-cell. When arriving at a G-cell g, the tool will compute the cost, called moving cost, to move to each of its neighboring G-cells and push these costs into a heap. With optimized cost parameters in G-cells, the GR tool can find better paths and allocate the routing resources to each net more smartly. PROS optimizes two types of cost parameters based on the prediction result, including overflow cost and wire/via cost . PROS will adjust the cost parameters in the projected congestion regions on all layers overflow cost wire/via cost: divided into two groups (small/large) according to their BBox sizes. Increasing the wire/via cost for small nets may be useless for congestion reduction and it may even increase the wire length or create new congestion due to detours out of the potential congestion region. In contrast, increasing the wire/via cost for large nets can be helpful since they can select another route within its BBox to completely avoid the potential congestion region CNN based wirelength estimator , By multiplying the predicted wirelength ratio and the precomputed FLUTE wirelength (训练一个系数). The lack of consideration of routing congestion in traditional methods is due to the dif ficulty of quickly obtaining accurate congestion estimation at the placement stage contribution:\nplug-in for Innovus: it can avoid extra runtime overhead of feature preparation industrial design suite advanced technology node SOTA high accuracy first work that utilizes the information of GR congestion to estimate routed wirelength at the placement stage PROS does not change a lot for the original EDA steps Overall Flow :\n分类和回归\nF is the feature number. XWL has two features: These two features will be resized to 128 × 128 before prediction the predicted congestion map the cell pin density map data\nfeature F\nHorizontal/Vertical Track Capacity Map\nCell Density Map\nFlip-Flop Cell Density Map\nFixed Cell Density Map\nCell Pin Density Map\nPin Accessibility Map\nHorizontal/Vertical Net Density Map\nSmall/Large-Net RUDY Map\nPin RUDY Map ?\nlabel\ncongestion label pre-process\nPROS does not need a very detailed congestion map\n最后还是为了优化服务的\nmodel\nDC: get more local information, but more GPU usage(acceptable) SUB: w*h*4c –\u0026gt;2w*2h*c. Compared with bilinear upsampling which is not trainable, subpixel upsampling can learn to recover the local information. Compared with deconvolution, subpixel upsampling is parameter free, so it will not significantly increase the training difficulty. dataset\nindustrial benchmark suite and DAC-2012 benchmark suite(19个 benchmark)\nindustrial benchmark suite 通过11种不同布局参数，翻转和旋转，制造了一共有1664个(约等于19*11*8)benchmark\nDAC-2012 20 different placements\n(4, 4, 4, 4, 3) 5折交叉验证\nexperiment\nenv\nTensorflow Intel Xeon CPUs at 2.2 GHz 256 GB memory NVIDIA TITAN V GPU setting\nAdam\nOne entire training process of the congestion predictor has 25 training epochs! 这么少（收敛好快）\ncongestion classification prediction\ncompare with PROBABILISTIC METHODS\nDR优化结果\n线长估计\nRuntime\ndetail routing # background # -Detailed Router-DATE-2021-RL # [DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route](\u0026ldquo;D:\\MyNotes\\EDA\\Routing\\DPRouter-Detail Routing(package design) Opt+net order decision-ASPADC-2023-RL(MARL)-diagonally route.pdf\u0026rdquo;) # BackGround\nmost time-consuming stages in the package design flow package designs have fewer layers; thus, we need to prevent net crashing cautiously contrbution:\nredefine the routing area and shrink the routing problem by dividing the entire design into non-overlapping boxes use DRL, not heuristic prove the number of design rule violations (DRVs), wirelength and layout pattern. task\n2-pin nets Initial routing: ignores the number of bends and allows design rule violations\nModel\nmulti-agent deep reinforcement learning (MARL) task [15] for asynchronous routing planning between nets. We regard each net as an agent, which needs to consider the actions of other agents while making pathing decisions to avoid routing conflict\nroute and slide the window repeatedly. advantage of box:process every box independently\nsequential routing\nthe repulsion point will be moved from the inner ring to the outer one until the box is successfully routed.\n具体算法：\nsequential routing\nRefinement\n-Detail routing+match+Opt-ISPD-2023-RL+GNN-FinFET # background:\ncutom circuits: a custom detailed router cannot adopt specialized layout strategies for specific circuit classes like human layout experts\n一直在强调match的问题：\ncontribution\nopt roouting, FinFET, sign-off solution 异构图 A rip-up and re-routing scheme can easily adapt to future design constraints three categories of routing methodologies\nTemplate-based methods manual design suffers from scalability issues Simulation-based techniques provide accurate performance feedback and can be generalized to consider various performance metrics (e.g., phase margin, power dissipation) across circuit classes long execution time and resource-hungry computations Constraint-based approaches widely adopted in existing custom routing studies PR Tools # Placement and routing (PnR) is the most time-consuming part of the physical design flow\nPlacer # Chip Placement with Deep Reinforcement Learning-marcro-arXiv-2020-RL # Differentiable-Timing-Driven Global Placement-global placement-DAC-2022-GNN- # Polar 2.0 # An effective routability-driven placer\ncells that are estimated to have high congestion are spread out and inflated to distribute routing demand more evenly.\nNTUPlace3 # DeepPlace # flow\nRePlAce\u0026ndash;TCAD-2018- # DREAMPlace-GP-DAC+TCAD+ICCAD+DATE-2019~2023 # introduction\nOver 30X speedup over the CPU implementation ( RePlAce) is achieved in global placement and legalization on ISPD 2005 contest benchmarks\nDREAMPlace runs on both CPU and GPU. If it is installed on a machine without GPU, only CPU support will be enabled with multi-threading.\nDREAMPlace also integrates a GPU-accelerated detailed placer, ABCDPlace, which can achieve around 16X speedup on million-size benchmarks over the widely-adopted sequential placer NTUPlace3 on CPU.\nPublications\nYibo Lin, Shounak Dhar, Wuxi Li, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement\u0026rdquo;, ACM/IEEE Design Automation Conference (DAC), Las Vegas, NV, Jun 2-6, 2019 ( preprint) ( slides) Yibo Lin, Zixuan Jiang, Jiaqi Gu, Wuxi Li, Shounak Dhar, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;DREAMPlace: Deep Learning Toolkit-Enabled GPU Acceleration for Modern VLSI Placement\u0026rdquo;, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 Yibo Lin, Wuxi Li, Jiaqi Gu, Haoxing Ren, Brucek Khailany and David Z. Pan, \u0026ldquo;ABCDPlace: Accelerated Batch-based Concurrent Detailed Placement on Multi-threaded CPUs and GPUs\u0026rdquo;, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD), 2020 ( preprint) Yibo Lin, David Z. Pan, Haoxing Ren and Brucek Khailany, \u0026ldquo;DREAMPlace 2.0: Open-Source GPU-Accelerated Global and Detailed Placement for Large-Scale VLSI Designs\u0026rdquo;, China Semiconductor Technology International Conference (CSTIC), Shanghai, China, Jun, 2020 ( preprint)(Invited Paper) Jiaqi Gu, Zixuan Jiang, Yibo Lin and David Z. Pan, \u0026ldquo;DREAMPlace 3.0: Multi-Electrostatics Based Robust VLSI Placement with Region Constraints\u0026rdquo;, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), Nov 2-5, 2020 ( preprint) Peiyu Liao, Siting Liu, Zhitang Chen, Wenlong Lv, Yibo Lin and Bei Yu, \u0026ldquo;DREAMPlace 4.0: Timing-driven Global Placement with Momentum-based Net Weighting\u0026rdquo;, IEEE/ACM Proceedings Design, Automation and Test in Eurpoe (DATE), Antwerp, Belgium, Mar 14-23, 2022 ( preprint) Yifan Chen, Zaiwen Wen, Yun Liang, Yibo Lin, \u0026ldquo;Stronger Mixed-Size Placement Backbone Considering Second-Order Information\u0026rdquo;, IEEE/ACM International Conference on Computer-Aided Design (ICCAD), San Francisco, CA, Oct, 2023 ( preprint) Architecture\nflow\nRouter # background # Global routing plays a crucial role in electronic design automation (EDA), serving not only as a means of optimizing routing but also as a tool for estimating routability in earlier stages such as logic synthesis and physical planning.\nOptimal(最优) global routing is a NP-complete problem.\nDRL：\n传统2dGR flow\n3dGR flow\nGR_outdated # FLUTE # FLUTE is an RSMT construction algorithm adopting a look-up table approach, which is both fast and optimal for low-degree nets. However, FLUTE is unaware of routing congestion.\n下面是一系列FLUTE和基于FLUTE的改进\nFastRoute1.0—2006 # roposed a simple way to construct congestion driven Steiner tree and an edge shifting technique to further refine it fastroute 2.0-Monotonic–2007 # monotonic routing to explore all shortest routing paths for two-pin connections. task\nflow\nfastroute 3.0-virtual capacity-ICCAD-2008- # fastroute 4.0-via min tree+3 bending-ASPDAC-2009- # 层分配\n?\nMaizeRouter- # 2nd place of ISPD 2007 contest 2D GR 1st place of ISPD 2007 contest 3D GR BoxRouter 1.0 # 3rd place of ISPD 2007 contest 2D GR 2nd place of ISPD 2007 contest 3D GR integer linear programming (ILP) based FGR-3d-TCAD-2008- # 1st place of ISPD 2007 contest 2D GR 3rd place of ISPD 2007 contest 3D GR -Layer assignment+Via minization-Trans-2008-DP-NTHU # Congestion-Constrained Layer Assignment for Via Minimization in Global Routing CUGR’s rely work ISPD07 contest后的一个跟进工作 也没提到maze routing 没定义wire cost, 在每一对GCell之间layer assignment, 慢？ 第一次用DP? background:\nthere are two main approaches\n3D: route all nets directly on the multilayer solution space. Because this approach directly generates a multilayer global routing result, it can take the via cost into account during construction. However, this method may cost too much CPU time with a large problem size. (现在都用GPU做并行了，这种方法就变多了)\nsuch as\n2D + layer assigment: The other approach is to first compress a multilayer grid graph into a one-layer grid graph, then use a one-layer router to solve the one-layer global routing problem, and finally perform layer assignment to assign each wire in the multilayer grid graph\nThe edges corresponding to vias disappear in the one-layer grid graph. The capacity of each edge in the one-layer grid graph is obtained by accumulating the corresponding edge capacities in the three-layer grid graph\nThis approach can take advantage of many current full-fledged one-layer routers, e.g., [2]–[4], and use an affordable run time to generate an initial one-layer routing result. 本文主要针对layer assignment. 注意layer assignment 是对二维的所有边进行层分配。\nvias not only degrade the reliability and the performance of a design but also increase the manufacturing cost.\nprevious work’s layer assignment use greedy heuristics [8] or time-consuming integer linear programming methods [9] to minimize the via cost.\n像这种串行的还是要考虑net order, 越早布线的net越不会拥塞，net order很重要\ntask and contribution:\n这篇没有考虑优先方向（To simplify the presentation of our algorithm, we do not make any assumption about the preferred routing direction for each layer in the layer assignment problem.）不过也说明了这个工作能够很简单引用到考虑优先方向的情况 follow ISPD07 contest, 假设via的capacity是无限的（CUGR中明确了不进行这种假设） based on a one-layer routing result minimize via cost, WL and congestion overflow propose a polynomial-time algorithm: first generate net order , then solves the layer assignment problem can improve 3 winner of ISPD07 contest model\nCOngestion-constrained Layer Assignment (COLA)’s submodule\nNet order generation\nThe net order has a direct influence on the utilization of routing resources, so it is one of the key parts of COLA.\n对net进行打分决定order\n注意，线长越短，分数越高，net越应该先布线。解释：\nEemove Cycles\nArbitrarily remove.\n（为什么映射到第一层会有cycles？初始是怎么连起来的？没说？FLUTE算法是08年才出来，可能当时还没用上）\nSingle-net layer assignment （SOLA+APEC）\nSOLA(Singlenet Optimal Layer Assignment)\ndetermines an optimal layer assignment result without considering congestion constraints for a given net\ndynamic programming technique\n不考虑拥塞，这个方法能得到最好质量\nstep:\n01: for tree in layer 1, random select a pin as root, then use DFS or DFS to get a queue, so get the edge order. It become a DAG\n02: 定义图5(c)中, a的父节点是p2，定义mvc(v, r)（minimum via cost）\n03:\n​\tfor pins who have not child, mvc:\n​\tfor pins who have child and not root:\n​\t这个公式其实就是为了确定下每个点下一步的layer在哪里。比如算出最小是mvc(v, 1), 那么e_(v, ch(e))就在第r层\n​\tfor root:\nthe difference is excluding r in ∆\nbecause mvc(v, r) does not depend on the value of r when v\nis the root, we have mvc (v, 1) = mvc(v, 2) = · · · = mvc(v, k)\nAPEC(Accurate and Predictable Examination for Congestion constraints)\ncan detect and prevent any congestion constraint violation in advance\nprevention condition:\n如果存在一个在layer1上压缩的边不满足这两个condition，那么这条边的layer assignment（SOLA）结果就不可能满足congesion\nSOLA+APEC always finds a layer assignment result satisfying both prevention conditions for each net\nCOLA\n​\ndata:\nsix-layer benchmarks from ISPD’07\nGRIP-3d+IP-DAC-2009 # 基于整数规划\n3d: solve the 3D problem directly on the 3D routing grids,\nslow: Although theoretically the direct 3D technique should produce better solutions, in practice it is less successful in both solution quality and runtime than 2D routing with layer assignment –cite–\u0026gt; [Fastroute4.1]\nslow: Although we see solutions with shorter wirelength generated by full-3D concurrent approach like GRIP [21], that solution quality is achieved by impractically long runtime –cite–\u0026gt; [Fastroute4.1]\nMGR–ICCAD-2011\nmulti-level （coarsened and fine-gained）\nFastRoute4.1-an efficient and high-quality global router-2012 # https://dl.acm.org/doi/abs/10.1155/2012/608362\nbackground\nFastRoute is a global routing tool for VLSI back-end design. It is based on sequential rip-up and re-route (RRR) and a lot of novel techniques. FastRoute 1.0 first uses FLUTE to construct congestion-driven Steiner trees, which will later undergo the edge shifting process to optimize tree structure to reduce congestion. It then uses pattern routing and maze routing with logistic function based cost function to solve the congestion problem. FastRoute 2.0 proposed monotonic routing and multi-source multi-sink maze routing techniques to enhance the capability to reduce congestion. FastRoute 3.0 introduced the virtual capacity technique to adaptively change the capacity associated with each global edge to divert wire usage from highly congested regions to less congested regions. FastRoute 4.0 proposed via-aware Steiner tree, 3-bend routing and a delicate layer assignment algorithm to effectively reduce via count while maintaining outstanding congestion reduction capability. FastRoute 4.1 simplifies the way the virtual capacities are updated and applies a single set of tuning parameters to all benchmark circuits.\nmodel\nflow\nNTHU Route 1.0- -TVLSI-2010- # NTHU Route 2.0- -TCAD-2013 # 2D\nNCTU GR 1.0-3D-congestion relaxed layer assignment- 2011- # it improved the scheme to estimate the realtime congestion more accurately by using a history term that will gradually wear off as the number of iterations increases if the overflow disappears. NCTU GR 2.0-Multithreaded Collision Aware- CAD-2013- # people.cs.nycu.edu.tw/~whliu/NCTU-GR.htm\nPengjuY/NCTU-GR2: This is a binary file of NCTUgr2, which is a global router\nnet-level parallel method 2D BoxRouter 2.0 # background\ntask\n是一个2d的\n整数规划\nOGRE- new cost function- -2019- - # Open source! LEF/DEF-based 3D 用的是老方法，不过解释的挺清楚的 components by a group of undergraduate students as a course project. GR_Adv # -DRL method-2019-DRL- # task\nDRL(DQN) for global route have not use real world design example:\n​\tfrom A to B\n​\tread means over flow\npipeline\nmodel\nstate:\n(pos_x/y/z, distance_x/y/z, 周围的capacity, )这种编码方案可以被视为当前状态、导航和本地容量信息的混合 action: 上下左右前后\nreward：\ncontribution\nfirst deep learning model for global routing\n-only CNN-DAC-2020-CNN(VAE)- # no experiment! 只用CNN分类结果不会好吧 不知道是什么类型的文章，只用了两页 background\nis approach treats the global routing problem as an image processing problem and solves it with a deep learning system\ndataset\nISPD’98 ibm01 64x64 circuit\nmodel\n-DRL-arxiv-2021-JP # [SPRoute 1.0: A Scalable Parallel Negotiation-based Global Router-ICCAD-2019]( IEEE Xplore Full-Text PDF:) # task\n基于net-level多线程的并行加速迷宫算法\nnegotiation-based rip-up and reroute two-phase maze routing\nresolves livelock issue\nopen source\nintroduced a concept called soft capacity to reserve routing space for detailed routing and explored several parallelization strategies to speed up global routing. background\n总体\nIn many global routers, maze routing is the most time-consuming stage.\nchallenge\n因为这个现象，多线程反而慢了\n原理\nGalois system\nNet-level Parallelism\nFine-grain Parallelism\ndata\nISPD 2008 contest\nSPRoute 2.0- detailed routability driven-ASP DAC-2019- # 特点\n基于多线程的并行加速\n2D\n开源： asyncvlsi/SPRoute: A parallel global router using the Galois framework\nCUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK # ICCAD 2019 Contest First Place\nopen source!\n3d+多线程+\n这个文章没有讨论prefer direction\n多线程体现在哪里？\n注意：这种格式的GR输出可以适配Innovus\ntime-complexity of 3D pattern routing is $\\mathcal{O}(L^4|V|)$\ncompare with [Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU), CUGR reduces the complexity to $\\mathcal{O}(L^4|V|)$ by selecting the root carefully so that each vertex will have at most three preceding vertices instead of four. 注意，这里说 相比[Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU)的$\\mathcal{O}(L^5|V|)$ ，它的复杂度是$\\mathcal{O}(L^4|V|)$ ，感觉是放在了[Trans-2008](# -Layer assignment+Via minization-Trans-2008-DP-NTHU)进行不转弯的DP-based layer assignment方法上了，实际上按照本文说的方法，理论上是$L * L^{23}|V|$，因为CUGR每次是对一个L pattern为单位计算mvc,时间复杂度是$2L*L$.确实是$L^4$, CUGR对一个L pattern分了两部分计算mvc没一部分时间复杂度是$L*2$\nbackground\nA common strategy of doing 3D global routing, as adopted by NCTU-GR 2.0 [5], NTHU-Route 2.0 [6], NTUgr [7] and FastRoute 4.0 [8], is to first compress the 3D grid graph into a 2D grid graph and perform 2D global routing. directly route the nets in a 3D grid graph：FGR [10] , GRIP [11] , MGR [12] Traditional pattern routing generates 2D topologies only, while our proposed 3D pattern routing directly generates 3D topologies without the need of an extra layer assignment stage 使用DR结果进行多角度metrics 评估： task\ndetailed-routability-driven directly-3d multi thread GR contibution\nprobability-based cost scheme minimizing the possibility of overflow after detailed routing 3D pattern routing technique (2D pattern routing + layer assignment)(前面又说directly in the 3D space?) without overflow even only L shape patten routing pre-work[15] 是先在2d上进行pattern routing, 然后进行layer assignment, 这里是直接在3d进行pattern routing. 3d pattern routing can avoid loss of accuracy caused by compressing 3D grid graph to 2D multi-level maze routing: coarsened level –\u0026gt; searches for a region with the best routability. first narrows the search space to a smaller region fine-grained level –\u0026gt; searches for a lowest cost solution within the region patching mechanism further improve the detailed routability flow\nIn 3D pattern routing (inital routing), the nets are broken down into two-pin nets, and a dynamic programming based algorithm will route the two pin nets sequentially using Lshape patterns and stacking vias at the turns.\nIn the multi-level 3D maze routing phase, the grid graph is coarsened to shrink the routing space, and maze routing is first performed in the coarsened space with an objective to find a routing region with the highest routability. A fine-grained maze routing will then search for a lowest cost path within the region. use its patching mechanism here.\nmodel\nGcell之间的容量等于track，一般GR表征via的容量是无限的，但是在本文中不是\nthree base definition:\nresource = capacity - demand 这三个变量在GCell和wire_edge上都有特征，也就是说有6个值 resource 能够直接表示拥程度 cost scheme\n主要分成wire和via两部分：\nwire cost:\n*wl*is wire lenght cost\neo is expected overflow cost, where uoc is hyper parameter, The larger d(u, v) is, the more likely it is to be congested. is accurate if the DR adopts the simplest strategy of picking a track randomly to route. However, most well designed detailed routers will do much better than random selection.\nlg(u,v) is a variable to refine d(u, v). “+1” 是为了值域在（0，1）表示概率。 slope is hyper parameter. When the resources are abundant, there is almost no congestion cost, but the cost will increase rapidly as the resources are being used up and will keep increasing almost linearly after all the resources are used\nvia cost:\nthanks to our 3D pattern routing strategy, a via cost scheme can be embedded to reflect the impact. uvc is hyper parameter. 公式（5a）为什么要“+1” Initial Routing / 3D Pattern Routing\nuse FLUTE first (not congestion awared)\nuse edge shifting (described in FastRoute) to alleviate congestion.\nrandomly choose one node in net, use DFS to get a queue and then get a DAG\n类似[15]，动态规划选择cost最小的3d L pattern，每个L pattern有(2 * L * L)种可能\n最后在root处得到最终的结果\nMulti-level 3D Maze Routing\nmaze route planing\naims at finding a smaller but highly routable search space\ncompress a block of G-cells (5x5 in our implementation), use avg to descripe capacity, demand, resource\ncost function:\n得到灰色粗网格：\n之后会在这几个BBox中分别进行计算cost scheme，得到上图黑色实线\nfine-grained maze routing within guides\nPostprocessing / Guide Patching\nwe can add new guides to improve detailed routability. adding new stand-alone guides to alleviate routing hot spots.\nthree kind of patching:\nPin Region Patching\nmost effective\nthe ideal way of improving pin accessibility is to identify those hard-to-access pins and assign more resources to them\nOur global router will check the upper (or lower) two layers of a pin, which are vital for accessing the pin. use 3 × 3 patching guides.\n没写判断hard-to-access pins 的具体的方法\nLong Segment Patching:\na longer routing segment often means more wrong way wires and causing more congestion. If a guide is longer than a specified length I, we’ll consider long segment patching. if a G-cell with resource below a threshold T is encountered, a single G-cell route guide will be patched above or below it, depending on which of them has sufficient resource Violation Patching:\nFor G-cell with inevitable violations, patching will be used again to enable the detailed router to search with more flexibility.\ndata\niccad 2019 dataset\nexperiment\n他自己又比赛后改进了\nour algorithm’s peak memory is close to the first place and is 1.83 times of that of the second place on average (ours is 8.22 GB on average and is 19.8 GB for\nthe biggest design)\nFastGR-GPU pattern routing+ multi thread maze–DATE-2022-PKU+CUHK+HNAL # GPU-accelerated accelerated the 3D pattern routing algorithm of [CUGR](# CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK) for initial routing by both net-level and path-level parallelization on GPU Gamer- -Trans-2022- - # GPU-accelerated accelerated the two-level maze routing of [CUGR](# CUGR-3D pattern+Multi level maze routing+patching-DAC-2020-CUHK) for rip-up and reroute by updating vertical and horizontal routing costs alternatively on GPU GGR-super fast gpu accelerate-ICCAD-2022- # open source！ Xplace/cpp_to_py/gpugr at main · cuhk-eda/Xplace\nbackground\nPerformance depends on the detail route\nModern global routing problem, which was introduced at the 2019 CAD contest at ICCAD, targets at closing the gap between global routing and detailed routing. The LEF/DEF files for detailed routing are directly used as the input for global routing.\nThe global routing quality is evaluated using an academic detailed router Dr. CU[8]\n2019 ICCAD contest on global routing did not directly evaluate global routing results based on overflows and total wirelength. The new evaluation uses the global routing results as route guides for a detailed router, and the metrics are all detailed routing related\n2D \u0026amp; 3D\nNCTU-GR 2.0[13], SPRoute[7] and FastRoute 4.0[14] are 2D GR\nHowever, compressed 2D grid graphs are less accurate than 3D grid graphs in terms of routing resources, which could limit the global routing quality.\nCUGR[11]. It has both 3D pattern routing and 3D maze routing\nmulti-thread vs GPU\nLEF/DEF based academic global routers SPRoute 2.0[6] is the only 2D GR\nGAMER[10] is a novel parallel maze routing algorithm integrated in CUGR.\nFastGR[12] introduced GPU parallelization of L-shape pattern routing\ncontribution\nflow\ndata\nmodel\nCUGR 2.0-DAG-based-DAC-2023- -CUHK # open source! background\nmany of the aforementioned global routers is that most of them rely heavily on time-consuming path search algorithms like maze routing to resolve overflows. These approaches are not efficient enough even with parallilization and may cause lots of unnecessary detours contribution:\na DAG-based generalized pattern routing algorithm\na new dynamic programming-based algorithm to calculate the routing cost\ntime complexity from $\\mathcal{O}(L^4|V|)$ to $\\mathcal{O}(L^2|V|)$\na DAG augmentation algorithm that enables the creation of alternative paths in a routing DAG. can even shift or create Steiner points. over 99% nets can be successfully routed without the need of maze routing\na new sparse graph maze routing algorithm\ncreation of alternative paths in a\nrouting DAG\nflow\nRSMT\nDFS and Routing DAG with L pattern\n注意多了节点g,f,i,h, 现在每条都是直线\nRouting DAG with other patterns，但是在这里没用做初始布线，初始只用了L-shape。文章也就这里提了一下，后面都和这个无关，得去源码仔细看看。\nDynamic Programming-based DAG routing(L-shape + Layer assignment)\n没说怎么舍弃的？\nDAG-based pattern routing with augmentation\nsparse graph maze routing algorithm\nmodel\ncost\nDynamic Programming-based\nDAG Augmentation for Congestion\ncreate alternative paths\nSteiner point movement\n具体怎么移动的文章也没说\nexperiment:\ncompare with CUGR [12] and SPRoute 2.0 [13]\nonly one thread for run time\nEffectiveness of steiner point augmentation\nrun time compare with GPU-accelerated GR\ncompare with FastGR [14] and GAMER [15]\nGPU的好坏也有关系吧。本实验用的RTX 3090\nslightly faster than FastGR for initial routing\naround 5.2× as fast as GAMER\nInstantGR-Scalable GPU Parallelization-ICCAD-2024-CUHK # open source! second place of ISPD25 contest GPU Parallelization parallel algorithm is mainly based on the DAG-based global routing algorithm in [CUGR2](# CUGR2.0 EDGE- -DAC-2023-). 应该是3D pattern routing DP的部分和maze routing的部分 parallel while do initial routing and RRR 提高了并行度，但是还是有串行的部分 也用了FLUTE 一定要以net为单元吗？是为了用DP background\nGPU memory is limited This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored nets in a batch can be routed in parallel task:\nparallelism for large-scale partitioned design contribution\na new method for net-level batch generation. based on 3D fine-grained overlap checking and explores more parallelism by increasing the number of nets per batch node-level parallel routing approach. achieves much higher parallelism compared to traditional net-level parallel routing. flow\nIn initial routing, we construct a basic routing DAG to perform L-shape pattern routing. key points\nspecific explanation show in routing2\nNET-LEVEL PARALLELISM\nsimultaneous routing of a batch of nets that do not “overlap”\n[2, 3, 14, 19, 20, 22, 26] 19年开始的，cugr2和fastgr都用了\nTypical Batch Generation Algorithm\nused in [2, 3, 14, 19, 20]\nR-trees 是实现line 4的常用做法\npessimistically approximates significantly lowers the degree of parallelism\ndefine and graph model\n以segment为单位，同时分开了水平和垂直两个部分，假设全部为L-shape，同时对于不在一条线上的两个节点，有两个L\nThese four nets will be divided into just one batch based on our exact representation of routing graphs for overlap checking, while into four batches by the traditional bounding box-based pessimistic approximation\nvia model:\nvia用一个十字表示\nOverlap Checking Algorithms\n以水平子图进行展示，垂直同理\n以水平segment为单位进行checking\n首先判断是不是y坐标相等：group the segments with the same 𝑦\ntradictional algorithm:\nThis is a classical computational geometry problem that can be efficiently solved by segment trees [1] in 𝑂(log𝑛) time for both operations,\nnew algorithm motivation:\nsegments are very short\nnew algorithm: Point Exhaustion\nsimply use a Boolean array to record whether each point in [1, 𝑛] is covered by some segment 𝑠 ∈ 𝑆. We mark every point 𝑥 ∈ [𝑙, 𝑟] when a segment [𝑙, 𝑟] is inserted, and check every point 𝑥 ∈ [𝑙𝑞, 𝑟𝑞] for overlap query of a segment [𝑙𝑞, 𝑟𝑞].\nfurther improve the efficiency of this point exhaustion by using bit arrays\nanother improvement: representative point exhaustion allowing a little bit of overlap. it only checks the two end points of a query segment. ??什么意思 covering most overlap scenarios in practice. The only scenario that this algorithm fails to find the overlap of two overlapping segments is when the query segment [𝑙𝑞,𝑟𝑞] contains the overlapping segment [𝑙,𝑟], [𝑙,𝑟] ⊂ [𝑙𝑞,𝑟𝑞] NODE-LEVEL PARALLELISM\n还是以net为单位分到不同的batch？\nrouting nodes of the same depth in parallel\nSuppose we have 4 nets, Net A, B, C and D in our grid graph. Since nets with overlap cannot be routed together, Net A and B are distributed to batch 0, as shown in Figure 7a, and nets C and D are distributed to batch 1.\nexperiment:\n4 NVIDIA A800 GPUs and 8 CPU threads.\ncompare different overlap checking methods\nThe number of nets per batch is limited to 1000\ncompare 2 largest benchmark\ncompare with Top-3 Global Routers of ISPD2024 Contest\nRuntime (s) of DAG-Based Augmented Routing with and without Node-Level Parallelism\nacceleration 那一行好像是加速倍率才对\nHeLEM-GR-Heterogeneous+Linearized Exponential Multiplier Method-ICCAD-2024- -PEK # first place of ISPD25 contest not open source 2025/2/6 2D routing algorithm background\nPRNet- -NeurIPS-2022- -SJTU+Noah’s Ark # PRNet can generate each route in one-shot but cannot guarantee connectivity which requires considerable post-processing for failed routes HubRouter 是两阶段框架，PRNet 是端到端框架。 HubRouter-generative model-NeurIPS-2023-GAN+RL-SJTU # open source! a chinese interpretation a global routing solver that includes a two-phase learning framework HubRouter 是两阶段框架，PRNet 是端到端框架。 对比 PRNet 生成模型，PRNet 在 CGAN 中使用双向映射将连接约束注入训练目标，将准确率提高了 10%，但在复杂情况下几乎无效。 background\n全局布线(Global Routing - GR)是 VLSI 设计中最复杂且最耗时的组合问题之一。GR 目标是总线长最小，同时避免拥塞(Congestion)，是个 NP 问题。\n传统采用启发式算法，多样性和规模问题对传统算法有了挑战，机器学习(ML)已经用于全局布线，在芯片设计中从逻辑合成到布局\n深度强化学习(Deep Reinforcement Learning - DRL )和生成式模型(Generative model)已经被用来解决全局布线。问题在于，DRL很受状态空间(State Space)影响，随着网格空间增大，需要花费大量时间生成。However, DRL methods suffer from large state space and often need to spend enormous time on generating routes as the scale of grids increases on the test instance, i.e., the netlist, which is practically intimidating for real-world global routing\n相反，生成式模型有一次性生成能力，在计算上更容易处理。\n生成式方法在训练时候考虑连通性限制，确保布线满足电路连通性要求。但是问题在于，如果初始生成路径不满足连通性要求时候，后处理阶段会变成一种穷举搜索过程。\n图一这里上图表示原始布线，下图表示算法生成的布线，生成布线没有正确连接所有应该连接的点(pin)，对于这样的情况，平均连通率很低，低于20%，意味着超过80%的生成布线需要经过耗时的后处理才能达到要求。显著的缺点。其实就和[CNN-based](# -only CNN-DAC-2020-CNN(VAE)-)这篇一样\ncontribution:\n为了解决上述问题，定义了一个新的概念，叫hub。将pin - pin问题 \u0026ndash;\u0026gt; hub - pin问题 。\n提出了一种新的两阶段全局布线方法 \u0026ndash;\u0026gt; HubRouter\ngeneration phase（生成阶段）\nhubs, routes, and stripe masks are together generated under a multi-task framework by generative models\n可以在多个框架下生成，比如 GAN (Generative Adversarial Nets) , VAE (Variational Auto-Encoder) , DPM (Diffusion Probabilistic Models) 。虽然hub是生成阶段的主要输出，但为了提升生成质量和准确性，发现生成附加信息是非常有用的。比如感知和掩码(local perception and stripe masks)，能够去除噪声点。引入多任务学习，布线和掩码一起生成，提高 hub 生成质量\npin-hub-connection phase（hub和pin连接阶段）\n将连接视为最小斯坦纳树(RSMT)问题，使用 actor-critic 模型网络策略。\nis hub generate correcttly, reconstruction time complexity can be reduced to O(n log n)\nSOTA generative global routing models\nmodel:\nHub\n(virtual) key point in the route transferring the pin-pin connection problem to the hub-pin connection problem 斯坦纳点(Rectilinear Steiner Point \u0026ndash;\u0026gt; RSP)是搜索全局最小总距离，但是 hub 是来确定路径。RSPs are special cases of hubs RSP是Hub的特例，Hub可以随意生成不同形状的路径(不仅是最短的) 这里的 c 和 x 分别代表条件图像和输入图像。条件图像可能包括引脚位置、已经提取的中心点以及条带掩模（stripe mask）。条带掩模是用来指示布线区域的一种方式，它可以帮助模型更好地理解哪些区域可以用于布线 flow\nhub生成阶段\nHub 生成可以表示为图像到图像的multi-task learning framework 任务, address the impact of sensitive noise points with stripe mask learning\n附录 B 介绍了将 GAN，VAE，EAN 纳入到生成框架\n在这个阶段，模型旨在逼近条件分布 pθ(x|z, c) 使其接近先验分布 p(x|c)。给定条件 c 和从先验分布 pz(z) 中采样得到的潜在变量 z（通常假设为高斯分布），模型会生成一些“中心点（hubs）”. 这里的 c 和 x 分别代表条件图像和输入图像。z is a latent variable from a prior distribution\nThe main objective of hub generation is to minimize the difference between probability distributions p(x|c) and pθ(x|z, c)\na noise hub, especially the outermost one, can largely harm the wirelength of routing. Use stripe mask to focus on bad cases for hub generation\nhub和pin连接阶段\n模型连接第一阶段生成的中心点，以获得最终的布线路由。这个过程可以被视为构建矩形稳定最小生成树（Rectilinear Steiner Minimum Tree，RSMT）的一部分。为了完成布线，模型遵循了一个基于强化学习（Reinforcement Learning，RL）的算法 REST。 在两阶段的过程中，作者还提出了一个多任务学习框架来提高生成中心点的质量。特别是，提出了一种新颖的条带掩模学习方法，旨在减轻噪声点案例可能造成的负面影响。算法的具体细节在附录 B 中给出。 detail router # DRCU\nacademic detailed\n综述 # ML4PR # Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview\n放置和布线是两个不可或缺且具有挑战性的 NP-hard 问题\n机器学习凭借其数据驱动的性质显示出了广阔的前景，它可以减少对知识和先验的依赖，并且通过其先进的计算范式具有更大的可扩展性 (例如 GPU 加速的深度网络)\n挑战:\nplacement:\n在路由完成之前，无法评估诸如可达性之类的放置目标；因此，在优化循环中可能需要花费数小时才能获得反馈，这对于进行数千次查询来说是负担不起的 现代的放置器需要在几个小时内处理数万个宏和数百万个标准单元。这种可扩展性的要求仍然超出了现有 ML 方法的能力 routing:\n在公平的比较下，现有技术很难在效率和求解质量上系统地优于经典布线算法 大多数基于学习的技术在具有数千个网络的小型电路上工作得很好，而实际的布线引擎需要在超大型 3D 网格图 ( \u0026gt; 1000 × 1000 × 10 ) (\u0026gt; 1000 × 1000 × 10)(\u0026gt;1000×1000×10) 上有效地处理数百万个网络并产生高质量的解决方案 相关工作\nplacement\nRouting\n超大规模集成电路布线算法综述 # 超大规模集成电路布线算法综述\nbackground\n布线相关详细看routing2.md, 详细布线、面向可制造性设计的布线算法 还没记录\nEDA+GNN # 详细看 A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks\n参考 # [AI技术带给EDA的机遇和挑战](AI技术带给EDA的机遇和挑战-Yibo Lin.pdf) [Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview]([ 读论文] Towards Machine Learning for Placement and Routing in Chip Design: a Methodological Overview_toward machine learning\u0026hellip;.lake-CSDN博客) 【阅读】A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN综述翻译_ppaml-CSDN博客 bak # CongestionNet-Congestion Prediction-IFIP-2019-GNN\n-placement Congestion prediction-arXiv-2021-GNN\n输入：网表\n输出：congestion at placement stage\nEDA-ML: Graph Representation LearningFramework for Digital IC Design Automation\n德雷塞尔大学电气与计算机工程系 Pratik Shrestha和Ioannis Savidis\nbackground\nVLSI : traditional methodologies -\u0026gt; ML,Graph representation learning ability to capture complex relationships in graph-structured data\nGNN：\ntask\nflow\ndata\n模型\n实验\n相关数据集 # only rtl # Home :: OpenCores # IWLS 2005 Benchmarks # openlane-examples: Examples from the Openlane repository # Global route # ISPD-2007 # the first published multilayer global routing benchmarks and the sizes of these benchmarks are large enough as compared to real industry cases has a two-layer and a six-layer version. ISPD-2008 # ICCAD-2019 # 2019 CAD Contest @ ICCAD\nISPD-2024 # Dockerfile无法创建镜像了，401，Github也找不到benchmarks\nISPD-2025 # Detail Route # ISPD-2018/2019 # Initial Detailed Routing Contest at ISPD 2018\nInitial Detailed Routing Contest at ISPD 2019\n一个别人写的parse脚本：Handling-the-ISPD19-benchmark-dataset\nhttps://ispd.cc/contests/19/ispd19eval.tgz：一个结果验证工具\n还可以看看被人的结果\ncongestion/DRC/IR drop/timing # circuitnet/CircuitNet: CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA)\n背景：\nf.daixianiu.cn/csdn/14209355328255857.html在研究过程中，我们发现AI+EDA的研究常常受限于公开数据集，不像计算机视觉领域有ImageNet这样的大数据集可以很方便地验证算法。针对这一问题，我们近期跟黄如院士、王润声教授等合作，发布了首个致力于芯片设计AI for EDA应用的开源数据集——CircuitNet，包含1万以上的数据样本，涵盖从实际制造工艺PDK下数字设计流程不同阶段中提取到的各类特征。 TimingPredict/TimingPredict: Official open source repository for \u0026ldquo;A Timing Engine Inspired Graph Neural Network Model for Pre-Routing Slack Prediction\u0026rdquo; (DAC 2022)\n相关会议/期刊 # 会议 # DAC:\n每年举办一次学术论坛和工业贸易展览 一般11月截止 ICCAD：\nInternational Conference on Computer-Aided Design 由电气电子工程师学会（IEEE）和美国计算机学会（ACM）共同举办的国际计算机辅助设计会议（ICCAD）被公认为EDA领域最重要的会议之一，享有很高的国际学术地位和广泛的影响力。该会议是探索EDA研究领域新挑战、展示前沿创新解决方案和识别新兴技术的重要论坛，涵盖了从器件和电路级到系统级的所有设计与自动化主题、以及后CMOS设计等新型方向。着重于学术研究，论文涉及专门的算法的研究进展。 一般4月截止 DATE 2025\nDesign, Automation and Test in Europe Conference 欧洲设计自动化和测试会议 一般9月截止 ASP-DAC\n亚洲、南太平洋设计自动化会议 一般7月截止 ISPD：\nInternational Symposium on Physical Design\n国际物理设计会议。是专注集成电路物理设计的国际研讨会，主题涵盖从ASIC和FPGA的传统物理设计到新兴半导体技术的物理设计自动化方法。\nCCF-C. 9月份左右\n每年ISPD会议同步举办国际物理设计竞赛，通常由国际知名芯片企业命题和组织，竞赛历时3个多月，结果在ISPD会议上揭晓。\nGLSVLSI\nCCF-C 大湖区超大规模集成电路设计国际会议 一般2月截止 25年为第35届 VLSI:\n有个DTCO? 一般1月 ISEDA:\n由IEEE和ACM主办，EDA²和CIE EDA委员会联合主办的ISEDA （EDA国际研讨会）是一个致力于VLSI设计自动化的年度顶级论坛。研讨会旨在探索新的挑战，展示前沿技术，并为EDA社区提供预测EDA研究领域未来发展方向的机会。ISEDA涵盖了从器件和电路级到系统级的所有EDA主题，从模拟到数字设计以及制造。会议的形式旨在培养富有成效和新颖 二月 25年第三届 NeurIPS ICML 期刊 # TCAD\n由美国电器电子工程师学会（IEEE）出版(就是Trans?) TODAES\n由美国计算机学会（ACM）出版的电子系统设计自动化汇刊 It publishes innovative work documenting significant research and development advances on the specification, design, analysis, simulation, testing, and evaluation of electronic systems, emphasizing a computer science/engineering orientation. Design automation for machine learning/AI and machine learning/AI for design automation are very much welcomed. For topics of interest please see https://dl.acm.org/journal/todaes/about. 参考 # (99+ 封私信 / 81 条消息) 集成电路设计的学术会议含金量排名如何？ - 知乎 相关科研实验室 # 清华 # 清华大学是国内较早从事EDA研究的高校，洪先龙教授和边计年教授做物理实现和逻辑综合，两位老先生的学生大部分去了三大EDA公司\n北大-无锡EDA研究院 # 无锡北京大学电子设计自动化研究院\n北京大学无锡电子设计自动化研究院-开源工具整合\n北京大学集成电路学院成立了国内唯一聚焦EDA技术的“设计自动化与计算系统系”，打造先进的教学与人才培养体系，并与国内外领先的企业深入合作，部分成果已经成功得到转化应用，相关技术是业内目前唯一的解决方案；近期依托院系新成立了无锡北京大学EDA研究院，加上此前与EDA及设计方向头部企业共建的多个联合实验室，形成了教育、科技和人才三位一体的布局。\n研究方向包括布局布线、FPGA设计自动化的可重构算法\n林亦波 Yibo Lin:yibolin@pku.edu.cn\nContest@ISPD 2024第一名指导的本科生赵春源提出的高效GPU异构并行布线算法\nCADathlon@ICCAD 2024第一名指导郭资政（毕设开源项目作者）、麦景。在9小时内，运用自己的编码和分析技巧来解决6道集成电路与系统中电子设计自动化问题\nCAD Contest@ICCAD第一名指导杜宇凡、郭资政。C赛题《Scalable Logic Gate Sizing Using ML Techniques and GPU Acceleration》\nDreamPlace, Limbo开源项目作者\n相关采访 北大林亦波：探索AI+EDA新路径 | 青源专栏 2022-09\n一个现象：\n复旦 # 集成芯片与系统国家重点实验室\n研究方向包括物理实现、参数提取、逻辑综合、可制造性设计等方向\n陈建利教授\n指导蔡志杰、魏民、邹鹏，ISPD 2024 contest 第三名 北航 # 港中文-EDA Center # CUHK EDA Center官网\nCUHK EDA Github\nBei Yu(余备)@CUHK-CSE\nbyu@cse.cuhk.edu.hk\nResearch Topics\nCAD Contest@ICCAD 2012第二名获得者\nSiting Liu(刘思婷)@CUHK-CSE\nlusicaliu@outlook.com\nF.Y. Young\nJinwei Liu 陈廷欢CHEN, Tinghuan\n方向：VLSI CAD and deep learning accelerators for edge devices chentinghuan@cuhk.edu.cn CHEN, Tinghuan # 福大 # 福州大学早期EDA研究始于范更华教授和朱文兴教授，当前的研究方向主要是物理实现。福州大学团队曾连续三年在CAD Contest@ICCAD夺冠。\n福州大学团队在CAD Contest@ICCAD大赛中提出的6T\u0026amp;6T PPNN单元布局方法已转让给华大九天\n林智锋教授\n指导陈忆鹭、吴昭怡， ISPD 2024 contest 第三名 上海交大 # 首页_上海人工智能实验室\n东南大学-国家ASIC工程中心 # 研究方向是亚阈值和近阈值相关的时序分析\nCAD Contest@ICCAD 2017第一名获奖者福州大学的朱自然（Ziran Zhu）毕业后任教于东南大学ASIC中心\n2020年和国微集团成立EDA联合实验室，瞄准EDA共性技术研发\n时龙兴:\n老所长 闫浩:\nyanhao@seu.edu.cn 领域：智能EDA，面向先进工艺、高能效电路设计中存在的问题，应用人工智能算法辅助电路设计；先进制程/低电压下的时序分析与优化 华中科技大学 # 西安电子科技大学 # 在国内较早开始从事成品率分析算法的研究，并且一直在宽禁带半导体的器件建模、可靠性分析等领域有深入的研究和突出的成果\n在2019年和囯微集团建立EDA研究院之后，开始进入布局布线和原型验证领域\n广东工业大学 # 电子设计自动化（EDA）科研团队-广东工业大学集成电路学院\n电子设计自动化（EDA）科研团队依托广东工业大学集成电路学院成立。面向人工智能辅助集成电路设计EDA工具开发、应用等国家重大战略与行业重大需求，以人工智能辅助EDA为研究核心，聚焦于数字集成电路设计后端工具、FPGA设计工具优化等领域的前沿基础理论和关键技术研究。团队主要开展“数据驱动机器学习的集成电路智能设计”、“人工智能方法实现集成电路的敏捷设计”、“基于传统的分析和优化技术的集成电路辅助设计”等研究\n数据驱动机器学习的集成电路智能设计 人工智能方法实现集成电路的敏捷设计 基于传统的分析和优化技术的集成电路辅助设计 国立清华大学 # University of California # Design Automation Laboratory\n相关企业/机构 # 华为诺亚方舟 \u0026amp; 海思 # Huawei Noah’s Ark Lab AI4EDA\nCAD Contest@ICCAD 2018第一名获奖者香港中文大学的陈劲松（Jingsong Chen，2021年博士毕业）毕业后加入华为\nEDA国创中心 # 与东南大学 有关联\n中心介绍—国家集成电路设计自动化技术创新中心，EDA国创中心【官方网站】\n芯行纪 # AmazeSys # 应用于数字芯片物理设计领域的布局布线工具\n包含宏单元布局规划、电源规划、布局、时钟树综合、布线、优化、寄生参数提取以及时序功耗分析等全功能模块，支持先进工艺制程下的超大规模设计，可完成数字芯片从Netlist到GDS的完整设计流程，快速达成性能、功耗、面积优化等设计目标\n基于强大的机器学习引擎内核，AmazeSys具备自适应超高质量优化能力。该引擎智能提取设计本身特点进行样本训练，综合性能、功耗、面积和布线拥塞等多项关键指标，快速获取量身定制的最佳优化方案，可有效帮助用户降低调整大量工具设置的时间成本。\nAmazeFP # 智能布局规划工具AmazeFP将机器学习技术与布局规划引警结合，在兼顾性能、功耗和面积(PPA)的同时，提供了高度智能的拥塞感知、便捷的数据流分析和宏单元自动整理对齐功能，有效解决当前数字芯片在后端设计阶段的布局规划节点面临的经验值需求高、手工耗时长、数据流结构分析不够深入、设计目标收敛性差等难题，助力用户在后端设计初期快速有效地获取高质量布局规划方案，减少迭代次数，从而节约大规模设计的研发成本，提速产品上市时间。\nAmazeFP-ME # 作为一款EDA机器学习的工具，AmazeFP-ME在AmazeFP的基础上，能够快速探索数百倍甚至更多的庞大解空间，无需用户手动调参，同时配备优异且精准的数据、图形分析功能，可为用户提供高效便捷的设计体验\nAmazeFP-ME作为AmazeFP的AI配套工具，将机器学习技术引入到AmazeFP的解空间探索中，不仅进一步显著地提升了PPA，还为用户创造全新的自动化使用体验。\nAmazeDRCLite # 云 # 华大九天 # 东南大学-华大九天-NiiCEDA联合实验室\nPyAether # Aether就是全定制电路（例如模拟、存储、射频、平板等）设计平台，包括原理图，版图，仿真环境，以及数据版本管理工具和Python接口等。\nPython拥有众多针对****数据科学和人工智能的强大的开源库，例如NumPy和Pandas用于数据处理，Matplotlib用于数据可视化，Scikit-Learn提供了大量的预处理方法和机器学习算法，TensorFlow和PyTorch则是深度学习领域的重要工具。这些库大大降低了开发难度，使得Python在AI领域的地位无可替代。所以无论是数据清洗和预处理，还是模型建立，例如决策树，神经网络，贝叶斯优化等，以及模型训练和测试，对模型结果的解读等，都会天然的使用Python。\n所以Python的开放性生态、天然的数据挖掘、包括机器学习的人工智能（AI）以及各类算法优化包，友好的web开发，使用户可以在更开放、更强大的生态体系里开展设计。可以用它来构建电路与版图的自动化任务，快速进行数据处理和分析。例如，PyAether可以赋能IC CAD，更好得响应IC 设计和版图各种要求。\n10月18日深度解析 PyAether EDA 生态系统，带您探索电路设计自动化的秘籍！ - 华大九天PyAether - EETOP 创芯网论坛 (原名：电子顶级开发网) - import pyAether class InvLe: def __init__(self, lib, cell, tech_lib, view=\u0026#34;layout\u0026#34;, mode=\u0026#34;a\u0026#34;): r\u0026#34;\u0026#34;\u0026#34;InvLe init function, receive the specified layout information. Parameters ---------- lib : str Library name. cell : str Cell name. tech_lib : str Attach tech library name. view : str View name, the default value is \u0026#39;layout\u0026#39;. mode : str Mode for open design, the default value is \u0026#39;a\u0026#39;. \u0026#34;\u0026#34;\u0026#34; pyAether.emyInitDb() pyAether.emyInitLog() self.pnt_x = 0 self.pnt_y = 0 self.namespace = pyAether.emyUnixNS() self.design = self.open_design(lib, cell, view, mode=mode) self.block = self.design.getTopBlock() if self.block is None: self.block = pyAether.emyBlock.create(self.design) self.uu2dbu = self.block.getDBUPerUU() oplib = self.design.getLib() tech_scl = pyAether.emyScalarName(self.namespace, tech_lib) tech = pyAether.emyTech.open(tech_scl) tech.attach(oplib, tech_scl) def open_design(self, lib, cell, view, view_type=\u0026#34;maskLayout\u0026#34;, mode=\u0026#34;r\u0026#34;): r\u0026#34;\u0026#34;\u0026#34;This function is used to open design and return an emyDesign object. Parameters ---------- lib : str Library name. cell : str Cell name. view : str View name. view_type : str Type of view, the default value is \u0026#39;layout\u0026#39;. mode : str Mode for open design, the default value is \u0026#39;r\u0026#39;. Returns ------- design : emyDesign An emyDesign object opened by given parameters. \u0026#34;\u0026#34;\u0026#34; lib_scl = pyAether.emyScalarName(self.namespace, lib) cell_scl = pyAether.emyScalarName(self.namespace, cell) view_scl = pyAether.emyScalarName(self.namespace, view) reserved_view = pyAether.emyReservedViewType(view_type) view_type = pyAether.emyViewType.get(reserved_view) design = pyAether.emyDesign.open(lib_scl, cell_scl, view_scl, view_type, mode) return design def create_inst(self, master_lib, master_cell, master_view, inst_name, point, params, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarInst object on specified block. Parameters ---------- master_lib : str Library name of instance. master_cell : str Cell name of instance. master_view : str View name of instance. inst_name : str Text string of instance. point : tuple Point to create an emyTransform object, such as (0, 0). params: emyParamArray emyParamArray kwargs Other keyword arguments, here specifies view_type, mode, view, status. \u0026#34;\u0026#34;\u0026#34; view_type = kwargs.get(\u0026#34;view_type\u0026#34;, \u0026#34;maskLayout\u0026#34;) mode = kwargs.get(\u0026#34;mode\u0026#34;, \u0026#34;r\u0026#34;) view = kwargs.get(\u0026#34;view\u0026#34;, pyAether.emcInheritFromTopBlock) status = kwargs.get(\u0026#34;status\u0026#34;, pyAether.emcNonePlacementStatus) master = self.open_design(master_lib, master_cell, master_view, view_type, mode) inst_scl_name = pyAether.emyScalarName(self.namespace, inst_name) pnt_x0, pnt_y0 = point point_1 = pyAether.emyPoint(int(pnt_x0 * self.uu2dbu), int(pnt_y0 * self.uu2dbu)) trans = pyAether.emyTransform(point_1) pyAether.emyScalarInst.create(self.block, master, inst_scl_name, trans, params, view, status) def create_net(self, net_name, path, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- net_name : str It specifies the net name string. path : list It specifies path list. kwargs Other keyword arguments, here specifies sigType, isGlobal, view. Returns ------- scl_net : emyScalarNet An emyScalarNet object created by given parameters. \u0026#34;\u0026#34;\u0026#34; sig_type = kwargs.get(\u0026#34;sigType\u0026#34;, pyAether.emySigType(pyAether.emcSignalSigType)) is_global = kwargs.get(\u0026#34;isGlobal\u0026#34;, False) view = kwargs.get( \u0026#34;view\u0026#34;, pyAether.emyBlockDomainVisibility(pyAether.emcInheritFromTopBlock)) net = pyAether.emyScalarName(self.namespace, net_name) scl_net = pyAether.emyScalarNet.create(self.block, net, sig_type, is_global, view) path.addToNet(scl_net) return scl_net def create_path(self, layer, purpose, width, start_point, end_point): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- layer : str It specifies the layer name string. purpose : str It specifies the purpose name string. width : float Define the width of the path. start_point : tuple Path start point, such as (0, 0). end_point : tuple Path end point, such as (1, 1). Returns ------- path : emyPath A path object created by given parameters. \u0026#34;\u0026#34;\u0026#34; (sta_x0, sta_y0), (end_x0, end_y0) = start_point, end_point sta_pnt = pyAether.emyPoint( int(self.pnt_x * self.uu2dbu) + int(sta_x0 * self.uu2dbu), int(self.pnt_y * self.uu2dbu) + int(sta_y0 * self.uu2dbu)) end_pnt = pyAether.emyPoint( int(self.pnt_x * self.uu2dbu) + int(end_x0 * self.uu2dbu), int(self.pnt_y * self.uu2dbu) + int(end_y0 * self.uu2dbu)) points = [sta_pnt, end_pnt] layernum = pyAether.emyGetLayerNumByName(self.design, layer) purposenum = pyAether.emyGetPurposeNumByName(self.design, purpose) wid = int(width * self.uu2dbu) path = pyAether.emyPath.create(self.block, layernum, purposenum, wid, points) return path def create_gr(self, centerLine, templateName, **kwargs): r\u0026#34;\u0026#34;\u0026#34;This function creates an emyScalarNet object on specified block. Parameters ---------- centerLine : emyPointArrayF Set the drawing route of the guard ring. templateName : str Set the template name of the guard ring. kwargs Other keyword arguments, here specifies type, justify, offset, topLayer, stackMode, maxContPattern, isBodyMode, bodyWidth, contRow, contSpaceX, contSpaceY, contSizeX, contSizeY, bIsChamfer, chamferAmount, metalSameBody, stackSameMetal, cornerContact. Returns ------- rect_nwgr : emyRect Build nwGuardRings. \u0026#34;\u0026#34;\u0026#34; type = kwargs.get(\u0026#34;type\u0026#34;, \u0026#34;Polygon\u0026#34;) justify = kwargs.get(\u0026#34;justify\u0026#34;, \u0026#34;Center\u0026#34;) offset = kwargs.get(\u0026#34;offset\u0026#34;, 0) topLayer = kwargs.get(\u0026#34;topLayer\u0026#34;, None) stackMode = kwargs.get(\u0026#34;stackMode\u0026#34;, False) maxContPattern = kwargs.get(\u0026#34;maxContPattern\u0026#34;, False) isBodyMode = kwargs.get(\u0026#34;isBodyMode\u0026#34;, True) bodyWidth = kwargs.get(\u0026#34;bodyWidth\u0026#34;, 0.5) contRow = kwargs.get(\u0026#34;contRow\u0026#34;, 0) contSpaceX = kwargs.get(\u0026#34;contSpaceX\u0026#34;, 0) contSpaceY = kwargs.get(\u0026#34;contSpaceY\u0026#34;, 0) contSizeX = kwargs.get(\u0026#34;contSizeX\u0026#34;, 0) contSizeY = kwargs.get(\u0026#34;contSizeY\u0026#34;, 0) bIsChamfer = kwargs.get(\u0026#34;bIsChamfer\u0026#34;, False) chamferAmount = kwargs.get(\u0026#34;chamferAmount \u0026#34;, 0) metalSameBody = kwargs.get(\u0026#34;metalSameBody\u0026#34;, False) stackSameMetal = kwargs.get(\u0026#34;stackSameMetal\u0026#34;, False) cornerContact = kwargs.get(\u0026#34;cornerContact\u0026#34;, True) pyAether.aeCrtGuardring(self.design, centerLine, templateName, type=type, justify=justify, offset=offset, stackMode=stackMode, maxContPattern=maxContPattern, isBodyMode=isBodyMode, contRow=contRow, contSpaceX=contSpaceX, topLayer=topLayer, contSpaceY=contSpaceY, contSizeX=contSizeX, contSizeY=contSizeY, bIsChamfer=bIsChamfer, chamferAmount=chamferAmount, metalSameBody=metalSameBody, stackSameMetal=stackSameMetal, cornerContact=cornerContact, bodyWidth=bodyWidth) def close(self): r\u0026#34;\u0026#34;\u0026#34;This function save and close the emyDesign object which is opened. \u0026#34;\u0026#34;\u0026#34; self.design.save() self.design.close() def create(self, x_0, y_0): r\u0026#34;\u0026#34;\u0026#34;This function creates an inverter. \u0026#34;\u0026#34;\u0026#34; self.pnt_x = x_0 self.pnt_y = y_0 # Create scalar instances params_p18 = pyAether.emyParamArray() params_p18.append(pyAether.emyParam(\u0026#39;Single_Width\u0026#39;, \u0026#39;1u\u0026#39;)) self.create_inst(\u0026#34;reference_pdk\u0026#34;, \u0026#34;p18\u0026#34;, \u0026#34;layout\u0026#34;, \u0026#34;M0\u0026#34;, (0.43, 3.15), params_p18) # pyAether.emyArray() params_n18 = pyAether.emyParamArray() params_n18.append(pyAether.emyParam(\u0026#39;Single_Width\u0026#39;, \u0026#39;600n\u0026#39;)) params_n18.append(pyAether.emyParam(\u0026#39;SD_Metal_Width\u0026#39;, \u0026#39;370n\u0026#39;)) self.create_inst(\u0026#34;reference_pdk\u0026#34;, \u0026#34;n18\u0026#34;, \u0026#34;layout\u0026#34;, \u0026#34;M1\u0026#34;, (0.29, 1.17), params_n18) # Create path path1 = self.create_path(\u0026#34;GT\u0026#34;, \u0026#34;drawing\u0026#34;, 0.18, (1.0, 3.15), (1.0, 1.77)) path2 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (1.36, 3.47), (1.36, 1.21)) path3 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (0.64, 1.21), (0.64, 0.18)) path4 = self.create_path(\u0026#34;M1\u0026#34;, \u0026#34;drawing\u0026#34;, 0.23, (0.64, 4.11), (0.64, 5.14)) # Create net self.create_net(\u0026#34;Y\u0026#34;, path1) self.create_net(\u0026#34;A\u0026#34;, path2) self.create_net(\u0026#34;vss\u0026#34;, path3) self.create_net(\u0026#34;vdd\u0026#34;, path4) # create GR self.create_gr([(0.53, 4.89), (1.47, 4.89)], \u0026#34;NWGR\u0026#34;, bodyWidth=0.4) # create PGR self.create_gr([(0.52, 0.41), (1.48, 0.41)], \u0026#34;PGR\u0026#34;, bodyWidth=0.4) if __name__ == \u0026#39;__main__\u0026#39;: example = InvLe(\u0026#34;lib01\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;reference_pdk\u0026#34;, \u0026#34;layout\u0026#34;, mode=\u0026#34;w\u0026#34;) example.create(0, 0) example.close() 概伦电子 # 收购了Entasys\n鸿芯微纳 # 华芯巨数 # 浙江\n嘉立创 # PCB\n相关竞赛 # CADathlon@ICCAD # CADathlon@ICCAD 2024 | ICCAD 2024\nEDA领域的**“奥林匹克运动会”，始于2002年** in-person event, all-day programming competition, 9 hours, two-person teams, information about the problems and relevant research papers will be released online one week before the competition. 一般在10月份举办 six problems Circuit Design \u0026amp; Analysis Physical Design \u0026amp; Design for Manufacturability Logic \u0026amp; High-Level Synthesis System Design \u0026amp; Analysis Functional Verification \u0026amp; Testing Future technologies (Bio-EDA, Security, AI, etc.) Contest@ISPD # International Symposium on Physical Design (ISPD)\n于2005年首次举办 Contest@ISPD作为ISPD研讨会的一部分，是全球三大顶尖国际物理设计学术竞赛之一，由全球研究计算机科学的权威学会ACM（Association for Computing Machinery）所举办 每年12月份由业界一流公司（IBM、Intel、Xilinx等）公布学术竞赛题目，3月份提交研发成果和软件系统，由业界公司负责提供测试电路，并测试参赛队伍所提交的软件系统，最后于3月底或4月初在年度ACM ISPD会议上公布竞赛结果。 题目 First Place 2015 Blockage-Aware Detailed Routing-Driven Placement Contest NTUPlacerDR CAD Contest@ICCAD # 始于 2012年 覆盖了EDA前端（front-end）和后端（back-end） 由IEEE CEDA、ACM SIGDA和工业界Cadence、Synopsys等共同赞助 Each year the organizing committee announce three challenging problems in different topic, can participate in one or more problems Blockage-Aware Detailed Routing-Driven Placement Contest\n历年相关赛题 # 题目 Sponsor 2024-C Scalable Logic Gate Sizing Using ML Techniques and GPU Acceleration Nvidia 2011 Routability-driven Placement Contest and Benchmark Suite 侠客岛 # EDA精英挑战赛 # TAU Contest # Tau 2021 Contest\n数字电路时序分析竞赛（TAU） 始于2011年，是由国际计算机协会ACM所举办的专业赛事 一般由IBM、Cadence、Synopsys、TMSC等国际顶尖公司参与命题 好像到21年就没了。。。 Programming Contest@IWLS # IWLS Contest\n始于2017年 是由IEEE/ACM International Workshop on Logic \u0026amp; Synthesis（IWLS）举办 由业界一流公司（Synopsys、Xilinx、Google等）公布竞赛题目 以逻辑综合（Logic Synthesis）和工具研发为竞赛主题 “全国大学生集成电路创新创业大赛”的华大九天赛道 # 全国大学生集成电路创新创业大赛\n第八届集创赛杯赛题目——华大九天杯 - 全国大学生集成电路创新创业大赛\nLLM4HWDesign Contest # 2024年ICCAD新设立LLM for Hardware Design Contest\nLLM4HW Design竞赛旨在为硬件代码生成构建大规模、高质量的Verilog代码生成数据集。在基于LLM的硬件代码生成中引发一场类似ImageNet的革命。为了实现这一目标，LLM4HWDesign竞赛鼓励参与者收集数据样本，并开发创新的数据清理和标记技术，以有效提高硬件代码生成数据集的规模和质量，为推进LLM辅助硬件设计工作流程建立关键基础设施。\nDAC System Design Contest # DAC 2012 Routability-Driven Placement Contest and Benchmark Suite\n参考 # 盘点全球顶级EDA竞赛及中国大陆获奖情况|清华大学|福州大学|iccad|上海交通大学|eda_网易订阅 相关PDK # "},{"id":11,"href":"/zh/docs/Digtal/flow/flow/","title":"Flow","section":"Physical design","content":" AI 4 Science # 数字集成电路后端设计整体流程 # 在完成前端设计、逻辑综合和时序分析后，后端设计阶段开始\n（1）布局规划（Floorplan）： 在布局规划阶段，设计团队确定芯片的大致布局，包括模块位置、互连和电源网络的布局。这个阶段的主要目标是确保设计满足所有功能需求和制造约束，同时优化芯片的性能和成本。\n（2）宏块和标准单元布局（Placement）： 此阶段中，具体摆放包括宏模块和标准单元。算法将尝试在保持功能和电气性能的前提下，最小化连线长度和延迟，优化布局密度。\n（3）时钟树合成（Clock Tree Synthesis，CTS）： 布局完成后，进行时钟树合成。CTS 的目的是构建一个时钟网络，以最小化芯片上不同部分之间的时钟偏差，并确保整个芯片的同步运行。\n（4）布线（Routing）： 在 CTS 之后，进行布线阶段，此阶段建立电子连接，以实现设计中的所有逻辑互联。布线需要解决路径规划和信号完整性问题，确保信号在整个芯片上无干扰地传递。\n（5）验证和测评： 最后，进行布局与布线后的验证工作，包括电路验证、时序分析和功耗分析等。\nFloorplanning（布图) # 确定核心和外围区域：定义芯片的核心逻辑区和外围接口区。 核心区域：这是用于放置 逻辑门、触发器等基础元件的区域。 外围区域：这里通常用于放置 I/O pads，电源和地引脚。 确定 IP Blocks 的位置：IP（Intellectual Property）模块的大致位置和尺寸。 硬宏（Hard Macros）：例如存储器、 模数转换器（ADCs）等，通常有固定的大小和形状。 软宏（Soft Macros）：通常是可以重新合成的逻辑模块，如处理器核心、 DSP 单元 等。 初步 Power Planning：设计初步的电源网格和地网。 电源网格设计：创建电源和地网格来提供电流和参考电压。 电源环（Power Rings）：在芯片外围设计电源环，用于电源和地的分发。 电源铺垫（Power Pads）：确定用于外部电源连接的电源和地铺垫的位置。 I/O Planning：规划输入/输出引脚的位置。 引脚位置：根据接口要求（如 GPIO、DDR 接口等）确定 I/O 引脚的位置。 引脚电特性：确定每个 I/O 引脚的电性能需求，如驱动能力、接受阈值等。 设置约束：设置时序、面积和功耗的约束。（各种 view, block) 时序约束：定义时钟域、时钟频率和时序要求。 面积约束：如果有面积限制，需要明确这一点。 功耗约束：设定功耗上限或优化目标。 Placement（布局） # 设计的所有逻辑元件（例如标准单元、触发器、门等）和预定义的 IP 块（例如硬宏）被物理地放置在芯片的核心区域内\n全局布局：进行粗略的布局优化。 草图生成：使用不同的算法（例如 模拟退火、 遗传算法 等）来生成一个初步的元件布局草图。（不会对准 row) 优化目标：主要考虑的是最小化布线长度、改善功耗和满足时序约束。 详细布局：进一步优化每个标准单元和宏单元的位置。 局部优化：在全局布局的基础上进行更细致的调整。 对齐和间距检查：确保所有元件都符合工艺规则，包括对齐、间距和其他布局规则。 优化：针对时序、功耗等进行局部优化。 Timing Driven Placement：根据时序需求进行局部或全局优化。 功耗优化：通过智能地布局来减少功耗（例如，通过聚集功耗高的单元）。 Power Planning：尽管大部分电源规划可能已在 Floorplanning 阶段完成，但在 Placement 阶段也可能需要进行一些细致的调整。例如，为了满足特定模块或逻辑块的电流需求，可能需要添加额外的电源或地连接。 验证 设计规则检查（DRC）：确保布局满足所有工艺和设计规则。 电气规则检查（ERC）：确保布局不会导致电气问题（例如，电流密度过高）。 Clock Tree Synthesis (CTS)（ 时钟树 综合） # 主要目的是生成一个有效的时钟分布网络。这个网络负责将时钟信号从一个或多个时钟源（Clock Source）传送到芯片内所有需要时钟的元件（如触发器和存储器元件）。在这一过程中，设计师需要权衡多个因素，包括但不限于时序、功耗、面积和可靠性\n创建时钟树：构建用于分发时钟信号的时钟树。 时钟缓冲：添加缓冲器来减少时钟偏斜。 优化：优化时钟树以满足时序和功耗需求。 Routing（布线） # 实现逻辑元件之间的物理连接\n全局布线：确定大致的连线路径。 路径规划：在这一步骤中，算法会大致规划出每一条互联线（net）应该走的路径。主要目标是规划逻辑元素（或电路网）之间的连接路径。这通常在一个 高级的抽象层面 上进行，一般不考虑过于详细的设计规则，比如具体的线宽和距离。 资源分配：为了确保所有的互联线都能被合适地布置，需要进行资源分配。 路径搜索：使用各种搜索算法（如 A*、Maze Routing 等）为每个网络找到一条或多条全局路径。 资源分配：在布线网格上为每条路径分配必要的资源，如布线轨和过孔。 处理冲突：当两个或更多的路径有冲突时（如共用相同的网格或资源），进行调整以解决冲突。 Skew 和延迟优化：对关键网络（如时钟网络）进行特殊处理，以最小化 skew 和信号延迟。 详细布线：在全局布线指导下，进行精确的连线。 实际布线：依据全局布线的结果，进行实际的布线操作。 处理冲突和过载：如果在布线过程中出现资源冲突或过载，需要进行相应的调整。 修复布线冲突：解决任何布线冲突或溢出。 生成最终的布线文件：这通常是一个包含所有物理信息的 GDSII 文件或其他类似格式的文件。 Physical Verification（物理验证） # 负责确保设计满足所有工艺和功能规格\nDRC（Design Rule Check）：使用工艺规则文件来验证设计，确保没有违反任何制程规则。\nLVS（Layout vs. Schematic）：确保物理布局与逻辑原理图一致。\nERC（Electrical Rule Check）：检查电流路径、电源连通性等。\n天线效应 检查：运用专用的检查工具来识别和解决可能的天线效应。\n抗辐射和电磁兼容（EMC）验证\n抗静电放电（ESD）和抗热设计\n时序验证(STA)\nRC 提取和 信号完整性分析\n尺寸和密度检查\nSign-off Checks # 它标志着设计即将完成，并准备进入制造阶段。在这个阶段，设计需要经过一系列严格的验证和审查，以确保其满足所有工艺、性能和功能规格\n时序 Sign-off：使用工艺库的最终版本和高精度模型来执行最终的时序分析。 静态时序分析（STA）：使用工艺最差条件（PVT，Process-Voltage-Temperature）进行时序验证。 动态时序分析：仿真整个时钟树和关键数据路径，以确认时序要求得到满足。 功耗 Sign-off：进行全芯片级的功耗 EDA 软件研发难点 # 参考 # 数字后端整体流程（Physical Design） - 知乎 EDA 重要性 # EDA 发展历史 # 中国大陆 # 由于1994年至2008年，中国大陆在EDA领域有差不多十五年的低迷期。很多高校失去了EDA的研究条件和生存环境，使得很多项目搞不下去，老师开始转型，导致高校从事EDA研究的人员越来越少。\n参考 # 超大规模集成电路物理设计-从图分割到时序收敛：第一章 # AI4EDA # 传统 EDA 缺点 # (1) 它依赖于硬件设计人员的专业知识来选择合适的 EDA 工具配置，(2) RTL 的设计空间探索，逻辑综合和物理综合是手动的，因此是有限且耗时的，(3) 设计中的更正将重新初始化流程，(4) 没有早期分析或结果的可预测性。\nGNN # 近年来，随着深度学习技术的广泛应用，越来越多的研究将其引入EDA领域。特别是图神经网络（Graph Neural Networks, GNN），凭借其在处理复杂图结构数据方面的显著优势，逐渐成为EDA后端设计中物理验证的重要工具。–cite–\u0026gt; 专题解读 | GNN在EDA后端设计物理验证环节中验证应力的应用\n由于考虑了特征和拓扑信息，GNN 已被证明优于其他 ML 模型\n[41] 中的研究 首次认识到 GNN 在 EDA 中的巨大潜力。他们表示，图形结构是表示布尔函数、网表和布局的最直观方式，这些是 EDA 流程的主要关注点。他们 将 GNN 视为 EDA 改进 QoR 并取代使用的传统浅层方法或数学优化技术的机会。\n基于 GNN 的架构优于其他模型和解决方案。上面列出的工作将他们的结果与浅层 ML、深度学习方法或特定任务的基线进行了比较。毫无疑问，GNN 的优越性是由于对拓扑和特征信息的考虑，这是以构建训练数据集的更大努力和更高的训练时间为代价的\nGNN 的优势与两个因素有关：定义明确的初始特征和图学习能力 [39]。定义明确的特征捕捉任务的基本特征，并为图学习提供宝贵的信息。 GNN 捕获特征和拓扑信息。 这与仅考虑图形连通性的方法相比，它具有明显的优势。\nG =(V, E) 分别不同的任务\n是否有向\n是否有环\n是否异构\n是否动态\n其他特殊图：二分图，正交图，超图\nrelate work 素材 # RL # 市场 # 三巨头： # 新思科技（Synopsys）：成立于 1986 年，是全球排名第一的电子设计自动化解决方案提供商，提供从设计到制造的全流程 EDA 工具，包括逻辑综合、时序分析、验证等。最大，还有 ip 楷登电子（Cadence Design Systems）：由 SDA Systems 和 ECAD 两家公司于 1988 年合并而成，提供广泛的 EDA 工具，包括模拟及数字集成电路设计和验证工具。 西门子 EDA（Siemens EDA）：前身是 Mentor Graphics，成立于 1981 年，2016 年被 西门子收购。Siemens EDA 提供全面的 EDA 软件、硬件及服务，包括 FPGA 设计、PCB 设计和 IC 设计工具、、、、、、、、、、、、、、、、、、、、、、 历史 # EDA 流程 # 数字前端 # 逻辑综合 将 HDL 中的 RTL 块映射到从 给定技术库 中选择的 门组合，同时针对不同目标优化设计。通常，这种优化涉及 时序收敛、面积和功耗之间的权衡。\n无需进行逻辑综合, 通过 RTL 预测 PPA # 精确时序或逻辑估计 [83]、[84]。\n功耗\n来识别与功耗相关的 RTL 信号。 Simmani [92] 和早期的功耗 建模工作 [93] 专注于 FPGA 和其他平台上的快速功耗 仿真，强调了 ML 方法的更广泛适用性，有助于在设 计阶段进行高效功耗分析。\nRTL 测试和验证领域：过学习 RTL 设计的语义抽象、促进功能预测和有效的测试生 成（显着缩短验证周期）\n数字后端 # Floorplanning Floorplan initialization - define the chip area, utilization IO pin placement (for designs without pads) Tap cell and well tie insertion PDN- power distribution network creation Global Placement Macro placement (RAMs, embedded macros) Standard cell placement Automatic placement optimization and repair for max slew, max capacitance, and max fanout violations and long wires Detailed Placement Legalize placement - align to grid, adhere to design rules Incremental timing analysis for early estimates Clock Tree Synthesis Insert buffers and resize for high fanout nets Optimize setup/hold timing Global Routing Antenna repair Create routing guides Detailed Routing Legalize routes, DRC-correct routing to meet timing, power constraints sign off Parasitic extraction using OpenRCX Final timing verification Final physical verification Dummy metal fill for manufacturability Use KLayout or Magic using generated GDS for DRC signoff 网表 # AI for Datapath Circuits：优化电路网表结构？加法器乘法器等\n[DRiLLS-Synthesis optimization(min area)-DAC-2020-RL(A2C)-](DRiLLS-Synthesis optimization(min area)-DAC-2020-RL(A2C)-.pdf)\n与仿真器互动 布图 floorplanning # 较大块被放置在二维网格上，以实现 最佳 PPA，同时 遵守设计规则。这可以表示为 马尔可夫过程，可以使用 RL 来解决。\nGoogle 展示了使用 DRL 框架对张量处理单元 (TPU) 加速器进行局部规划的成功芯片宏放置。在 [44] 中，将 GNN 合并到 RL 框架中以对过程的不同状态进行编码，预测拥塞、密度和线路长度的奖励标签，并推广到未见的网表。所提出的架构称为基于边缘的图神经网络（Edge-GNN）[44]，它计算整个网表的节点和边缘嵌入。此 RL 代理提供与人类设计师相当或更好的结果，但需要数小时而不是数月。\n布局 # 人工智能在标准单元设计中的应用，特别是布局和布线，由于其高密度和严格的可布线性要求，带来了一 系列独特的挑战。利用强化学习的人工智能辅助方法 已被证明可以改善布局顺序和可布线性，从而提供更 好的线长性能 [188]。\n任务：致力于确定单元内最佳晶体管位置\nglobal placement\ninvolves macro placement and standard cell placement, most crucial but timeconsuming steps in the chip design process, which can be cast as a constrained optimization problem. Detailed placement\nincludes legalization, wirelength and routability refinement Solution from global placement is often illegal: cells may overlap or occupy illegal sites, e.g. between placement rows. This is because global placers are unaware of these constraints. snaps standard cell to the sites of rows with minimum adverse impact on placement quality. 方向\nTraditional Placers Enhancement\nPL-GNN [Ward et al., 2012]\n结合了支持向量机（SVM）和神经网络来进行数据路径提取和评估，促进数据路径感知的放置策略。\nPL-GNN [Lu et al., 2021]\n种基于图学习的框架，该框架通过基于逻辑亲和性信息和设计实例的属性生成单元簇来为商业布局器提供布局指导\nDREAMPlace [Lin et al., 2020] 基于最先进的分析放置算法 RePlAce，DREAMPlace 通过深度学习工具包 PyTorch 实现手动优化的关键运算符，并比基于 CPU 的工具实现了超过 30 倍的加速\nPlacement Decision Making\nGoogle [Mirhoseini et al., 2021] nature.\nproposes an end-to-end learning method for macro placement that models chip placement as a sequential decision making problem. In each step, the RL agent places one macro and target metrics are used as reward until the last action.\nGNN is adopted in the value network to encode the netlist information and deconvolution layers in the policy network output the mask of current macro position.\nDeepPlace [Cheng and Yan, 2021]\nfor the placement of macros and standard cells RL + GNN + CNN base a gradient-based classical cell placer ([Lin et al., 2020]) Prediction Model Embedded in Placement\nML also assists placers to optimize complicated objectives like routability by embedding prediction models, as it is difficult to foresee routing congestion accurately during placement\nIEEE Xplore Full-Text PDF:\nbuilt to predict #DRVs at the macro placement stage without cell placement and routing information macro placer : 此外，模拟退火优化用于搜索具有预期最少 DRV 的最优宏布局 cnn [Chan et al., 2017]\n(1) machine-learning techniques to effectively predict detailed-route DRC violations after global routing and\n(2) detailed placement techniques to effectively reduce detailed-route DRC violations.\n[Liu et al., 2021b]\npredicts congestion hotspots and then incorporates this prediction model into a placement engine,\nRL\n许多研究探索了早期可路由性预测。 RouteNet [114] 使用 CNN 来预测路由设计后规则违 规 (DRV)，从而避免难以路由的布局。\n称为 Net 的 GAT 用于在 [61] 布局前中 估计路径长度。为此，他们 将网表转换为有向图，其中网络代表节点，边在两个方向上连接网络。单元数、扇入、扇出大小和面积用作特征节点。使用聚类和分区结果定义边缘特征。\nneurips21-1.pdf 全流程参数优化\u0026amp; VLSI Placement Parameter Optimization using Deep Reinforcement Learning (acm.org) 为了实现 PPA（性能、功耗、面积）目标，人类工程师通常需要花费大量时间调整商业放置工具的多个设置（maximum density, congestion effort, etc.）。本文提出了一个深度强化学习（RL）框架，用于优化商业 EDA 工具的放置参数。GCN（GraphSAGE） 是一个关键组件，因为它提取 RL 代理所需的本地和全局信息\n常见解决算法：动态规划，强化学习，满足性模型理论\n布线 # 任务：完成 cell 之间的连线。按照设计规则（例如允许角度的类型）连接放置的组件、门和时钟信号\nglobal routing\ndetail routing\nconsidering complicated design rules 详细布线还需要考虑优选布线方向，其中相邻布线层优选垂直布线方向。遵循其相应层的首选方向（例如，X 或 Y 方向）的连续网格边缘被描述为布线轨道 方向\nLearning-aided Routability Prediction 常用方法：A-star、整数线性规划和可满足性模理论\nDRC 检查：RL 方法，，简化了路由过程并支持使用 A 星或迷宫路由来获得最佳解决方案。机器学习技术 还促进了 DRC 规则的适应，简化了标准单元布局跨技 术节点的迁移 [190]\nCongestionNet 使用多层 GAT, 特征节点是 50 维向量，包含有关 单元类型、大小、引脚数和逻辑描述 的信息, 拥塞图被分成网格，每个网格的拥塞值被作为放置在该网格中的单元格的标签。对于超过 100 万个单元的电路，推理时间约为 19 秒\nhttps://ieeexplore.ieee.org/document/9643435/：GNN+LSTM, 预测端口路由 TNS, 利用 gnn 获得 embedding，用 place, opt.place, opt.cts 后的图分别预测电路 TNS 值，各自的 TNS 预测再构建一个 LSTM 网络，用于预测最后的 routing 后的 TNS 值，\n每个节点的特征都与任务相关，例如单元的最差松弛、最差的输出和输入压摆以及驱动网络的开关功率。这些是从技术库中收集并生成的报告。每个阶段的网表由全局 GNN 编码。在这三个阶段中的每一个阶段，图嵌入的使用都是双重的：它们是预测模型和 LSTM 的输入，其中图嵌入用作时间序列。单一预测模型预测每个阶段的 TNS，而 LSTM 将综合低点映射到连续低点。每阶段预测平均实现小于 12.6% 的归一化均方根误差，而基于 GNN 的 LSTM 预测在两个测试电路中实现小于 5.2%\n验证 # timing, power, drc\n逆向工程 # ReIGNN [107] 和 GNN-RE [108] 等工具利用 ML 来执行逆向工程任务，例如识 别状态寄存器和破译子电路的功能。\n模拟 # 模拟设计流程 的高复杂度是由于 大的设计空间和信号敏感性 w.r.t.噪音。因此，模拟流程可以从 ML 等现代方法中受益匪浅，从而使方法现代化并提高 QoR。\n拓扑生成 # Sizing(调整长宽比 ) # CircuitGNN # AutoCkt : Deep Reinforcement Learning of Analog Circuit Designs (DATE,2020）\nGCN-RL Circuit Designer: Transferable Transistor Sizing with Graph Neural Networks and Reinforcement Learning (DAC, 2020)\nCktGNN : Circuit Graph Neural Network for Electronic Design Automation (ICLR, 2023)\nDNN- Opt : An RL Inspired Optimization for Analog Circuit Sizing using Deep Neural Networks (DAC, 2021)\nAnalog Layout Automation：版图大小，DRC 预测 [208]，布局 [212]，路由 [210]， # 预测寄生参数：[217]，ParaGraph [46] ， [35] # LLM 大语言模型 # 将生成式人工智能（特别是大型语言模型 (LLM)）集成 到 IC 设计中正在成为一种变革趋势。通过利用专有数 据集，IC 设计公司可以开发人工智能助手来增强和加快 设计过程。这些工具能够提供深入的见解，自动执行和 完善传统的手动任务\n相关数据集：\n生成 RTL # 功能验证 # LLM 通过将自然语言规范转换为 SystemVerilog 断言 (SVA)，在功能验证方面取得了重大进展。此过程 确保 RTL 实现遵循他们的预期规格。\nLLM 在解决布尔可满足性 （SAT）问题 [179] 方面取得了成功，可应用于验证算 术电路。\nSecurity Verification: 使用 LLM 指出 RTL 的安全漏洞，基于 ChatGPT 推荐安全 RTL 代码 [181] 和相关的断言 [182]\n脚本生成和架构设计 # TCL 脚本生成: ChatEDA [183] 引入了基于 LLM 的代理，旨 在促进使用自然语言进行 EDA 工具控制，提供了一种 替代方案传统 TCL 脚本。\nGPT4AIGChip [184] 利用 LLMs 生成 AI 加速器高级合成的 C 代码。\n同样，Yan 等人 [185] 研究了 llm 在优化 内存计算(CIM) DNN 加速器中的使用，展示了该模型在提高计算效率方面的潜力\n[186] 深入研 究量子架构设计，探索量子计算的前沿。\n模拟 # 参考 # 浅谈大语言模型与 EDA\nLLM4EDA: Emerging Progress in Large Language Models for Electronic Design Automation\nLCM # EDA 工作流程从最初的规格延伸到详细的最终布局， 涵盖各种电路设计格式，每种格式都需要 LCM 内的 不同编码器。这些编码器旨在处理特定模式（规范、 架构设计、高级算法、RTL 设计、电路网表和物理布 局），是 LCM 的核心组件。\n虽然这些模型已经在基准数据集上 证明了有效性，但它们推广到新颖设计的能力仍然是 一个令人担忧的问题。\n电路数据固有的计算和结构的 独特融合需要超越通用人工智能解决方案能力的细致 入微的理解。例如，在不深入理解电路设计细微差别 的情况下将 LLM 应用于 RTL 生成通常无法实现最佳 PPA 结果。\n大型基础模型（如 BERT [2]、GPT [5] 和 MAE [8]）的出现，已经重新定义了人工智能的格 局，提供了一种分叉的方法，对不同的数据进行广泛 的预训练，然后针对特定任务进行有针对性的微调。 这种方法有助于实现各种数据类型的突破，预示着人 工智能应用的新时代。\n通过支 持 LCM，我们站在 EDA 革命的风口浪尖，超越特定 于任务的限制，拥抱人工智能原生解决方案推动电路 设计创新、效率和卓越的未来\n对齐挑战\n鉴于 LCM 依赖于广泛、高质量的训练数据集，数据 稀缺成为一个关键障碍\n团队 # 北大 CECA\n上交\n香港中文\n复旦\n华为诺亚方舟实验室，华为海思\n参考 # 2403.07257] The Dawn of AI-Native EDA: Opportunities and Challenges of Large Circuit Models (arxiv.org)\nA Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN\n书： Machine Learning Applications in Electronic Design Automation | SpringerLink\ninnovus # flow # floorplan # 考虑因素 # 封装形式 面积、绕通性、电源完整性、时序性能、功耗 Hard IP 使用需求 基础概念 # Box # Die Box: 整个芯片区域\nCore Box: 标准单元和 IP 摆放单元\nIO Box: IO 单元摆放区域(红色与黄色之间)\nCore2IO Box: 隔离距离，电压隔离，ESD 保护，Core 电源环创建（绿色红色之间）\nsite, row, # Site(最小布局单位) # SITE 的类别通常分为 core 和 pad，分别对应着 std cell 的 row 和 io cell 的 row。 SITE 的方向通常有 X，Y，R90 三个参数。X 代表可以沿 X 轴翻转，Y 代表可以沿 Y 轴翻转，R90 代表可以任意翻转。 SIZE 定义了 site 的宽度，通常 std cell 都是 site 的整数倍高度，宽度 Row(Standard/l0 cell 摆放位置) # 整数倍 Site Row 也有自己的方向，如上图箭头所示，通常相邻的 row 会 abut 且 flip，这样相邻 site 可以 共用一根电源线，节省 Power 资源。 Row Cut 问题 非整数倍 Row 低功耗设计 所有 std cell 都必须 snap 到 row 上面，这是最基本的 place 规则 默认的 std cell 摆放方向遵从 Row 的方向，即方向箭头一致，但是根据 cell 本身的 symmetry，std cell 的摆放位置也可以有如上图所示的选择 实际 design 中，我们还能经常见到一些其他种类的 row。常见的有 double height，trible height 的 row，用来摆放两倍高，三倍高的 cell。 一般我们只允许创建整数倍高的 row，而在 Voltage island 中，我们允许创建非整数倍高的 Row，比如默认电压区域用的是 9T 单元，而在 Voltage island 中我们使用了 12T 的 cell，这时候就需要创建非整数倍高度的 row EndCap, WellTap, Decap # 在后端物理设计中，除了与，非，或等一些常见的标准单元外，还有一些特殊的物理单元(physical cell)，它们通常 没有逻辑电路，不存在与 netlist 当中，但是对整个芯片的运行，稳定却起着举足轻重的作用。\nEndCap # 也叫 boundary cell， 拐角单元 是一种特殊的标准单元。 作用是确保每个 nwell 都是 nwell enclosed，类似一个封闭环。主要加在 row 的结尾(两边都要加)，以及 memory 或者其他 block 的周围包边 WellTap # welltap 是只包含 well contact 的 cell，将衬底接到电源和地网络，避免衬底悬浮。主要防止 CMOS 器件的寄生闩锁效应(latch-up)\n一般 tap cell 的作用范围是 30~40um, 即每隔 60um 左右放置一个 tap cell，具体的数据要参考艺商给的 document\nwell tap cell 一般交错摆放，类似棋盘分布。 Decap # Decap cell，去耦单元，这是一种特殊的 Filler cell。 当电路中大量单元同时翻转时会导致冲放电瞬间电流增大，使得电路 动态供电电压下降 或地线电压升高，引起动态电压降俗称 IR-drop。为了避免 IR-drop 对电路性能的影响，通常在电源和地线之间放置 由 MOS 管构成的电容，这种电容被称为去耦电容或者去耦单元，它的作用是在瞬态电流增大，电压下降时向电路补充电流以保持电源和地线之间的电压稳定，防止电源线的电压降和地线电压的升高。 Filler # 缓解 dynamic IR drop, eco\n通常是单元库中与逻辑无关的填充物\n可以分为 I/O filler(pad filler)以及普通的 standard cell filler.\npad filer，通常是用来填充 I/O 单元与 I/O 单元之间的空隙。为了更好的完成 power ring，也就是 ESD 之间的电源连接。通常是在 Floorplan 阶段时添加。\nstandard cell filler, 也是为了填充 std cell 之间的空隙。主要是为了满足 DRC 规则和设计需求，并形成 power rails。这个在 route 之前，之后加都可以。\nDecap cell，去耦单元，这是一种特殊的 Filler cell。\n当电路中大量单元同时翻转时会导致冲放电瞬间电流增大，使得电路 动态供电电压下降 或地线电压升高，引起动态电压降俗称 IR-drop。为了避免 IR-drop 对电路性能的影响，通常在电源和地线之间放置 由 MOS 管构成的电容，这种电容被称为去耦电容或者去耦单元，它的作用是在瞬态电流增大，电压下降时向电路补充电流以保持电源和地线之间的电压稳定，防止电源线的电压降和地线电压的升高。\n需要注意的是 Decap cell 是 带有 metal 层 的，为了不影响工具 routing resource，一般建议是最后 routing 全部结束后再加，加完之后再添加普通的不带 metal 的 filer.\nhard IP # hard IP 就是 macro\nmacro 有自己 单独的 lef 文件， 定义形状，pin 信息等等\nhard IP 一般有：SRAM/DDR/PLL/AD/DA\n常用原则\nMacro 一般摆放在芯片或模块(block)边缘 Macro 摆放时尽量缩短与其通信的 10 或 Macro 的距离 Macro 摆放时尽量缩短其 pins 与 standard cell 谡辑的距离 Macro 之间留够安全距离 重视 macro 之间的 channel，可以 abut 尽量 abut, channel 中在 place 时根据需求加入 soft blockage 标准单元区域尽量保持连续，不要产生小宽度的 channel; 长宽比接近 1 backbox # BlackBox 类似于一个 HardMacro，它内部的东西完全看不见，只是一个黑盒子，但是它又类似于一个 ModuleBoundary。它可以被改变形状，而且它可以被分配 pin 和被分割出去(partition)。如下图所示，灰色的形状就是 Black Box。\nBlackBox 是一种较为粗糙的模型，由于它看不见里面的东西，这样的结构使得它做任何 implementation 速度都很快，取而代之的精准度就会相对较低\ntrack, pitch # track # 走线轨道，信号线通常在 track 上 可以约束走线的方向 Std Cell 的高度通常用 metal2 track pitch 来表示，常用的 std cell 库有 7T/9T /12T，就是以 track 来区分的， 9T 就是说 std cell 的高度范围内可以走九条线，所以一般来讲， 7Tcell 的 size 最小， 9T cell 的 size 稍大。 布线时，往往第一层一般是水平，第二层垂直，相互交替 .lef 中定义如下，举例：\nLAYER M1 TYPE ROUTING ;#TYPE ROUTING代表这是一层走线层，我们还有其他的type包括Implant, Masterslice等. DIRECTION VERTICAL ; #DIRECTION代表这层Metal prefer走线方向，这边值得注意的是，每层track会分为pref track和non pref track。pref track就是这层layer上主流的走线方向，那剩下的non pref track就是非主流方向。因此上述例子中的主流走线方向就是vertical(纵向)，非主流就是横向(honrizontal)。通常。走non-pref track的wire会比较宽，这样就比较占用绕线资源。所以，一般不推荐使用non-pref track。特别是在先进工艺的设计中，绕线资源极其紧张，一般很少用到non-pref track. PITCH 0.090 0.064 #track之间的间距，垂直方向间距是0.09，水平方向是0.064. OFFSET 0.000 0.000 #第一条track偏离起始点的举例 MAXWIDTH 2; #WIDTH就代表默认这层layer上wire的宽度？MAXWIDTH就代表最高不能超过多少width WIDTH 0.032; Grid # Litho Grid，中文名，光刻格点。又被称为制造单元格点，这是 最基本的网格单元，任何元件都要对 Litho Grid 上，不然就无法被制造 它定义在 design 的 technology LEF. e.g.: MANUFACTURINGGRID 0.001;. 这就代表着改设计的制造单元格点间距为 0.001, 起始点是 Die Box 的 lower left 角上 Blockage, halo # Net, Wire # Net # 线网，也就是 Verilog 里的 wire(还有 tri、wor、trior、wand、triand、trireg、tri1、tri0、supply0、supply1) Wire\n后端工具中的 wire 指的是 net 的 物理化概念 每一条 net 在后端工具里面是由许多小段的 wire 组成，每一小段 wire 我们称之为 wire segment. wire 按照类型可以分为 Regular Wire(信号线)，Special Wire(电源线)，Patch Wire(补丁线)。 Regular Wire 就是我们平常见到的信号连线，连接各个 Siqnal Pin 的金属线段。每层金属层上的 Regular wire 默认的宽度都是一样的。 Special Wire 就是电源接地线，平常我们所见到的 power ring，stripes，power rail 等都是 Special Wire。一般用高层金属走线. Patch Wire，我们称之为补丁线。这是先进工艺中的一种走线，用于修复 Min Area，MinStep 等 DRC，不属于任何 net。 Pin # 引脚\n分为 Instance Pin, I/O Pin, Physical Pin, Partition Pin:\nInstance Pin: cell 的 pin\nI/O Pin: 模块输入输出，也叫 IO port\nPhysical Pin: Physical Pin 是 IO pin 具体物理化的信息，该引脚用于底层模块与上层模块拼接时的接口，类似一个纽扣一样，定义模块走线的起点和终点。它也是有具体的金属层参数信息，和普通 wire 一样。\nPartition Pin: 切分模块的引脚。用于在顶层模块未切分时，定义 physical pin 的位置，这个阶段的 physical pin，我们称之为 partition pin。和 Physical Pin 一样，他具有实际的金属层参数信息。\nplacement # 摆放标准单元，同时满足各种 constraint\n会删掉综合后加入的 buffer\n基础概念 # Tie High/Low\n电压转换\n尺寸越小越重要，静电\nGlobal/Detail Place\nDetail 是把 Global 后的单元放到网格上同时满足 constraint 要求\ndrv\nhvt 和 lvt\nHVT (High Voltage Threshold)：高电压阈值晶体管。这类单元库的特点是它们的阈值电压较高，因此它们在泄漏电流（leakage current）方面表现较好，也就是说 在静态功耗方面比较低。但是，它们的开关速度较慢，因此在性能（speed）方面不如低阈值电压的单元库。HVT 单元库通常用于对功耗要求较高的场合，但对性能要求不是非常高的地方。 LVT (Low Voltage Threshold)：低电压阈值晶体管。与 HVT 相反，LVT 单元库的阈值电压较低，这使得它们在开关速度上更快，因此性能较高。但是，这种速度的提升是以增加泄漏电流为代价的，也就是说它们的静态功耗较高。LVT 单元库通常用于对性能要求较高的设计中。 CTS # placement 后的 clock tree 是理想的（没有延时）\n主要的行为是插入 buffer/inverter\n希望到同一级（流水线的级？）的时钟 delay 是一致的\n如果有不同 clock，也要考虑 clock 之间的影响\ninnouvs 的 CTS 工具叫 ccopt\n评价指标：(latency (insertion delay), skew, clock power, clock em, long common path(cppr), duty cycle)\n基本概念 # route # 三个步骤：global route, track assignment（分配 global route 的 track 给对应的 net）, detail route\n基本知识 # nano # SI # Antenna # eco route # 工艺制造，栅极放电破坏\nsignoff 的时候会检查这个问题，工具会加上\n连接到栅极的面积不要太大\nsign off # 基本知识 # mode # function # 最常见 标准时序约束模式 Scan shift # 移位扫描模式 由于芯片内部是个黑盒子，在外部难以控制。我们将芯片中的所应用的普通寄存器替换成带有扫描功能的扫描寄存器，首尾相连成串，从而可以实现附加的测试功能，这就是 Scan chain 的概念。下图一就是扫描寄存器，下图二就是将扫描寄存器串起来的 Scan Chain Capture # 也叫 Stuck-at 模式 DC 模式：主要检查我们平时常见的 stuckat 0/1 错误。比如下图中的 inverter A 端如果被接到了 VSS 端的话，就是一个 stuck at 1 的 fault ASST # At Speed MBIST # Boundary Scan # common command # #gui innovus -no_gui win/win_off #gui 开关 win_off用不了？ #run innovus -init init.tcl source xxx.tcl dbGet top.insts.name selectInst xxx_insts_name dbGet selected.pgInstTerms.name #kill ps -ef | grep innovus killall -9 innovus 实战 c # 0_所需文件： # netlist\ntech_lef, cell_lef(standard cell, io, ip(ram))\npex_tech(best, worst, typ_qrcTechFile)\nmmmc.viewDefinition.tcl\nlibrary_set\nfast standard cell\u0026rsquo;s .lib, ip\u0026rsquo;s .lib slow standard cell\u0026rsquo;s .lib, ip\u0026rsquo;s .lib rc corner\nbest/worst qrcTechFile(unreadable) delay_corner\nconstraint_mode\nconfig sdc_file\nanalysis_view\n1_数据初始化 # 设置 netlist\ntech_lef，cell_lef\npex_tech\nset scenarios\nset cell type\n############################################################## # Common design settings # Created by Yanfuti ############################################################## ### design information set design \u0026#34;leon\u0026#34; ### design data directory set project_root \u0026#34;..\u0026#34; set library_root \u0026#34;~/BackEnd/innovus_learn/library\u0026#34; set reports_root \u0026#34;${project_root}/reports\u0026#34; ### gate level netlist files set import_netlists \u0026#34;\u0026#34; lappend import_netlists \u0026#34;${project_root}/netlist/post_syn_netlist/${design}.vnet.gz\u0026#34; ### SDC files ### tech lef set tech_lef \u0026#34;${library_root}/tlef/gsclib045_tech.lef\u0026#34; ### library files set cell_lef \u0026#34;\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/gsclib045_hvt_macro.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/gsclib045_macro.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/MEM1_256X32.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/MEM2_128X32.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/pdkIO.lef\u0026#34; lappend lef_files \u0026#34;${library_root}/lef/pads.lef\u0026#34; ### PEX tech set qrc_tech(rcbest) \u0026#34;${library_root}/tech/qrc/rcbest/qrcTechFile\u0026#34; set qrc_tech(rcworst) \u0026#34;${library_root}/tech/qrc/rcworst/qrcTechFile\u0026#34; set qrc_tech(typical) \u0026#34;${library_root}/tech/qrc/typical/qrcTechFile\u0026#34; ### view (scenarios) of each step set default_scenarios \u0026#34;func_slow_rcworst\u0026#34; set placeopt_scenarios \u0026#34;func_slow_rcworst\u0026#34; set cts_scenarios \u0026#34;cts_slow_rcworst\u0026#34; set clockopt_scenarios \u0026#34;func_slow_rcworst func_fast_rcbest\u0026#34; set routeopt_scenarios \u0026#34;func_slow_rcworst func_fast_rcbest\u0026#34; ### cells type settings set fillers_ref \u0026#34;FILL1 FILL16 FILL2 FILL32 FILL4 FILL64 FILL8\u0026#34; set welltap_ref \u0026#34;DECAP8\u0026#34; ############################################################## # END ############################################################## 2_import # set init_top_cell $design #给该design赋一个名字 set init_verilog $import_netlists #设置verilog文件的路径 set init_lef_file [concat $tech_lef $lef_files] #设置lef file的路径 set init_pwr_net \u0026#34;VDD\u0026#34; #表示初始电源网络的标识符或名称 set init_gnd_net \u0026#34;VSS\u0026#34; #表示初始接地网络的标识符或名称 set init_mmmc_file \u0026#34;../viewDefinition.tcl\u0026#34; #设置mmmc文件的路径 setImportMode -keepEmptyModule true #-keepEmptyModule是一个命令的参数，它指定是否在导入设计时保留空的模块，空的模块，顾名思义，没有任何内容（如实例化，信号，逻辑，声明等）的模块。通过保留这些模块，可以确保设计的层次结构不变，方便后续的设计迭代与调试。 ### read design init_design #开始导入设计 setIoFlowFlag 0 #此内容可以先忽略 ### connect pg (pg--power ground) globalNetConnect $init_pwr_net -type pgpin -pin VDD -all #globalNetConnect，用于连接全局网络也就是用于定义全局电源（Power）和地（Ground）连接。在后端设计阶段，需要明确的定义电源和地如何连接到各个模块和单元。$init_pwr_net 是一个变量，表示初始电源网络的名称，此处等价于VDD，-type 是指定连接的类型是电源/地引脚（pgpin）-------pgpin（power ground pin），-pin VDD，这是另一个参数，用于指定连接的引脚名称或标识符，这里是指定连接到电源引脚，也就是要将$init_pwr_net 连接到所有名为VDD的引脚上，-all 表示该连接适用于设计中的所有实例。 globalNetConnect $init_gnd_net -type pgpin -pin VSS -all #同上，这里不挨个解释，综合说明一下，也可看作是上一条的总结：将变量$init_pwr_net（通常是表示某个电源网络，例如 VSS）连接到设计中所有单元和模块中的 VSS 引脚。这种全局连接是为了确保设计中的所有模块和单元都能正确地连接到电源网络，确保电源供给的一致性和可靠性。 ### save design file delete -force ${data_dir}/${current_step}.enc* #保存设计之前把该路径下存在的.enc文件全部删除 saveDesign ${data_dir}/${current_step}.enc #saveDesign命令，用于保存设计，其后接的是保存设计的文件路径 mmmc(viewDefinition.tcl)\n### library set (-aocv or lvf, spatial socv) create_library_set -name \u0026#34;fast\u0026#34; -timing\\ [list \\ ${library_root}/liberty/fast_vdd1v2_basicCells.lib\\ ${library_root}/liberty/fast_vdd1v2_basicCells_hvt.lib\\ ${library_root}/liberty/MEM1_256X32_slow.lib\\ ${library_root}/liberty/MEM2_128X32_slow.lib\\ ] create_library_set -name \u0026#34;slow\u0026#34; -timing\\ [list \\ ${library_root}/liberty/slow_vdd1v0_basicCells.lib\\ ${library_root}/liberty/slow_vdd1v0_basicCells_hvt.lib\\ ${library_root}/liberty/MEM1_256X32_slow.lib\\ ${library_root}/liberty/MEM2_128X32_slow.lib\\ ] ### rc corner create_rc_corner -name \u0026#34;rc_best\u0026#34;\\ -preRoute_res 1.34236\\ -postRoute_res 1.34236\\ -preRoute_cap 1.10066\\ -postRoute_cap 0.960235\\ -postRoute_xcap 1.22327\\ -preRoute_clkres 0\\ -preRoute_clkcap 0\\ -postRoute_clkcap {0.969117 0 0}\\ -T 0\\ -qx_tech_file ${library_root}/tech/qrc/rcbest/qrcTechFile create_rc_corner -name \u0026#34;rc_worst\u0026#34;\\ -preRoute_res 1.34236\\ -postRoute_res 1.34236\\ -preRoute_cap 1.10066\\ -postRoute_cap 0.960234\\ -postRoute_xcap 1.22327\\ -preRoute_clkres 0\\ -preRoute_clkcap 0\\ -postRoute_clkcap {0.969117 0 0}\\ -T 125\\ -qx_tech_file ${library_root}/tech/qrc/rcworst/qrcTechFile ### delay corner for each pvt (process voltage temperature) : library set + rc corner create_delay_corner -name slow_rcworst\\ -library_set slow\\ -rc_corner rc_worst create_delay_corner -name fast_rcbest\\ -library_set fast\\ -rc_corner rc_best ### mode : (func + shift + capture) #一般对不同情况有多个sdc文件，比如现在有两种delay_corner,就可以写两个，不过现在只有一个现成的sdc文件所以只写一个 create_constraint_mode -name functional \\ -sdc_files [list ${sdc_file}] ### define view (mode + delay corner) create_analysis_view -name func_slow_rcworst -constraint_mode functional -delay_corner slow_rcworst create_analysis_view -name func_fast_rcbest -constraint_mode functional -delay_corner fast_rcbest ### set analysis view status set_analysis_view -setup [list func_slow_rcworst] -hold [list func_fast_rcbest] 3_floorPlan # floorPlan -site CoreSite -d 930 600.28 0 1.71 0 1.71 -fplanOrigin llcorner\t#-d \u0026lt;W H Left Bottom Right Top\u0026gt; 得到的是Die size; -s 得到的是Core size; #-fplanOrigin llcorner 设置原点坐标 #手动放置marco: shift+r进入移动模式，选中后移动marco 对齐，移动：用 ctrl 选择多个 macro\n导出位置 tcl 文件，方便下次自动化：\n注意！这部分要手工！！\n1. 选中macrof 2. writeFPlanScript -selected -fileName ${project_root}/scripts/macro_placement.tcl 3. source ${project_root}/scripts/macro_placement.tcl #fix macro dbGet top.insts.cell.subClass block dbGet [dbGet top.insts.cell.subClass block -p2].name dbSet [dbGet top.insts.cell.subClass block -p2].pStatus fixed ### create placement and routing halo around hard macros (instance name vs cell name, and reference name) set halo_left 2.0 set halo_right 2.0 set halo_top 2.0 set halo_bottom 2.0 set rhalo_space 2.0 deleteHaloFromBlock -allBlock deleteRoutingHalo -allBlocks #addHaloToBlock $halo_left $halo_bottom $halo_right $halo_top -allBlock foreach macro [dbGet [dbGet top.insts.cell.subClass block -p2].name] { addHaloToBlock $halo_left $halo_bottom $halo_right $halo_top $macro addRoutingHalo -space $rhalo_space -top Metal11 -bottom Metal1 -inst $macro } ### place ports set input_ports [dbGet [dbGet top.terms.direction input -p].name] editPin -pinWidth 0.08 -pinDepth 0.32 -fixOverlap 1 -unit TRACK -spreadDirection clockwise -layer 5 -spreadType START -spacing 4 -start 0 -200 -pin $input_ports -fixedPin -side LEFT set output_ports [dbGet [dbGet top.terms.direction output -p].name] editPin -pinWidth 0.08 -pinDepth 0.32 -fixOverlap 1 -unit TRACK -spreadDirection counterclockwise -layer 5 -spreadType START -spacing 4 -start 0 -200 -pin $output_ports -fixedPin -side RIGHT dbSet top.terms.pStatus fixed #放置blockage 2. writeFPlanScript -selected -fileName ${project_root}/scripts/blockage_placement.tcl 3. source ${project_root}/scripts/blockage_placement.tcl #一些endcap, welltap ### insert boundary cells (endcap) set endcap_prefix \u0026#34;ENDCAP\u0026#34; set endcap_left \u0026#34;FILL2\u0026#34; set endcap_right \u0026#34;FILL2\u0026#34; set endcap_top \u0026#34;FILL1\u0026#34; set endcap_bottom \u0026#34;FILL1\u0026#34; deleteFiller -prefix $endcap_prefix setEndCapMode -reset setEndCapMode -topEdge $endcap_top setEndCapMode -bottomEdge $endcap_bottom setEndCapMode -leftEdge $endcap_left setEndCapMode -rightEdge $endcap_left setEndCapMode -leftBottomCorner $endcap_bottom setEndCapMode -leftTopCorner $endcap_top setEndCapMode -rightBottomCorner $endcap_bottom setEndCapMode -rightTopCorner $endcap_top setEndCapMode -leftBottomEdge $endcap_left setEndCapMode -leftTopEdge $endcap_left setEndCapMode -rightBottomEdge $endcap_right setEndCapMode -rightTopEdge $endcap_right addEndCap -prefix $endcap_prefix ### create well tap cells (fix latch up) set welltap_prefix \u0026#34;WELLTAP\u0026#34; deleteFiller -prefix $welltap_prefix addWellTap -prefix $welltap_prefix -cell $welltap_ref -cellInterval 70 -checkerBoard 4_powerPlan # ### remove all existing power routing editDelete -use {POWER} -shape {RING STRIPE FOLLOWPIN IOWIRE COREWIRE BLOCKWIRE PADRING BLOCKRING FILLWIRE FILLWIREOPC DRCFILL} #Add power Stripe setAddStripeMode -reset setAddStripeMode -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal1#指定最底层和最顶层要用via连接的是哪些层，此处我们只create Metal1最底层的rails，所以top_layer和bottom_layer都是Metal1。 addStripe -nets { VDD } -layer Metal1 -direction horizontal -width 0.120 -spacing 1.710 -set_to_set_distance 3.420 -start [expr 1.71 - 0.120 / 2.0] -stop $die_y1 -area $die_area -area_blockage $macro_region #-nets 指定是VDD #-layer 指定使用的层，此处是Metal1 #-direction 指定方向，此处为horizontal #-width 一般来说是std cell的VDD的width是多少就设为多少，下图所示是0.12，所以我们也设为0.12 addStripe -nets { VSS } -layer Metal1 -direction horizontal -width 0.120 -spacing 1.710 -set_to_set_distance 3.420 -start [expr 1.71*2 - 0.120 / 2.0] -stop $die_y1 -area $die_area -area_blockage $macro_region ##给macro通过ring加上power strip ### create power rings for memory cells {Metal8 \u0026amp; Metal9} setAddRingMode -reset deselectAll selectInst [dbGet [dbGet top.insts.cell.subClass block -p2].name] setAddRingMode -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addRing -nets {VDD VSS} -type block_rings -around selected -layer {top Metal9 bottom Metal9 left Metal8 right Metal8} -width {top 5 bottom 5 left 5 right 5} -spacing {top 1.25 bottom 1.25 left 1.25 right 1.25} -offset {top 5 bottom 5 left 5 right 5} deselectAll ### create power stripes (Metal8 and Metal9) #editDelete -use {POWER} -shape {RING STRIPE FOLLOWPIN IOWIRE COREWIRE BLOCKWIRE PADRING BLOCKRING FILLWIRE FILLWIREOPC DRCFILL} setAddStripeMode -reset setAddStripeMode -break_at {block_ring} -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addStripe -nets {VDD VSS} -layer Metal9 -direction horizontal -width 5 -spacing 1.25 -set_to_set_distance 72 -start_from bottom -start_offset 40 -stop_offset 0 -block_ring_top_layer_limit Metal9 -block_ring_bottom_layer_limit Metal1 setAddStripeMode -reset setAddStripeMode -break_at {block_ring} -stacked_via_bottom_layer Metal1 -stacked_via_top_layer Metal9 addStripe -nets {VDD VSS} -layer Metal8 -direction vertical -width 5 -spacing 1.25 -set_to_set_distance 75 -start_from left -start_offset 35 -stop_offset 0 -block_ring_top_layer_limit Metal9 -block_ring_bottom_layer_limit Metal1 #check set report_drc_dir ${project_root}/reports/${current_step} file mkdir ${report_drc_dir} verify_drc -limit 99999 -report ${report_drc_dir}/verify_drc.rpt#给一个error数量的限制 -limit 99999 verifyConnectivity -net {VDD VSS} -error 99999 -report ${report_drc_dir}/verifyConnectivity.rpt #给一个error数量的限制 -limit 99999 redirect -tee ${report_drc_dir}/checkPlace.rpt {checkPlace} 可以在这里查看报告：\n#上面这个bug： deleteRouteBlk -name $rblkg_prefix 5_place_opt # setDesignMode\n-node，别称“超级开关”，是比较重要的一个设置，可以针对 某一种特定的工艺做一些基础的设置。它的选项很多，分别对应不同 Foundary 的不同工艺的区别，N 系列就是台积电的，S 系列就是三星的。。。\n-process，相比于-node，-process 是更 通用的设置，因为可以看到-node 里面的都是 20 以下的，此处用到的工艺是 45，所以使用更为通用的-process 45。在成熟的工艺中，都有特定的数字去代替，比如 40，28 等等。\n-topRoutingLayer,-bottomRoutingLayer. 就是告诉工具只能用哪些层进行绕线\nsetAnalysisMode\n-analysisType {single | bcwc | onChipVariation}\n其中(onChipVariation)模拟的 PVT 条件的偏差会更接近实际情况，会减少一些不必要的悲观量。\n一般都用 OCV\n-cppr 是关于 clock line 上的 common path 的一个处理方式\nsetOptMode\n-addInstancePrefix, -addNetPrefix\n工具在优化的过程中会增加很多新的 Cell，对于这些 Cell，我们希望他们都带一个我们能快速辨别他们的名字。也就是 Prefix（前缀）。当然，可以给 Instance 加 Prefix，那么也可以给 Net 加 Prefix\ne.g.:\nsetOptMode -addInstancePrefix \u0026#34;PRECTS_\u0026#34; -addNetPrefix \u0026#34;PRECTS_NET_\u0026#34; -powerEffort {none|low|high}\n-maxDensity -maxLength setTieHiLoMode\n这条命令本身只是去控制那些加的 Tie-high 和 Tie-low 的 Cell，也就是说在电路中某些地方电平需要拉高和拉低，就需要 专门的 Cell 去做这些连接。\n-maxFanout 2 ，就是设置一个 Tie cell 可以连接几个 Fanout。若设置的太大，可能出现的问题：需要拉高的时候拉不高，需要拉低的时候拉不低。若是设置的太小，可能导致 Tie Cell 最后局部的 density 会出现问题。 -honorDontTouch true ，就是设置为 honorDontTouch 的情况下到底要不要加 Tie，一般加的 DontTouch 都是工程师自己加的，也就是真的不希望动的地方，所以设置为 true -honorDontUse true，同上一样，是工程师真的不需要用到的，所以设置为 true。 -prefix “PRECTS_TIE_” , 给加的 Tie cell 加一个 Prefix（前缀）。便于识别。 -cell {TIEHI TIELO} 就是指定我们需要加的 Tie Cell 的类型 setNanoRouteMode\n这里的绕线是 global route\n-routeWithTimingDriven -true 也就是告诉工具在绕线的时候考虑时序。 group_path, setPathGroupOptions\n-effortLevel 对不同的 path group 的关注不一样，如此处，我们 关心 reg2reg，所以把 reg2reg 的 effortLevel 设置为 high set_dont_use_cells\n一般用于优化 PPA 的时候, 把一些面积大的, 功耗大的删掉\nset_clock_uncertainty\nset_clock_uncertainty 150 [all_clocks] -setup\nplace : jitter + clock skew + route correlation (si) + extra margin clock : jitter + route correlation (si) + extra margin route : jitter + extra margin signoff : jitter + extra margin set_max_transition\n一般可以按照 clock_cycle 的比例来定，对 clock 上面的 transition 一般定为 5%-8%，对 data 上面的 transition 一般定为 15%-20%\n库里面也有一些关于 max_transition 的限制, 但是往往比较宽松, 需要自己设置\n-clock_path xxx [all_clocks]\n-data_path xxx [all_clocks]\n-override, 覆盖其他地方的关于 max_transition 的设置\nplace_opt_design\n使用 GigaPlace 进行布局优化\n-expanded_views 就是告诉工具不要做 view 的 merge\n-out_dir 就是告诉工具输出的 path 放在哪个地方\n-prefix ”innovus_placeopt“\n6_CTS # set_ccopt_property\n查看 clk_buffer 种类：get_lib_cell *CLK*BUF*，一般不选 hvt buffer_cells clock_gating_cells use_inverters effort max_fanout target_skew target_max_trans target_insertion_delay route_type use_estimated_routes_during_final_implementation add_ndr\nNDR:(Non-Default Rule)\nclock 上的 route 需要和 standard cell 上的不一样，需要更大的间距。。。\nccopt_design\n7_cts_opt # optDesign -expandedViews -setup -hold -drv -outDir \u0026quot;myreports/${current_step}/innovus_clockopt\u0026quot; -postCTS -prefix \u0026quot;innovus_clockopt\u0026quot;\n8_route # 优化 # 优化目标 # 时序(Performance)\n设计规则(DRV): transition(slew)/cap/wire length setup / hold /recovery/ removal /other 噪声: Sl violation 功耗(Power):\nleakage/internal/switching 面积(Area): total standard cell area\nDFM: 电迁移(EM)\ninnovus 优化流程 # 有些公司不做 postCTS_opt, 应为还没有进行真实的布线，RC 延时估算不准，尤其是对 hold 来说。\n做关于 hold 的优化是很有限的，基本上只有插入 buffer 和调整 size，CTS 之后基本不会将存在的 buffer 删掉，因此一般没什么优化\n在 placement 就存在的 vio 很难在后面的优化中去掉\n文件名称 # GDSII： # 它是用来描述掩模几何图形的事实标准，是二进制格式，内容包括层和几何图形的基本组成。\nCIF： # （caltech intermediate format）, 叫 caltech 中介格式，是另一种基本文本的掩模描述语言。\nLEF： # （library exchange format）, 叫库交换格式，它是描述库单元的物理属性，包括端口位置、层定义和通孔定义。它抽象了单元的底层几何细节，提供了足够的信息，以便允许布线器在不对内部单元约束来进行修订的基础上进行单元连接。\n包含了工艺的技术信息，如布线的层数、最小的线宽、线与线之间的最小距离以及每个被选用 cell，BLOCK，PAD 的大小和 pin 的实际位置。 cell，PAD 的这些信息由厂家提供的 LEF 文件给出，自己定制的 BLOCK 的 LEF 文件描述经 ABSTRACT 后生成，只要把这两个 LEF 文件整合起来就可以了。\nLayer： pitch: track 之间的最小距离 offset：track 到边缘的最小距离 area：一块金属的最小面积 SPACINGTABLE: Standard cell # DEF： # （design exchange format），叫设计交换格式，它描述的是 实际的设计，对库单元及它们的位置和连接关系进行了列表，使用 DEF 来在不同的设计系统间传递设计，同时又可以保持设计的内容不变。DEF 与只传递几何信息的 GDSII 不一样。它还给出了器件的物理位置关系和时序限制等信息。\n主要包含如下内容:\n版本和设计名称\n单位和数据库设置\n设计组件（Components）\n引脚（Pins）\n网表（Nets）\n轨道（Tracks）和 GCell 网格\n区域（Regions）和楼层规划（Floorplanning）区域\n组（Groups）和组约束\nVIAs\n特殊网表（Special Nets）\n属性（Properties）\n一个实例:\nVERSION 5.8 ;\rDIVIDERCHAR \u0026#34;/\u0026#34; ;\rBUSBITCHARS \u0026#34;[]\u0026#34; ;\rDESIGN my_chip_design ;\rUNITS DISTANCE MICRONS 1000 ;\rDIEAREA ( 0 0 ) ( 100000 100000 ) ;\r// Components\rCOMPONENTS 300 ;\r- comp1 cell1 + PLACED ( 10000 10000 ) N ;\r- comp2 cell2 + PLACED ( 20000 20000 ) N ;\r...\rEND COMPONENTS\r// Pins\rPINS 50 ;\r- pin1 + NET net1 + DIRECTION INPUT + USE SIGNAL\r+ PORT\r+ LAYER metal1 ( 0 0 ) ( 100 100 )\r+ PLACED ( 5000 5000 ) N ;\r...\rEND PINS\r// Nets\rNETS 200 ;\r- net1\r+ ROUTED\r+ metal1 ( 10000 10000 ) ( 15000 15000 )\r+ VIA via1 ( 15000 15000 )\r+ metal2 ( 15000 15000 ) ( 20000 20000 ) ;\r...\rEND NETS\r// Tracks and GCells Grid\rTRACKS\r...\rEND TRACKS\rGCELLGRID\r...\rEND GCELLGRID\r// Regions and Floorplan\rREGIONS\r...\rEND REGIONS\r// Groups and Constraints\rGROUPS\r...\rEND GROUPS\r// VIAs\rVIAS 10 ;\r- via1\r+ RECT metal1 ( -5 -5 ) ( 5 5 )\r+ RECT via ( -5 -5 ) ( 5 5 )\r+ RECT metal2 ( -5 -5 ) ( 5 5 ) ;\r...\rEND VIAS\r// Special Nets\rSPECIALNETS\r...\rEND SPECIALNETS\r// Properties\rPROPERTYDEFINITIONS\r...\rEND PROPERTYDEFINITIONS\rEND DESIGN 相关指令\ndefin\ndefout\n[def 文件的作用及相关操作_.def 文件-CSDN 博客]( https://blog.csdn.net/NCG951204/article/details/126570067#:~:text=defin ：加载一)\nLib: # 命名规则：\n​\tlib 文件\n​\tcell：\n文本格式: .lib 文件通常是文本文件，使用人类可读的 ASCII 文本来描述。 标准化: .lib 文件使用的是 Liberty 格式，这是一个业界标准，用于描述电子电路库的性能。 可携带性和可读性: 由于它是一个文本文件，所以很容易通过文本编辑器查看和修改，并且容易在不同的设计工具和平台之间转移。 用途: Liberty 文件主要用于逻辑合成和静态时序分析（STA）。它包含有关单元（如门、触发器等）的时序和功耗特性 SDF： # (Standard delay format), 叫标准延时格式，是 IEEE 标准，它描述设计中的时序信息，指明了模块管脚和管脚之间的延迟、时钟到数据的延迟和内部连接延迟。\nDSPF、RSPF、SBPF 和 SPEF： # DSPF（detailed standard parasitic format）, 叫详细标准寄生格式，属于 CADENCE 公司的文件格式。\nRSPF（reduced standard parasitic format）, 叫精简标准寄生格式，属于 CADENCE 公司的文件格式。\nSBPF（synopsys binary parasitic format）, 叫新思科技二进制寄生格式，属于 SYNOPSYS 公司的文件格式。\nSPEF（standard parasitic exchange format）, 叫标准寄生交换格式，属于 IEEE 国际标准文件格式。\n以上四种文件格式都是从网表中提取出来的表示 RC 值信息，是在提取工具与时序验证工具之间传递 RC 信息的文件格式。\nALF： # (Advanved library format), 叫先进库格式，是一种用于描述基本库单元的格式。它包含电性能参数。\nPDEF： # （physical design exchange format）叫物理设计交换格式。它是 SYNOPSYS 公司用在前端和后端工具之间传递信息的文件格式。描述了与单元层次分组相关的互连信息。这种文件格式只有在使用 SYNOPSYS 公司的 Physical Compiler 工具才会用到，而且.13 以下工艺基本都会用到该工具。\nTLF # TLF 文件是描述 cell 时序的文件，标准单元的 rise time，hold time，fall time 都在 TLF 内定义。时序分析时就调用 TLF 文件，根据 cell 的输入信号强度和 cell 的负载来计算 cell 的各种时序信息。\nGCF # GCF 文件包括 TLF/CTLF 文件的路径，以及综合时序、面积等约束条件。在布局布线前，GCF 文件将设计者对电路的时序要求提供给 SE。这些信息将在时序驱动布局布线以及静态时序分析中被调用。\ninstall # 环境：ubuntu20.04, innovus20\n安装包： innovus20_install\n依赖 # sudo apt-get -y install openjdk-11-jdk sudo apt-get install ksh sudo apt-get install csh sudo apt-get install xterm sudo add-apt-repository ppa:linuxuprising/libpng12 sudo apt update sudo apt install libpng12-0 sudo apt install libjpeg62 sudo apt install libncurses5 1.进入 官网 下载 Xbin.tgz 这个文件\n解压 # #解压3个innovus20压缩包 #InstallScape是一个安装cadence软件的工具，解压以后进入03.InstallScape/iscape/bin/ sh iscape.sh 安装 # 等待，弹出终端选 no，然后回车结束\n破解 # #在crack文件夹中 ./1patch.sh /your/install/path python cdslicgen.py #生成license.dat cp patch/license.dat /path/you/want/to/place/License/ #把license放到一个你要放的位置 cdslicgen.py 破解改动在这里，我只是发现了别人的脚本在这里会报错，改了一点：\n环境变量 # 根据你的安装路径和 license 路径对应修改\n# \u0026gt;\u0026gt;\u0026gt; innovus initialize \u0026gt;\u0026gt;\u0026gt; export INNOVUS_HOME=/opt/EDA_Tools/cadence/innovus20 # license export LM_LICENSE_FILE=${INNOVUS_HOME}/License/license.dat export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${INNOVUS_HOME}/tools.lnx86/lib/64bit:${INNOVUS_HOME}/tools.lnx86 export PATH=${PATH}:${INNOVUS_HOME}/tools.lnx86/bin # \u0026lt;\u0026lt;\u0026lt; innovus initialize \u0026lt;\u0026lt;\u0026lt; 大致结束 # innovus \u0026amp; 其他相关 bug # 1.libstdc++.so.6\n[Cadence Innovus2020 在 Ubuntu20.04 上的安装教程【超详细】_innovus 安装-CSDN 博客]( https://blog.csdn.net/qq_44447544/article/details/122698979?ops_request_misc =%7B%22request%5Fid%22%3A%22A2277519-6B4E-4DD3-952A-1958A9EA40EA%22%2C%22scm%22%3A%2220140713.130102334..%22%7D\u0026amp;request_id = A2277519-6B4E-4DD3-952A-1958A9EA40EA\u0026amp;biz_id = 0\u0026amp;utm_medium = distribute.pc_search_result.none-task-blog-2alltop_click~default-2-122698979-null-null.142^v100^control\u0026amp;utm_term = innovus 安装\u0026amp;spm = 1018.2226.3001.4187)\nsudo ln -s /lib/x86_64-linux-gnu/libstdc++.so.6.0.30 libstdc++.so.6\n2.No LSB modules are available.\nsudo apt-get install lsb-core\n3.place_opt_design 后\nterminate called after throwing an instance of \u0026#39;std::runtime_error\u0026#39;\rwhat(): locale::facet::_S_create_c_locale name not valid\rInnovus terminated by internal (ABORT) error/signal...\r*** Stack trace:\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x12f9ffe5]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(syStackTrace+0xa5)[0x12fa0456]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4aa5ef3]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15goSignalHandler13executeActionEiP7siginfoPv+0x47)[0x7c97667]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15goSignalHandler16executeSigActionEiP7siginfoPv+0x84)[0x7c98494]\r/lib/x86_64-linux-gnu/libc.so.6(+0x4251f)[0x7f2653c1951f]\r/lib/x86_64-linux-gnu/libc.so.6(pthread_kill+0x12c)[0x7f2653c6d9fc]\r/lib/x86_64-linux-gnu/libc.so.6(raise+0x15)[0x7f2653c19475]\r/lib/x86_64-linux-gnu/libc.so.6(abort+0xd2)[0x7f2653bff7f2]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(+0xa2b9d)[0x7f265ac76b9d]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(+0xae20b)[0x7f265ac8220b]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZSt9terminatev+0x16)[0x7f265ac82276]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(__cxa_throw+0x47)[0x7f265ac824d7]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZSt21__throw_runtime_errorPKc+0x3f)[0x7f265ac7951c]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6locale5facet18_S_create_c_localeERP15_ _locale_structPKcS2_+0x27)[0x7f265aca5257]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6locale5_ImplC2EPKcm+0x54)[0x7f265ac96d04]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libstdc++.so.6(_ZNSt6localeC1EPKc+0x144)[0x7f265ac978e4]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK11oiInstCntCL5printERKSsb+0x2a)[0x7490eaa]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN15oiPhyDesignMcCL6createERK22oiPhyDesignGridParamCLiib+0x290)[0x74948e0]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z17oiPhyInitDesignMci+0x22)[0x7495112]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4d546fb]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN10tcmBaseCmd7executeEP10Tcl_InterpiPPc+0x166)[0x15264886]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN6tcmMgr9cmdParserEPvP10Tcl_InterpiPPc+0x693)[0x15257fe3]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclInvokeStringCommand+0x7f)[0x20ed56df]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20edc527]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_EvalEx+0x15)[0x20edce55]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_Eval+0x14)[0x20edce74]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN5oiTcl9CmdInterp6evalOKEPKc+0x2d)[0x4d87a8d]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK14rdaOptDesignCL3runEv+0x9c3)[0x4d2b543]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4d4da81]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN10tcmBaseCmd7executeEP10Tcl_InterpiPPc+0x166)[0x15264886]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN6tcmMgr9cmdParserEPvP10Tcl_InterpiPPc+0xad2)[0x15258422]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclInvokeStringCommand+0x7f)[0x20ed56df]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20edc527]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_EvalEx+0x15)[0x20edce55]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNREvalObjEx+0x6e)[0x20edcefe]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20f9270a]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20ef0150]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(TclNRRunCallbacks+0x46)[0x20eda056]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_RecordAndEvalObj+0xf3)[0x20f78753]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_RecordAndEval+0x37)[0x20f788b7]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z17rdaEditCmdLineEndPc+0x344)[0x4b68f44]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN9seConsole7sesMode9DoExecuteERKSsPv+0xc6)[0xfb3bc66]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline9EmacsMode10AcceptLineEv+0x3b)[0x10cac8eb]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline11ModeCommandINS_9EmacsModeEE15CommandFnNoKeysERKN5boost8functionIFvRS1_EEERNS_6EditorE+0x60)[0x10cb4e70]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN5boost6detail8function26void_function_obj_invoker2INS_3_bi6bind_tINS3_11unspecifiedENS_8functionIFvRN7Redline6EditorEEEENS3_5list1INS_3argILi1EEEEEEEvS9_RKNS7_14KeyCombinationEE6invokeERNS1_15function_bufferES9_SJ_+0x1a)[0x10cc46ca]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZNK7Redline7Command3RunERNS_6EditorERKNS_14KeyCombinationE+0x1b)[0x10cc43eb]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_ZN7Redline6Editor9Internals3RunEb+0xdf)[0x10ca8f0f]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x20fdce36]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_ServiceEvent+0x86)[0x20f9e886]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_DoOneEvent+0x128)[0x20f9eb88]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libtq.so(_ZN17TqEventDispatcher13processEventsE6QFlagsIN10QEventLoop17ProcessEventsFlagEE+0x69)[0x7f265741b239]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/Qt/v5//64bit/lib/libcdsQt5Core.so.5(_ZN10QEventLoop4execE6QFlagsINS_17ProcessEventsFlagEE+0xe9)[0x7f2656ad00c9]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/Qt/v5//64bit/lib/libcdsQt5Core.so.5(_ZN16QCoreApplication4execEv+0x83)[0x7f2656ad8953]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/lib/64bit/libtq.so(_ZN13TqApplication4execEv+0x176)[0x7f265741a896]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(_Z12edi_app_initP10Tcl_Interp+0x2a8)[0x4b510d8]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(Tcl_MainEx+0x176)[0x20f993c6]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus(main+0x1d1)[0x41d4b71]\r/lib/x86_64-linux-gnu/libc.so.6(+0x29d8f)[0x7f2653c00d8f]\r/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x7f)[0x7f2653c00e3f]\r/opt/EDA_Tools/cadence/innovus20/tools.lnx86/innovus/bin/64bit/innovus [0x4aa2c1c]\r==== ==== ==== ==== ==== ==== ==== ==== ==== ====\rgdb\r==== ==== ==== ==== ==== ==== ==== ==== ==== ====\rUsing: gdb\rCould not attach to process. If your uid matches the uid of the target\rprocess, check the setting of /proc/sys/kernel/yama/ptrace_scope, or try\ragain as the root user. For more details, see /etc/sysctl.d/10-ptrace.conf\rptrace: Operation not permitted.\r/home/pengxuan/Project/mylab/innovus/lab2/work/1314912: No such file or directory. 参考 # Cadence Innovus2020 在Ubuntu20.04上的安装教程【超详细】_innovus安装-CSDN博客\ninnovus2020安装_innovus安装-CSDN博客\nUbuntu18.04安装Cadence Innovus2021_innovus安装-CSDN博客\n参考 # 官方文档：UserGuide, Command reference\nOpenROAD/ORFS/OpenLane # 特点 # 优点 # 开源，可以自定义修改\n该领域的热门应用\n作者回复迅速（一般第二天就会回复）\n自动化程度较高\n还在不断更新中，更新快\n缺点 # 有一些商用工具有的功能他没有 relation between openroad/SRFS/openlane # openroad # basic model netlist2gds, 也可以hdl2gds，但是比较麻烦， 用abc做综合 越来越流行了，比赛也开始用了 ORFS # hdl2gds pdk friendly， 可以直接跑7nm 支持重新编译OpenROAD（自定义修改） gui不知道为什么用起来很卡 内置AutoTuner，一个扫参自动优化PPA的工具 支持在线使用（Colab） openlance # hdl2gds most auto 内置只有sky130 PDK 不支持重新编译OpenROAD Architecture # openlane\nOpenLane Flow Stages # OpenLane flow consists of several stages. By default all flow steps are run in sequence. Each stage may consist of multiple sub-stages. OpenLane can also be run interactively as shown [here][25].\nSynthesis Yosys - Perform RTL synthesis and technology mapping. OpenSTA - Performs static timing analysis on the resulting netlist to generate timing reports Floorplaning OpenROAD/Initialize Floorplan - Defines the core area for the macro as well as the rows (used for placement) and the tracks (used for routing) OpenLane IO Placer - Places the macro input and output ports OpenROAD/PDN Generator - Generates the power distribution network OpenROAD/Tapcell - Inserts welltap and endcap cells in the floorplan Placement OpenROAD/RePlace - Performs global placement OpenROAD/Resizer - Performs optional optimizations on the design OpenROAD/OpenDP - Performs detailed placement to legalize the globally placed components CTS OpenROAD/TritonCTS - Synthesizes the clock distribution network (the clock tree) Routing OpenROAD/FastRoute - Performs global routing to generate a guide file for the detailed router OpenROAD/TritonRoute - Performs detailed routing OpenROAD/OpenRCX - Performs SPEF extraction Tapeout Magic - Streams out the final GDSII layout file from the routed def KLayout - Streams out the final GDSII layout file from the routed def as a back-up Signoff Magic - Performs DRC Checks \u0026amp; Antenna Checks Magic - Performs DRC Checks \u0026amp; an XOR sanity-check between the two generated GDS-II files Netgen - Performs LVS Checks All tools in the OpenLane flow are free, libre and open-source software. While OpenLane itself as a script (and its associated build scripts) are under the Apache License, version 2.0, tools may fall under stricter licenses.\nEverything in Floorplanning through Routing is done using OpenROAD and its various sub-utilities, hence the name “OpenLane.”\nPDK # The OpenROAD application is PDK independent. However, it has been tested and validated with specific PDKs in the context of various flow controllers.\nOpenLane supports SkyWater 130nm and GlobalFoundries 180nm.\nOpenROAD-flow-scripts supports several public and private PDKs including:\nOpen-Source PDKs # GF180 - 180nm SKY130 - 130nm Nangate45 - 45nm ASAP7 - Predictive FinFET 7nm Proprietary PDKs # These PDKS are supported in OpenROAD-flow-scripts only. They are used to test and calibrate OpenROAD against commercial platforms and ensure good QoR. The PDKs and platform-specific files for these kits cannot be provided due to NDA restrictions. However, if you are able to access these platforms independently, you can create the necessary platform-specific files yourself.\nGF55 - 55nm GF12 - 12nm Intel22 - 22nm Intel16 - 16nm TSMC65 - 65nm Basic Run # openroad [-help] [-version] [-no_init] [-exit] [-gui] [-threads count|max] [-log file_name] cmd_file -help show help and exit -version show version and exit -no_init do not read .openroad init file -threads count|max use count threads -no_splash do not show the license splash at startup -exit exit after reading cmd_file -gui start in gui mode -python start with python interpreter [limited to db operations] -log \u0026lt;file_name\u0026gt; write a log in \u0026lt;file_name\u0026gt; cmd_file source cmd_file OpenROAD sources the Tcl command file ~/.openroad unless the command line option -no_init is specified.\nOpenROAD then sources the command file cmd_file if it is specified on the command line. Unless the -exit command line flag is specified, it enters an interactive Tcl command interpreter.\nA list of the available tools/modules included in the OpenROAD app and their descriptions are available here.\nBasic Command # area # ord::get_die_area ord::get_core_area\nSave Image # # This command can be both be used when the GUI is active and not active to save a screenshot with various options.\nsave_image [-resolution microns_per_pixel] [-area {x0 y0 x1 y1}] [-width width] [-display_option {option value}] filename Options # Switch Name Description filename path to save the image to. -area x0, y0 - first corner of the layout area (in microns) to be saved, default is to save what is visible on the screen unless called when gui is not active and then it selected the whole block. x1, y1 - second corner of the layout area (in microns) to be saved, default is to save what is visible on the screen unless called when gui is not active and then it selected the whole block. -resolution resolution in microns per pixel to use when saving the image, default will match what the GUI has selected. -width width of the output image in pixels, default will be computed from the resolution. Cannot be used with -resolution. -display_option specific setting for a display option to show or hide specific elements. For example, to hide metal1 -display_option {Layers/metal1 false}, to show routing tracks -display_option {Tracks/Pref true}, or to show everthing -display_option {* true} Select Objects # This command selects object based on options. Returns: number of objects selected.\nselect -type object_type\r[-name glob_pattern]\r[-filter attribute = value]\r[-case_insensitive]\r[-highlight group] Options # Switch Name Description -type name of the object type. For example, Inst for instances, Net for nets, and Marker for database markers. -name (optional) filter selection by the specified name. For example, to only select clk nets *clk*. Use -case_insensitive to filter based on case insensitive instead of case sensitive. -filter (optional) filter selection based on the objects’ properties. attribute represents the property’s name and value the property’s value. In case the property holds a collection (e. g. BTerms in a Net) or a table (e. g. Layers in a Generate Via Rule) value can be any element within those. A special case exists for checking whether a collection is empty or not by using the value CONNECTED. This can be useful to select a specific group of elements (e. g. BTerms=CONNECTED will select only Nets connected to Input/Output Pins). -highlight (optional) add the selection to the specific highlighting group. Values can be 0 to 7. Add a single net to selection # To add a single net to the selected items:\ngui:: selection_add_net name Options # Switch Name Description name name of the net to add. Add multiple nets to selection # To add several nets to the selected items using a regex:\ngui:: selection_add_nets name_regex Options # Switch Name Description name_regex regular expression of the net names to add. Add a single inst to selection # To add a single instance to the selected items:\ngui:: selection_add_inst name Options # Switch Name Description name name of the instance to add. Add multiple insts to selection # To add several instances to the selected items using a regex:\ngui:: selection_add_insts name_regex Options # Switch Name Description name_regex regular expression of the instance names to add. Select at point or area # To add items at a specific point or in an area:\nExample usage:\ngui:: select_at x y\rgui:: select_at x y append\rgui:: select_at x0 y0 x1 y1\rgui:: select_at x0 y0 x1 y1 append gui:: select_at x0 y0 x1 y1\r[append]\rOr\rgui:: select_at\rx y [append] Options # Switch Name Description x, y point in the layout area in microns. x0, y0, x1, y1 first and second corner of the layout area in microns. append if true (the default value) append the new selections to the current selection list, else replace the selection list with the new selections. Select next item from selection # To navigate through multiple selected items: Returns: current index of the selected item.\ngui:: select_next Select previous item from selection # To navigate through multiple selected items: Returns: current index of the selected item.\ngui:: select_previous Clear Selection # To clear the current set of selected items:\ngui:: clear_selections Set Heatmap # To control the settings in the heat maps:\nThe currently availble heat maps are:\nPower Routing Placement IRDrop RUDY [ 1] These options can also be modified in the GUI by double-clicking the underlined display control for the heat map.\ngui:: set_heatmap name\r[option]\r[value] Options # Switch Name Description name is the name of the heatmap. option is the name of the option to modify. If option is rebuild the map will be destroyed and rebuilt. value is the new value for the specified option. This is not used when rebuilding map. Dump Heatmap to file # To save the raw data from the heat maps ins a comma separated value (CSV) format:\ngui:: dump_heatmap name filename Options # Switch Name Description name is the name of the heatmap. filename path to the file to write the data to. init # floorplant # placement # Routing # globle routing # Write Guides # This command writes global routing guides, which can be used as input for global routing.\nExample: write_guides route.guide.\nwrite_guides file_name Options # Switch Name Description file_name Guide file name. report and dump # Write Macro Placement # This command writes macro placement.\nwrite_macro_placement file_name Global Routing - FastRoute4.1 # OpenROAD/src/grt at master · The-OpenROAD-Project/OpenROAD\nSwitch Name Description -guide_file Set the output guides file name (e.g., route.guide). -congestion_iterations Set the number of iterations made to remove the overflow of the routing. The default value is 50, and the allowed values are integers [0, MAX_INT]. -congestion_report_file Set the file name to save the congestion report. The file generated can be read by the DRC viewer in the GUI (e.g., report_file.rpt). -congestion_report_iter_step Set the number of iterations to report. The default value is 0, and the allowed values are integers [0, MAX_INT]. -grid_origin Set the (x, y) origin of the routing grid in DBU. For example, -grid_origin {1 1} corresponds to the die (0, 0) + 1 DBU in each x\u0026ndash;, y- direction. -critical_nets_percentage Set the percentage of nets with the worst slack value that are considered timing critical, having preference over other nets during congestion iterations (e.g. -critical_nets_percentage 30). The default value is 0, and the allowed values are integers [0, MAX_INT]. -allow_congestion Allow global routing results to be generated with remaining congestion. The default is false. -verbose This flag enables the full reporting of the global routing. -start_incremental This flag initializes the GRT listener to get the net modified. The default is false. -end_incremental This flag run incremental GRT with the nets modified. The default is false. Using Macro in openlane # debug in openroad # make as follow # cd OpenROAD mkdir build_debug cd build_debug cmake .. -DCMAKE_BUILD_TYPE=DEBUG #wait make #make -j $thread_to_make my lancun.json # {\r\u0026#34;configurations\u0026#34;: [\r{\r\u0026#34;name\u0026#34;: \u0026#34;(gdb) Launch\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;cppdbg\u0026#34;,\r\u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;,\r\u0026#34;program\u0026#34;: \u0026#34;/you/path/OpenROAD/build_debug/src/openroad\u0026#34;,\r\u0026#34;args\u0026#34;: [],\r\u0026#34;stopAtEntry\u0026#34;: false,\r\u0026#34;cwd\u0026#34;: \u0026#34;/you/path/OpenROAD-flow-scripts/tools/OpenROAD/build_debug/src/\u0026#34;,\r\u0026#34;environment\u0026#34;: [],\r\u0026#34;externalConsole\u0026#34;: false,\r\u0026#34;MIMode\u0026#34;: \u0026#34;gdb\u0026#34;,\r\u0026#34;setupCommands\u0026#34;: [\r{\r\u0026#34;description\u0026#34;: \u0026#34;Enable pretty-printing for gdb\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;-enable-pretty-printing\u0026#34;,\r\u0026#34;ignoreFailures\u0026#34;: true\r},\r{\r\u0026#34;description\u0026#34;: \u0026#34;Set Disassembly Flavor to Intel\u0026#34;,\r\u0026#34;text\u0026#34;: \u0026#34;-gdb-set disassembly-flavor intel\u0026#34;,\r\u0026#34;ignoreFailures\u0026#34;: true\r}\r]\r}\r]\r} after add your breakpoints, click the triangle to debug and you have to wait a minutes then you can input you command to debug openroad in terminal I just found out how to do that too, holp this help.\ninstall # Installing OpenROAD — OpenROAD documentation\n#在ubuntu:20.04新的docker容器中\rapt update\rapt-get update --fix-missing\rapt install git\rgit clone --recursive https://github.com/The-OpenROAD-Project/OpenROAD.git\rcd OpenROAD/\r./etc/DependencyInstaller.sh\rcd build/\rmake\rmake install\ropenroad -help install in a new ubuntu20.04 container\n现在openroad中安装依赖，再直接build ORFS\nBuild from sources using Docker — OpenROAD Flow documentation\napt install swig apt-get install libboost-all-dev a bug:\nIgn:1 https://download.docker.com/linux/ubuntu focal InRelease\nErr:2 https://download.docker.com/linux/ubuntu focal Release\nCould not handshake: Error in the pull function. [IP: 13.35.210.84 443]\nHit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\nHit:4 http://archive.ubuntu.com/ubuntu focal InRelease\nHit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\nHit:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nReading package lists\u0026hellip; Done\nE: The repository \u0026lsquo; https://download.docker.com/linux/ubuntu focal Release\u0026rsquo; no longer has a Release file.\nN: Updating from such a repository can\u0026rsquo;t be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nbuild in docker, not in locally 开源工具 # openroad，openlane rtl-dgs全流程\nALIGN2（“模拟布局，从网表智能生成”）\nGlobal Router:\nNCTUGR 2.0: can generate precise congestion maps\nFastRoute1 [ICCAD 06]:\nFastRoute2 :\nFastRoute3 :\nFastRoute4 :\nLabyrinth [TCAD 2002] :\nChi Dispersion router [DAC 2003] :\n数据集 # openroad 也有一些数据集?\n比如:\nCircuitNet:\n在某些应用中，基于 GNN 的解决方案仍然没有达到完全的准确性。这可以使用 GNN 的结果作为进一步后处理步骤的输入来解决，如 GANA [30] 中那样。然而，我们希望未来的工作能够扩大训练数据和特征集以提高准确性，正如 GRANNITE [71] 中所提出的那样。更大的数据集将启用更深层次的模型，这可以转化为更好的结果。对于数据集生成，我们期望更多地使用开源 EDA 工具和技术。一个开放和标准的数据收集基础设施将最大限度地减少图形构建、映射和标记工作。此外，它将增强对 GNN 和 EDA 的研究，并实现研究结果比较和基准测试。\nChipyard\nOpencores\nPDK # DK即Process Design Kit 工艺设计包，是连接IC设计公司、代工厂和EDA公司的桥梁. PDK包含了从芯片设计到制造的各个环节所需的数据和信息，为了更直观地了解它，我们可以将PDK比作芯片设计过程中的“指导手册”\nPDK的主要作用是将晶圆代工厂的制造工艺要求转化为芯片设计师能够理解的信息。设计师利用PDK中的数据来确保他们的设计能够顺利制造，并将PDK导入到EDA软件中，进行设计、模拟和验证。一旦完成设计，设计师就可以将设计文件发送给晶圆代工厂进行生产。\nA Process Design Kit (PDK) serves as the fundamental building block for integrated circuit (IC) design, playing a crucial role in transforming chip designs into silicon reality. These files serve as essential inputs for Electronic Design Automation (EDA) tools during chip design. Clients engage with a foundry\u0026rsquo;s PDKs before production to ensure that their chip designs align with the foundry\u0026rsquo;s capabilities and intended functionality.EDA Tool Ecosystem and PDK Integration. These tools rely on accurate PDK data to generate layouts, verify designs, and simulate performance. Standardized interfaces across diverse technology platforms enhance PDK usability.\n内容 # 生态 # 上游到下游\n开源PDK # sky130 # GF180 # FreePDK45 # nangate45 # FreePDK45 是北卡罗来纳州立大学的电子设计自动化实验室提供的免费开源的45nm工艺库，使用了MOSIS工艺\nIHP Open Source PDK # ASAP7 # 7nm Predictive PDK\nASAP5 # 5nm\nThe-OpenROAD-Project/asap5\n貌似还用不了\n参考 # DesignAutomationConference_SFO_2024\n"},{"id":12,"href":"/zh/docs/Digtal/flow/notebak/EDA+GNN/","title":"Eda Gnn","section":"Physical design","content":" Survey # Background \u0026amp; Intro # 只有在物理验证和签名(sign off)以及测试期间，才能衡量设计在功率、性能和面积 (PPA) 方面的质量。通常需要在中间步骤中进行纠正修改，这会导致设计的多次迭代。因此，在设计的早期阶段对 PPA 的估计将减少所需的迭代次数，增加设计的可靠性，同时深入研究flow，并最终提高结果质量 (QoR)\nNP-complete # EDA 工具通常面临 NP-complete 问题，机器学习 (ML) 方法可以更好更快地解决这些问题\nNP问题是一类可以通过非确定性图灵机( Non-deterministic Turing Machine)在多项式时间(Polynomial time)内解决的决策问题集合。\nNP问题中最困难的问题称之为NP完全问题(NP-complete)\nML # ML 已集成到 EDA 中，尤其是逻辑综合、布局、布线、测试和验证 [23] ML 用于预测传统方法的最佳配置。其次，ML 学习模型的特征及其性能来预测看不见的设计的行为，而无需运行昂贵的综合步骤。此外，在优化 PPA 的同时，可以通过 ML 进行设计空间探索。最后，强化学习 (RL) 探索设计空间、学习策略并执行转换，以通过“人工智能辅助设计流程”获得展望未来的最佳设计。 在 EDA 中使用 ML 的一个促成因素是 EDA 工具在设计过程中生成的大量数据。 欧几里得数据\nEDA # flow # 逻辑综合 # 逻辑综合将 HDL 中的 RTL 块映射到从给定技术库中选择的门组合，同时针对不同目标优化设计。通常，这种优化涉及时序收敛、面积和功耗之间的权衡。\n描述硬件设计的 RTL 模块被映射到技术库中的逻辑单元。此映射必须满足时序约束，以在所需时钟速率下运行，同时考虑面积和功耗。因此，综合是一个可以应用 ML 的复杂优化问题。例如，提供更早的 QoR 预测以避免耗时的合成步骤的多次运行\nD-SAGE [55]\n物理综合 # 主要步骤\n布局规划 # 在芯片布局规划中，网表的主要块和较大块被放置在二维网格上，以实现最佳 PPA，同时遵守设计规则。这可以表示为马尔可夫过程，可以使用 RL 来解决。\n（Edge-GNN）[44]。在 [44] 中，将 GNN 合并到 RL 框架中以对过程的不同状态进行编码，预测拥塞、密度和线路长度的奖励标签，并推广到未见的网表。它计算整个网表的节点和边缘嵌入。此 RL 代理提供与人类设计师相当或更好的结果，但需要数小时而不是数月。\n布局 # 设计门被映射到芯片布局的确切位置。设计越大，这个过程就越复杂。放置期间的错误决定会增加芯片面积，但也会降低芯片性能，如果导线长度高于可用布线资源，甚至会使其不适合制造。通常，需要多次放置迭代，这是耗时且计算效率低下的。因此，布局被视为一个约束优化问题。正在探索 ML，尤其是 GNN，以简化此步骤\n[61] 中提供预置网络和路径长度估计。为此，他们将网表转换为有向图，其中网络代表节点，边在两个方向上连接网络。单元数、扇入、扇出大小和面积用作特征节点。使用聚类和分区结果定义边缘特征。节点的真实标签是放置后作为边界框的半周线长度获得的净长度。\n在 [38、39] 中，GraphSAGE 被用来构建 PL-GNN\n[2] 中介绍了将 EDA 中的 PPA 优化任务映射到 RL 问题的概念验证框架。这个 RL 框架使用 GraphSAGE 和无监督训练来学习可以推广到看不见的网表的节点和边缘嵌入。 GCN 是一个关键组件，因为它提取 RL 代理所需的本地和全局信息。作为研究案例，分析了 2-D 放置期间的线长度优化。\n​ 在 [1] 中，自主 RL 代理以归纳方式找到最佳放置参数。网表被映射为有向图，节点和边特征是手工制作的与放置相关的属性。 GraphSAGE 学习网表嵌入并有助于推广到新设计。\n时钟插入 # 布线 # 在 [29] 中，GAT 仅使用在物理设计后获得的特定技术门级网表来预测路由拥塞值。为此，将网表构建为无向图，其中每个门都是一个节点，边定义为通过网络连接的门之间的连接。特征节点是 50 维向量，包含有关单元类型、大小、引脚数和逻辑描述的信息。为了获得节点的真实标签，拥塞图被分成网格，每个网格的拥塞值被作为放置在该网格中的单元格的标签。 [29] 中提出的称为 CongestionNet 的架构不超过遵循公式 4 的八层 GAT。节点嵌入用于预测局部拥塞值。使用 GAT 可以提高预测质量，对于超过 100 万个单元的电路，推理时间约为 19 秒。“单V100 GPU上训练为60小时”\n在 [37] 中，提出了一个端到端框架，使用基于 GNN 的长短期记忆 (LSTM) 架构来预测端口路由 TNS\n[9] 中，提出了两个 RL 框架来优化布局（DeepPlace）和布局布线一起优化（DeepPR）\n验证和签收 # 制造 # 制造、封装和最终测试\n挑战 # (1) 它依赖于硬件设计人员的专业知识来选择合适的 EDA 工具配置，\n(2) RTL 的设计空间探索，逻辑综合和物理综合是手动的，因此是有限且耗时的，\n(3) 设计中的更正将重新初始化流程，\n(4) 没有早期分析或结果的可预测性\nGraphs # 处理图结构数据的方法 # 传统浅嵌入方法 # 旨在将节点信息分解为低维嵌入向量，考虑图中节点的位置和邻域的结构[17]。最著名的图嵌入技术之一是 Random Walk [36]。在这种技术中，给定图中的起点，随机选择一个相邻点。作为第二步，再次选择随机选择的点的邻居。这是以递归方式完成的。这会生成一个随机的点序列，即随机游走。 DeepWalk [45] 和 Node2vec [16] 是众所周知的基于随机游走的图嵌入方法。\n缺点 # 他们的编码器将重要信息从图中映射到嵌入空间，优化每个节点的唯一嵌入向量。这在大图中的计算/统计上可能是昂贵的。\n它们是转导的，即它们只能为训练期间看到的节点生成嵌入。这是一个主要缺点，因为该模型无法推广到看不见的节点。\n他们没有考虑在编码过程中可以提供宝贵信息的节点特征。\n其他神经网络 (NN)缺点 # 例如 CNN，如果不将其结构映射到固定大小的向量格式，就无法直接对图形数据进行操作。首先，图没有固定的局部性或滑动窗口概念来执行卷积操作。其次，图没有固定的节点顺序。作用在图上的操作应该对节点排序或排列保持不变。\nGNN # 由于考虑了特征和拓扑信息，GNN 已被证明优于其他 ML 模型\n[14] 中引入了一种称为 GNN\n直接在图上运行的神经网络框架\nGNN 由置换不变函数和置换等变函数组成，因此也可以在节点粒度上运行。?\nGNN 旨在学习每个节点的嵌入向量\n消息传递策略已被 GNN 的新颖架构继承\nGNN # 两篇开创性论文 [25, 41] 强调了 EDA 任务和 GNN 之间的重要联系。 [41] 中的研究首次认识到 GNN 在 EDA 中的巨大潜力。他们表示，图形结构是表示布尔函数、网表和布局的最直观方式，这些是 EDA 流程的主要关注点。他们将 GNN 视为 EDA 改进 QoR 并取代使用的传统浅层方法或数学优化技术的机会\nGNNs for the Digital EDA Flow # 类型 # Recurrent Graph Neural Networks（RecGNNs） # 通过假设节点与其邻居交换信息直到达到稳定点来循环处理节点信息\nConvolutional Graph Neural Networks # 卷积图神经网络 (ConvGNN) 旨在通过堆叠多个图卷积层来学习嵌入向量。与共享权重的 RecGNN 不同，ConvGNN 每层使用不同的权重。 ConvGNN 是 CNN 对图形数据的泛化，分为光谱和空间方法 [60]：\nGCN属于这种\nGraph Autoencoders（GAE） # 图自动编码器 (GAE) [60] 属于无监督框架家族，因为训练数据没有真实标签。因此，计算的损失取决于整个图的拓扑信息，包括节点和边缘特征[58]。\n用于两种类型的任务：基于图的表示学习和图生成\n[28] 中提出的最常用的 GAE 之一中，GCN 被用作编码器来提取图嵌入。\nSpatial-Temporal Graph Neural Networks (STGNN) # 许多实际应用中，输入图的结构会随时间发生变化，即矩阵 A 和 X 沿时间轴变化。使用时空图的一个例子是计算机视觉领域的动作识别问题[63]。\nGNN 的设计流程 # Graph Definition # 定义每个节点或边缘的特征向量。\nTask Definition # 基于要解决的问题，定义任务的粒度和监督设置。 GNN 的任务分为三个级别：节点级别、边级别和图级别\n我们以不同的方式训练模型：监督，如果所有节点都被标记；半监督，如果只知道一些标签；和无监督的，当没有标签可用时 [60]。\n目标任务和监督设置共同决定了训练期间要使用的损失函数。例如，节点级监督回归任务需要均方误差 (MSE) 函数作为训练集中所有节点的损失函数。在节点级半监督分类任务的情况下，交叉熵损失可用于少数提供的标记节点。？\nModel Definition # 在 [72] 中，GNN 模型被定义为堆叠计算模块的概要\n三种不同类型的模块：传播、采样和池化。\n传播模块在保留特征和拓扑信息的节点之间传播和聚合信息。由残差神经网络（ResNets）[21] 激发的跳跃连接机制也被认为是一个传播模块。\n采样：在 GNN 中，一个节点的信息被聚合到其上一层邻居的信息中。因此，深度 GNN 会导致需要考虑和聚合的邻居呈指数增长。采样模块减轻了邻居爆炸。采样粒度可以是节点、层和子采样级别。在节点级别，通过考虑每个节点的固定数量的邻居来限制邻域大小。在层级，每层只考虑固定数量的节点进行聚合。最后，子图级采样将邻域搜索限制为采样子图[72]。 池化：池化层驱动的池化模块在减小图的大小的同时获得更一般的特征。 定向池化，也称为读出或全局池化，它对节点特征应用节点操作以获得图级表示；和分层池化，它遵循分层模式并按层学习图表示[72]。\nGNN优点 # 基于 GNN 的架构优于其他模型和解决方案。上面列出的工作将他们的结果与浅层 ML、深度学习方法或特定任务的基线进行了比较。毫无疑问，GNN 的优越性是由于对拓扑和特征信息的考虑，这是以构建训练数据集的更大努力和更高的训练时间为代价的\nML对比 # shallow ML # [42] 中，基于 GNN 的模型解决方案优于用于二元分类的经典 ML 技术，例如线性回归器 (LR)、支持向量机 (SVM)、随机森林和 MLP。与商业工业工具相比，它在不丢失故障覆盖率的情况下，插入的测试点减少了 11%，测试模式帐户减少了 6%。 GNN-RE [4] 中，将基于 GNN 的模型与使用每个节点相同特征向量的监督分类任务的 SVM 进行比较。但是，根据定义，SVM 只考虑单个节点的特征，不能访问邻居节点的特征。 SVM 的训练时间几乎是 GNN-RE [4] 的 10 倍。然而，分类指标清楚地表明了 GNN 的优越性。 ParaGraph [46] 与 XGBoost [6] 和 LR 模型以及普通 GraphSAGE 进行了比较。预测准确率平均为 77%，比 XGBoost 好 110%，比 GraphSAGE 好 7%。 deep ML # D-SAGE [55] 与 MLP 和 vanilla GraphSAGE 进行了比较。**基于 GNN 的模型优于 MLP，强调结构信息与操作映射的相关性。**此外，由于边缘方向信息，D-SAGE [55] 相对于 GraphSAGE 获得了 17% 的相对增益。 定制的 ABGNN [22] 在输入和输出边界分类任务方面都优于普通 GraphSAGE、GAT 和图同构网络 (GIN) [62]，同时推理时间分别减少了 19.8% 和 18.0%。与使用电平相关衰减和 (LDDS)-存在向量 (EV) 来表示电路拓扑 [11] 的 NN 相比，ABGNN [22] 的性能也更高且运行时间更低 [49] 中，Circuit Designer [59] 与非基于图的 RL 架构进行了比较。不同的实验表明了 GCN-RL 的优越性，它在非基于图的 RL 永远不会收敛的情况下收敛，即使有非常多的模拟步骤。 Circuit Designer [59] 的成功也归功于考虑线性晶体管参数的明确特征向量 Compared to task-specific baselines. # GNN 的优势与两个因素有关：定义明确的初始特征和图学习能力 [39]。**定义明确的特征捕捉任务的基本特征，并为图学习提供宝贵的信息。 GNN 捕获特征和拓扑信息。**这与仅考虑图形连通性的方法相比，它具有明显的优势。\n在 PL-GNN [39] 中，与层次相关的特征用于学习哪些节点相似，而与记忆相关的特征有助于平衡关键路径。 PL-GNN [39] 优于基于模块化的聚类，后者仅使用连接信息\nCongestionNet [29] 的先验拥塞估计性能优于基线方法 29%，而对于较低层的拥塞估计则优于 75%。尽管如此，CongestionNet [29] 训练需要在单个 GPU 上进行 60 小时。在推理期间，130 万个单元的运行时间减少到 19 秒，少于基线方法的运行时间。\nEdge-GNN [44] 与开源全局布局工具 RePLAce3 [8] 和使用行业标准 EDA 工具的手动布局的结果进行了比较。在训练超过 10000 个芯片 loorplans 之后，Edge-GNN [44] 优于这两种方法，平均给出更低或相当的最差负松弛、总面积、功率和拥塞\nModels Depth # GNN 模型的层数是一个超参数。添加过多的层会使输出嵌入变得平滑并降低端到端任务的准确性。因此，更深层次的模型需要更大的数据集 [64]。！\nChallenges # 鲁棒性 # 可解释性 # 预训练 # 复杂图类型 # GNNs in EDA Challenges # 从 EDA 的角度来看，在将 GNN 应用于设计流程时，尤其是图形的可扩展性和多样性 [41] 时，先前的挑战会加剧。在 EDA 中，输入图代表不同抽象级别的电路网表，通常具有非常大的尺寸。大图会导致巨大的稀疏邻接矩阵和非常大的节点列表，其计算耗时且计算量大。！\n与简单的无向图或有向图相比，EDA 对象在直觉上更类似于复杂的图类型。直观地，电路网表是有向超图或异构图，为了与这些图类型相结合，应该制定新的 GNN 架构，如 [22, 55] 中所做的那样。为 EDA 对象定制 GNN 架构并提高其处理复杂图形类型的性能仍然是一个开放的研究课题。\n数据生成仍然是一个开放的挑战\nFuture Work # Exploiting Transfer Learning # ​ CongestionNet [29] 等应用程序与技术无关，即它们根据所使用的技术构建具有特征向量和标签的数据集。对于针对新工艺技术的实验，应重新构建数据集并重新训练模型。我们期望未来的 EDA 应用程序评估 GNN 的迁移学习技术的使用，例如 [19、32、44、59] 中已经完成的。例如，GCN-RL Circuit Designer [59] 受益于 RL 的可转移性，并利用它在 5 个不同的技术节点和拓扑之间进行知识转移。\nExploiting Feature Information # GNN 的一个成功因素是定义明确的特征向量。因此，我们相信未来的研究将评估不同的特征节点，以提高当前解决方案对更先进技术和复杂任务的可扩展性和泛化性。\n例如，当前的 Circuit Designer 实施仅使用线性晶体管参数作为特征。未来的工作应该涵盖非线性特征以支持非线性组件类型。\n在 [29] 中，进行了消融研究以确定特征对 CongestionNet 预测的重要性。因此，与cell类型或功能相关的特征比与cell几何形状相关的特征更重要。因此，未来的工作建议包括新的特征，如引脚和边缘类型。\n此外，他们建议使用有向图或超图而不是无向图。\nEnlarging Datasets # 开源工具 # 1https://github.com/The-OpenROAD-Project\n2https://github.com/ALIGN-analoglayout/ALIGN-public\nOpenROAD 和 ALIGN 都没有开始探索 GNN 的使用\n参考 # 【阅读】A Comprehensive Survey on Electronic Design Automation and Graph Neural Networks——EDA+GNN综述翻译_ppaml-CSDN博客\n"},{"id":13,"href":"/zh/docs/Digtal/Placement/placement/","title":"Placement","section":"Physical design","content":" 介绍 # Placement # 良好的布局会带来更好的芯片面积利用率、时序性能和可达性，而较差的布局会影响芯片的性能，甚至使其无法制造\n布局可以看作是具有几何约束的二维装箱问题的一个更为复杂的变化。后者被认为是 NP-hard 问题。\n布局与电路设计的逻辑互连和逻辑元件的几何位置有关。由于在布线之前无法准确评估放置解决方案的质量，导致设计流程中的反馈循环很长，因此现代布局需要在早期阶段减少布线拥塞(Congestion)并提高可达性(Routebility)\nWL估计方法 # Global Placement # 通常，全局布局（Global Placement）涉及宏布局（Macro Placement）和标准单元布局（Standard Cell Placement）。\n输入:网表\n优化目标:HPWL线长最小(最基本)…\nDetail Placement # 详细布局（Detailed Placement）包括合法化（legalization），线长（wirelength）和可达性的细化（routability refinement）\nhistory # 参考 # 2021-Place-YuBei-slice.pdf "},{"id":14,"href":"/zh/docs/Digtal/Routing/global-router/congestion/%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E9%A2%84%E8%B7%AF%E7%94%B1%E6%8B%A5%E5%A1%9E%E9%A2%84%E6%B5%8B%E7%A0%94%E7%A9%B6/","title":"基于图神经网络的预路由拥塞预测研究","section":"Physical design","content":"基于图神经网络的EDA预路由拥塞预测研究\n课题描述:\n​\t近年来随着数字芯片使用越来越小的工艺制程和芯片内包含越来越多的逻辑单元，使其设计更新迭代优化的难度越来越大。由于数字后端中的布局(Placement)布线(路由, Route)流程属于是NP-Hard的算法优化问题，EDA(Electronic Design Automation)工具在这一阶段往往及其费时，导致更长的物理设计周期。\n​\t在数字电路优化过程中，布线拥塞是用于物理设计过程迭代优化的重要指标。某些区域的布线密度过高，导致无法继续进行有效的布线，进而导致时序与设计规则违例等问题。为此，许多现代综合与布局工具利用拥塞数据，以尽量减少最终物理设计中的拥塞影响。通过布线的拥塞数据，布局布线工具将相应地优化相关的可移动单元位置，以减少线长度、拥塞和违例，进行迭代，直到收敛，从而产生更优的布线结果。精确的拥塞预测在电路布线中起着至关重要的作用，不幸的是，直到设计周期的后期，也就是缓慢的布局和布线流程，精确的拥塞结果才被准确地知道。\n​\t这启发我们设计一个跨设计阶段(Cross-stage)的拥塞预测方法，在设计初期进行布局布线优化，从而加速优化迭代流程。多个先前的工作尝试在利用布局数据预测详细路由(Detail Route)拥塞，以优化放置解决方案的可达性，如：RUDY、GTL、POLAR 2.0等。这些基于专家经验的方法往往预测精度较低。近年来，随着图神经网络(Graph Neural Network, GNN)在学习图结构和挖掘图信息方面展示出了卓越的效果。由于电路结构可以自然地表示为图，图神经网络在电子设计自动化领域受到了越来越多的关注。GNN 模型可以端到端的方式学习全局指标而无需额外的特征工程比传统深度学习方法更高的准确度。\n​\t因此，本课题将设计实现基于图神经网络的EDA预路由拥塞预测任务，给定电路布局结果，或仅仅根据电路网表内容，实现对布线后的拥塞结果预测。\n内容\n学习DeepLearning框架(Pytorch/Tensorflow)的使用, 环境的搭建, 图神经网络模型(GNN, Graph Neural Network)的搭建，综述调研 学习并掌握一款工具的使用(OpenROAD(推荐)/Candance/Innovus). 并且利用工具获取相关数据集 学习与复现相关论文，基于所学内容设计基于GNN的预路由拥塞预测架构, 实现拥塞预测. 设计创新点, 改进模型性能, 实现结果分析, 结果可视化, 模型对比实验(精度/推理速度/内存占用等), 消融实验等. 参考资料以及说明\n图神经网络相关算法详述及实现:一个GNN教程\nRUDY：Fast and Accurate Routing Demand Estimation for Efficient Routability-driven Placement ：一个基于布局结果的快速路由拥塞估计器\nGTL:Detecting tangled logic structures in VLSI netlists: 一种基于图结构直接从网表中估计拥塞的方法\nPOLAR 2.0: An effective routability-driven placer：一个基于拥塞预测与可达性的布局工具\n华南理工大学图书馆数据库：可免费下载各大国内外期刊文章\nGoogle Scholar: 一个学术论文搜索引擎\nConnected Papers | Find and explore academic papers: 一个基于图相关性论文搜索引擎\nAwesome AI for EDA：EDA研究中现有AI方向的高质量高影响力论文列表网站\n基于图神经网络的电子设计自动化技术研究进展：一篇关于GNN在EDA方面应用的综述文章\nCongestionNet: Routing Congestion Prediction Using Deep Graph Neural Networks ：一种基于GNN和综合后网表数据预测路由拥塞的方法\nGeneralizable Cross-Graph Embedding for GNN-based Congestion Prediction:一种基于GNN和综合后网表数据预测路由拥塞的方法\nPin Accessibility and Routing Congestion Aware DRC Hotspot Prediction using Graph Neural Network and U-Net :一种基于GNN和CNN和布线数据预测DRV的方法\nLHNN | Proceedings of the 59th ACM/IEEE Design Automation Conference:一种基于GNN和布线数据预测拥塞的方法\nThe OpenROAD Project：一个开源RTL-to-GDS项目， 特点: 开源软件, 易于安装与使用, 内置可以直接使用的开源PDK.\nOpenCores：一个开源数字网关IP核的参考社区，可提取HDL文件使用数字后端设计工具实现自定义数据提取\nISPD 2011 Routability-driven Placement Contest and Benchmark Suite：ISPD举办的布局器比赛，内有数据集可参考\nDAC 2012 Routability-Driven Placement Contest一个DAC举办的布局器比赛，内有数据集可参考\n基于项目”chacha“的拥塞示例数据\nEDA三巨头整套虚拟机:太大了无法上传，需要的话发邮箱到：icpengxuan@mail.scut.edu.cn\nAnwar-Said/Circuit-Completion-Using-GNNs: Source code and datasets for Circuit Design Completion using GNNs paper:一个开源代码\nycchen218/EDA-Congestion-Prediction: This is a deep-learning based model for Electronic Design Automation(EDA), predicting the congestion location.：一个开源代码\nCircuitNet: 一个开源数据集，内置开源代码\nAccurate Prediction of Detailed Routing Congestion using Supervised Data Learning：一篇相关论文。。。\n相关知识与术语:\n图神经网络(GNN)：一种基于具有不规则结构图结构的深度学习模型。最基础的图卷积模型是GCN(相当于图结构的CNN)。\n数字后端: 以前端综合后的网表(.v文件)、工艺库PDK和一些约束文件(如.sdc文件等)作为输入, 经过布图、布局、时钟树综合、布线与验证后输出可用于流片的.gds(Graphic Data System)版图文件的流程\n布局：确定电路中各个组件在芯片中的物理位置。由于在布线之前无法准确评估放置解决方案的质量，导致设计流程中的反馈循环很长，因此现代布局需要在早期阶段减少布线拥塞(Congestion)并提高可达性(Routability)\n预路由(pre-routing): 布线阶段前的数字设计阶段。\n拥塞：在芯片设计或者FPGA设计中，硬件资源可分为逻辑资源和布线资源，当设计工程较大或较复杂时，可能逻辑资源仍然在合理范围内，但是布线资源却超出固有资源或者较为不合理。这时候可能会产生congestion（拥塞）问题，也就是布线资源紧张导致的。\n拥塞图(congestion map): 版图中使用网格(grid)用于标识路由需求超过路由容量的区域。布局工具(Placer)将相应地优化相关的可移动单元位置，以减少线长度和拥塞，并迭代地重复上述循环，直到收敛，从而产生放置解\nRUDY (Rectangular Uniform wire DensitY): 是基于布局结果的快速路由拥塞估计器。它假设网线在其包围框内均匀分布。速度快但是精度低。\nDRVs (design rule violations) :设计规则违规。这些违规是指在集成电路的版图设计过程中，经过DRC(Design Rule Check)违反了特定的设计规则而导致的潜在问题。设计规则是由代工厂针对特定工艺制定的一系列强制性要求，它们综合考虑了电学性能和可靠性限制，并按照芯片加工过程所需的一系列限制来制定。\nshift-left: 指的是将测试和验证活动提前到开发周期的更早阶段，以便更早地发现和修复缺陷。EDA的一大研究方向就是cross-stage prediction：通过早期流程数据对预测后期结果数据，减少工作迭代次数， 实现效率提升。\nG-cells ：是电路上放置单元的矩形单元。是总体布线过程中的基本布线单元\nG-nets：表示引脚之间以G-cells为路径单元的连线\n"},{"id":15,"href":"/zh/docs/Digtal/Routing/global-router/ISPD_2024_contest/ISPD-NTUEE-main/ISPD24_contest-main/","title":"Index","section":"Physical design","content":" ISPD24 Contest: GPU/ML-Enhanced Large Scale Global Routing # Contest Introduction # Global routing is a critical component of the VLSI design process, exerting a substantial influence on circuit timing, power consumption, and overall routability. The efficiency of global routing is of paramount importance, as a swift and scalable approach can guide optimizations in early design stages like floor-planning and placement.\nOver the past decade, GPU accelerated computing platforms have been evolving into highly versatile and programmable systems capable of delivering immense parallel computing power. Recent studies have successfully leveraged GPUs to achieve over a 10x acceleration in global routing without compromising performance. Furthermore, machine learning (ML) techniques have been integrated into the global routing process, leading to enhanced routing solution quality.\nThe goal of this competition is to stimulate academic research aimed at developing a GPU/ML-enhanced global router tailored for industrial-level circuits. Notably, contemporary VLSI circuits often encompass tens of millions of cells, which is a significant departure from past global routing competitions that typically dealt with scenarios involving no more than 1 million cells. Due to the limitations of current routers, hierarchical or partitioning-based methods are commonly employed to manage large circuits, albeit at the risk of sacrificing a certain degree of optimality. It is of great importance to develop a scalable global router capable of handling circuits with tens of millions of cells, as it can greatly inform optimizations in the early design stages, such as floor-planning and placement. By fostering enthusiasm and innovation within the global routing research community, this competition aims to deliver substantial reductions in global routing runtime for these expansive industrial-grade circuits, harnessing the computational power of GPUs and the potential of machine learning techniques. Simultaneously, it strives to enhance the overall quality of routing results.\nInput/Output Formats and Evaluation # To enable teams from diverse backgrounds to participate, we have extracted routing resource information and netlist data from LEF and DEF files and organized them in simplified formats. Consequently, participants can approach the contest as a mathematical optimization problem within the GCell grid graph. The desired outcome is global routing solutions described within the GCell grid graph. The evaluation process is centered on several key metrics, including total wirelength, via count and routing congestion of the global routing solution, as well as the execution runtime of the global router.\nPlease check Introduction of the contest for more details.\nSubmission Guidance # We expect teams to package their global routers into Docker images. And we will pull and execute these images on a NVIDIA platform equiped with 4 NVIDIA A100 GPUs.\nAnouncement # The evaluation platform is configured with CUDA version 11.7 and driver version 515.00. We have prepared a Dockerfile ( https://github.com/liangrj2014/ISPD24_contest/blob/main/Dockerfile) that will install deep learning toolkits compatible with the CUDA version on our evaluation platform. Generally, participants are welcome to modify the Dockerfile as necessary, ensuring compatibility with our evaluation platform for utilizing the GPUs on the system. - Dec 02, 2023. We\u0026rsquo;ve identified some bugs in our evaluation script (thanks to the participants for bringing them to our attention!). An updated version will be released shortly, addressing these bugs and significantly improving runtime speed. Stay tuned for the latest updates! - Nov 30, 2023. We\u0026rsquo;ve released example global routing solutions on Oct 28, 2023. We\u0026rsquo;ve released the evaluation scripts on Oct 28, 2023. To simplify the entry process for the competition, we\u0026rsquo;ve extracted routing resource information and netlist data from LEF and DEF files and stored them in simplified formats. As a result, participants can tackle the contest challenge as a mathematic optimization problem within the GCell grid graph. - Oct 28, 2023. Registration opens on Sep 13, 2023! Released the first set of benchmarks on Sep 13, 2023 Released the docker for environment setup on Sep 13, 2023 Registration # Please fill in this online registration form\nRegistration window: Sep 13, 2023 - Dec 1, 2023\nWe confirm that we\u0026rsquo;ve received the registrations forms from the following teams. Please feel free to send us an email if we overlooked your registration forms or any related information.\nID Team Name Affiliation 1 Mamta Unknown 2 NianNianYouYu Fudan University 3 Binghamton Binghamton University 4 NTHU-TCLAB-GR National Tsing Hua University 5 Alpha-Team AlphaCHIP LLC; National Research University of Electronic Technology 6 HumbleRoute University of South Florida; CMR Institute of Technology 7 automl-for-global-routing Texas A\u0026amp;M University 8 Lira Unknown 9 SCAW Sun Yat-sen University; Institute of Computing, Chinese Academy of Sciences 10 TeamSD Unknown 11 NTUSTGR National Taiwan University of Science and Technology 12 SmartRoute University of Science and Technology of China 13 metaRoute Fudan University 14 IWantNvidia Unknown 15 GRFirExp University of Science and Technology of China 16 DIAG University of Science and Technology of China 17 Santhosh Unknown 18 VCISEDA Beijing University of Posts and Telecommunications 19 Puipui Nara Institute of Science and Technology 20 Team-XJWIN Xi\u0026rsquo;an Jiaotong University 21 Route 99 Tsinghua University; University of Science and Technology Beijing 22 Team California University of California , Santa Cruz 24 AnxietyAttack University of Peradeniya 25 fzu _team Unknown 26 Jack\u0026rsquo;s team Unknown 27 iEDA-iRT Institute of Computing Technology; Chinese Academy of Sciences; Shenzhen University; Peng Cheng Laboratory 28 GGRouter Pohang University of Science and Technology 29 NTUEE+ National Taiwan University 30 color Chinese University of Hong Kong 31 NNU_FZUTeam Nanjing Normal University; Fuzhou University 32 NYCU_GR Unknown 33 NTUEDA National Taiwan University 34 FZU_MathGR Fuzhou University 35 RL-Route The Chinese University of Hong Kong 36 HustForest Huazhong University of Science and Technology 37 ZJ Unknown 38 Marvin Indian Institute of Technology Madras 39 Tiger Unknown 40 NJUFZUglobalrouter Nanjing Normal University 41 GoToRoute Fuzhou University 42 NYCU-VDA-GR National Yang Ming Chiao Tung University 43 Kate Scientific research institute for system analysis of Russian Academy of Sciences 44 SEU-Router Southeast University 45 Easy_Router Unknown 46 etuoReL Fudan University 47 PY-Router Unknown 48 PampaRouting Universidade Federal do Rio Grande do Sul 49 Team Ondru Indian Institute of Technology Madras 50 XianBaoMing National Tsing Hua University 51 EA University of Calgary 52 CUEDA The Chinese University of Hong Kong Important Dates # Registration Open: Sep 13, 2023 Registration Close: Dec 1, 2023 Alpha Submission: Jan 5, 2024 Beta Submission: Feb, 2, 2024 Final Submission: Mar, 1, 2024 Results Anouncement: March 15, 2024 Downloads # Introduction of the contest First set of benchmarks with Nangate45 technology node Please note that all the essential input information for global routing is contained within the .cap files and .net files located in the \u0026ldquo;Simple_inputs\u0026rdquo; folder. We also release the LEF/DEF files of the circuits just for reference. Evaluation Scripts Example global routing solutions Dockerfile for environment setup Note that the Dockerfile has been updated on Dec 02, 2023. Q\u0026amp;A # Please post your questions in GitHub Issues Contact # Email：ispd2024contest@gmail.com Contest Prizes # 1st place: $1000 + one NVIDIA GPU of similar value 2nd place: $500 + one NVIDIA GPU of similar value 3rd place: $250 + one NVIDIA GPU of similar value Sponsor # Sponsored by NVIDIA "},{"id":16,"href":"/zh/docs/Digtal/Routing/global-router/ISPD_2024_contest/ISPD-NTUEE-main/README/","title":"Readme","section":"Physical design","content":" ISPD-NTUEE # "},{"id":17,"href":"/zh/docs/Digtal/Routing/routing/","title":"Routing","section":"Physical design","content":" 介绍 # 随着IP复用，业界一度试图使用IP内部资源进行布线，但此举可能引发噪声和转换电压过大，因此绕障策略在布线算法中发挥着重要的作用。\n曼哈顿结构以及非曼哈顿结构 # 总体布线的布线算法主要基于曼哈顿结构以及非曼哈顿结构两种，非曼哈顿结构因其更强的布线优化能力受到越来越多研究人员的关注。布线互连结构可分为曼哈顿结构和非曼哈顿结构。曼哈顿结构的布线方向只能是水平走线和垂直走线两种,而非曼哈顿结构的布线方向则更为多样化,主要包括走线方向为 **0°、90°和士45°**的X结构以及走线方向为 0°、60°和 120°的Y结构。随着系统级芯片(System-on-a-Chip,SoC)设计概念的出现和制造工艺的不断发展,**互连线的延迟对 VLSI设计的影响越来越大,同时互连线的不断增长会降低芯片的速度,造成过高的功耗以及增大噪声,**这要求更有效的互连线线长优化和更强的电路性能。但基于曼哈顿结构的相关物理设计阶段在优化互连线线长时限制了相关策略的优化能力。为优化芯片的整体性能,相关研究人员开始尝试基于非曼哈顿结构的布线。\n非曼哈顿结构的数学基础是λ-几何学理论\n(1)当λ=2时,布线的方向为ix/2,走线方向包括 0°和 90°,对应传统的曼哈顿结构,亦称为直角结构。 (2)当λ=3时,布线的方向为 iπ/3,走线方向包括 0°、60°和120°,称为Y结构。 (3)当λ=4时,布线的方向为 i/4,走线方向包括0°、90°和士45°,称为X结构。已经得到工艺支持\n意义 # 物理设计过程是EDA的主要处理对象，是人工最易出错的\n当前,超大规模集成电路(Very Large Scale Integration Circuit,VLSI)设计在许多高科技电子电路的发展中起着至关重要的作用。当前集成电路(IntegratedCircuit,IC)产业向超深亚微米工艺不断推进,芯片的集成度进一步提高,一块芯片上所能集成的电路元件越来越多,VLSI是将数百万个品体管集成到单个芯片中形成 IC 的过程。这一市场趋势对**物理设计(Physical Design,PD)和物理验证(Physical Verification,PV)**提出了许多挑战。以 VLSI为基础的电子信息产业的发展,对我国国民经济的发展、产业技术创新能力的提高以及现代国防建设都具有极其重要的意义。\n物理设计是VLSI构建流程中最为耗时的,其设计好坏将影响芯片的最终性能,包括时延特性,电能消耗、电路稳定性等。\n近年来 ，集成电路领域发展越来越迅猛 ，晶体管数量随集成电路制造⼯艺发展逐年增加 ，芯片内包含的逻辑门数量急剧提升 ，这给集成电路设计带来了巨大的难题。由于超大规模集成电路（very-largescale integration circuit，VLSI）逻辑的高度复杂性 ，其物理设计往往需要使用计算机辅助设计⼯具来完成。这就向电子设计自动化（electronic design automation，EDA）⼯具提出了严峻挑战\n在物理设计过程中 ，布线是极其重要的一环 。布线⼯作占据了 EDA 过程的大部分时间 ，甚至在大部分情况下 ，自动布线的结果还需要设计人员在后期手⼯调整。具备优秀的布线速度及高布线质量的布线器对缩短芯片设计周期有着至关重要的作用 。\n布线 # 在物理设计中需要采用电路划分方法将复杂庞大的电路系统分解至合理小的电路子系统;其次,在电路划分后,布图规划和布局步骤则是将不同形状和大小的单元或模块合理地放置到芯片的不同布线区域,同时满足芯片固有的一些相关几何约束;再次,布局阶段确定模块和引脚各自的位置,在此基础上经总体布线后,将每条待绕线的线网的各部分合理分配到芯片中的各个布线通道区;最后,由详细布线得到各个布线通道区的实际绕线。\n模型输入输出 # 输入 # cell, pin\u0026rsquo;s position netlist graph(connection relation) 设计工艺：多少层，via几何形状信息，各种drc 部分关键线网延时信息 wire和via的电气特性 输出 # 一个尽可能满足约束条件并更少得需要人⼯调整线网的布线结果\n网表内各线网的连接⽅式 ，包含金属线及通孔的几何描述信息\n约束 # 线网连接正确性 布线障碍 :指布线过程中被占用的区域，包括逻辑单元及芯片版图中的布线障碍 ，以及部分已布线网 ，如电源线网和时钟线网等 版图设计规则 :主要由制造⼯艺决定。制造厂商在制造过程中 ，为满足芯片最基本的可制造性 ，尽可能让芯片的设计可用 ，根据现有的制造技术设计了种种版图设计规则。设计规则违反（design rule checking violations，DRC）的数目很大程度上代表了布线质量的高低。 主要包含： 金属线的最小宽度（min-width）； 金属线间及金属线与布线障碍间的最小线间距（min-spacing）； 一条金属线的最小面积（min-area），当金属线的宽度固定为最小宽度时 ，最小面积约束也被称作最小长度约束 总体布线 # 又称概略布线,全局布线\n总体布线负责合理将每条线网的各部分分配到各个布线通道区中(也就是分配布线资源)并明确定义各布线问题\n总体布线的结果对详细布线的成功与否起到决定性作用,同时总体布线严重影响最后制造出来的芯片性能。\n一个经典图论问题\n整个芯片被分为多个区域 ，并将线网的连接关系对应到区域上 ，在区域间连线。由于全局布线不需要考虑版图设计 规则的约束 ，甚至不需要考虑大部分几何级问题 ，其布线模型的建模较为简单 ，即使在具有数以万计的区域的芯片版图上布线，也只产生较低的时间开销\n总体布线中首先将可布线区域划分成多个小格,每个格的布线资源使用带容量的边来表示,所有布线资源由一个网格图表示;再确定一个线网所占用网格图中的边,即线网的大致走线,将各线网合理地分配到各个网格中,以确保尽可能高的布通率。\n**总体布线图(Global Routing Graph, GRG)**将布线区域、每个区域内的布线容量、布线区域内的引脚信息以及不同布线区域之间的相互关系等信息抽象为一张图。不同的设计模式产生多种布线图模型,常见的布线图模型主要包括网格图模型、布线规划图模型以及通道相交图模型\n即使是最简单的问题,如一组两引脚线网在拥塞约束下布线,也是一个NP 完全问题。\n全局布线的主要目标是为后续的详细布线提供指导 ，从而降低布线问题的复杂程度 ，减少整体的时间开销。作为整个布线任务中多种优化目标的主要影响因素 ，全局布线要在给定布线资源的情况下 ，优化线长、通孔数及关键线网时延等目标函数\n评价全局布线算法的主要指标有线长、通孔数、溢出数 量、运行时间\n布线图模型 # 网格图模型 # 一个顶点表示一个总体布线单元(Global Routing Cell,GRC),GRC之间的连接关系则由水平边和垂直边表示。\n对于给定的线网集合,则将它们的引脚集合按照其所在的总体布线单元,映射到该总体布线单元对应的顶点上\n每一个全局布线单元（GRC)被视作全局布线问题中的一个点 ，相邻近的单元所代表的点之间具备一条有容量的边 ，对应相邻单元间的边界 ，这条边的容量代表能穿过此边界的金属线的最大数目 。因此 ，可以通过各边的容量与穿过边的金属线数量估计全局布线的资源拥挤程度。\n布图规划图模型 # 通道相交图模型 # 算法 # 最早用于解决总体布线图上的最短路径问题的是1959年出现的Diikstra算法,该算法的时间复杂度为 O(n^2^)\n后来发展为迷宫系列算法，缺乏寻找最优解的能力，不适用VLSI\n多引脚网分解 # 多引脚线网分解常用于总体布线算法。具有两个以上引脚的线网通常被分解成两个引脚的子网,然后每个子网的点对点布线以某种串行方式执行。这种线网分解是在总体布线开始时执行的,这会影响最终布线结果的质量。许多总体布线都采用多引脚线网分解。分解多引脚线网的两种流行方法是RSMT构造和最小生成树(Minimum Spanning Tree,MST)构造。RSMT 通常提供较短线长的树状拓扑结构,而 MST 由于产生更多的工形双引脚线网而提供更大的灵活性。\n最小树算法 # Steiner 最小树算法 # 多端点线网的总体布线可定义成寻找 Steiner 树问题,精确算法、传统启发式算法、计算智能方法都可用于求解 Steiner 树。\n在VLSI总体布线问题中,多端线网的总体布线问题是寻找一棵连接给定引脚集合的布线树问题,而 Steiner 最小树相对于其他方法所得的布线树来说具有更小的布线树总线长。因此,Steiner最小树被看作总体布线问题中多端线网的最佳连接模型,并且在总体布线图上的Steiner 最小树算法是所有总体布线算法的基础。\n精确算法包括动态规划技术、拉格朗日松弛法、分支界限法等。虽然从理论上能够得到问题的精确解,但是问题规模越大,精确算法越难求解问题。继而研究工作开始转向启发式策略。遗传算法、蚁群算法、鱼群算法、粒子群优化算法等计算智能方法在求解 Steiner 问题中展示出了广阔的应用前景。\n近年来,随着计算能力的增强,加之高性能电路的设计需要,版图设计技术也将随之改进。出于增强电路的性能的目的,研究人员提出新型互连结构,即非曼哈顿互连结构,非曼哈顿结构 Steiner 树则应运而生。\n然而,精确算法受其复杂度限制不适用于求解非曼哈顿结构 Steiner 树这类NP难问题,而贪心策略致使传统启发式算法极易过早收敛。据所查找的资料文献中,目前将计算智能方法应用到求解该NP难问题的研究工作还较少。\n整数线性规划布线 # 慢\n拆线重步 # 在确定了一组线网的初始布线后,通常会发现一些布线资源被过度使用了。然后,现有的布线被拆开,重新分配到一个迭代修复框架中,这个框架被称为“拆线重布”。现代整数线性规划工具帮助基于整数线性规划的总体布线在数小时内成功完成数十万条布线。然而**,商业EDA 工具需要更大的可扩展性和更少的运行时间**。在布线阶段,如果一个线网无法布线,通常是由于物理障碍或其他布线线网占用了它的路径。核心思想是允许临时违规,直到所有线网都被布线。也就是说,迭代地拆开一些线网,并以不同的方式重新对它们布线,以减少违规的数量。如果一次只处理一个网,那么这个策略就是串行法,所以线网的串行处理对最终解的质量影响很大。 文献[31]对于每一个违规的线网定义了拆线重布的成功率,并且只对最有希望改进的线网重布线。然而**,若一个线网在没有违规的情况下不能布线,那么成功率需要重新计算。这是非常昂贵的,尤其是对于大规模的设计。**拆线重布通常与其他总体布线方法相结合,作为进一步提高布线质量的后处理步骤。\n协商拥塞布线 # 层分配问题 # 层分配在可布线性、时序性、串扰性和可制造性方面起着至关重要的作用。如果特定层分配的导线数量过多,则会加剧拥塞和串扰。此外,如果总体时序关键线网被分配到较低层,则时序由于导线宽度/间距较窄而恶化。差的层分配产生的大量通孔,其比线需要更大的面积和更宽的间距,进而导致可布线性/引脚访问问题。对于纳米设计,最小化通孔数量尤为重要,因为通孔故障是关键的可制造性问题之一。层分配是多层总体布线中的关键步骤,因为它将二维总体布线的结果映射到原始的多层解空间。现代集成电路或芯片通常是多层结构。在布线时,大多数布线器通常不会在三维空间中直接布线。相反,它们在二维平面上布线,然后通过层分配技术将二维布线结果恢复到三维空间。有些工作是基于动态规划实现的,此外,BoxRouter 2.0实现了一种复杂的线性规划技术,可以根据二维投影恢复三维布线,并根据三维布线结果优化二维布线器。**层分配的目标通常是保持二维总体布线的总溢出,然后最小化通孔数量。**在层分配中考虑天线效应,通过适当地将导线分配到较高的金属层(不一定是顶层),可以有效地减少天线违规\n一个k层的布线区域可以被划分为一大批的总体布线块并建模成为k层网格图G^k^(V^k^,E^k^)。其中k表示布线层的数量,V ^k^表示第k层网格总体布线单元的集合,E^k^表示第k层的网格布线边,其中每条边表示相邻布线块的边界。相邻层的连接边表示通孔。一条网格边的容量定义为可以经过相邻布线块的布线轨道数。\n层分配定义：\n串行和并行方法 # 串行 # 布线多个线网的最原始和最简单的策略是选择特定的顺序,然后按该顺序布线线网。这种方法的主要优点是:在布线当前线网时,可以知道并考虑前期布线线网的拥塞信息。例如,在将多引脚线网分解成两引脚线网的早期算法中,使用绕障迷宫布线或线路探测布线等方法来对每个线网布线。在这些方法中,单元边界对路径搜索开放,直到所有的路径都被先前考虑的线网占据。在这一点之后,边界被视为障碍。顺序法的缺点是解的质量很大程度上取决于线网的处理顺序,很难找到好的顺序。在任意特定的顺序下,由于过多拥塞,很难对后期的线网布线。\n此外,没有反馈机制允许这些线网将信息反馈给前期布线的线网,以便为后期布线的线网留下一些区域。文献[109]提到没有一种单一的线网排序方法始终表现良好。尽管对于线网的排序问题上存在争议,但在串行布线上已经有了一些很好的研究成果,主要是通过迭代循环将后期布线的线网的拥塞信息反馈给前期布线线网\n虽然串行方法、拆线重布以及其他启发式方法在实践中可能是有效的,但是它们不能提供关于是否存在可行解决方案的具体答案。换句话说,如果这些方法不能找到可行的解决方案,不清楚这是因为可行的解决方案不存在,还是因为启发式方法的缺点。另外,当启发式方法找到可行解时,不知道解是否最优,与最优解相差多远。？\n依据预先给定的线网顺序对线网进行布线,布线过程中先布线网会抢占后布线网的布线资源,不同的布线顺序可能会生成完全不同的布线结果。早期的一项研究指出,在布线开始之前找到一个最优布线顺序是NP难问题,且不存在一个在所有情况下都达到最优的布线顺序选取策略叨。对所有线网同时进行布线的同时布线算法可以避免线序对布线结果的影响。\n策略：\n按端点数量的升序布线。端点数量较多的线网往往会造成内部空间的拥塞。 按线长升序布线以降低容量溢出 ，提升可布性。线长较短的线网布线范围比较小 ，灵活性有限 ，而线长较长的线网则可以在更大范围内绕路 ，寻找更优解。 按线长降序布线以降低总体时延。优先布线长较长的线网 ，降低线长较长 的关键线网对总体时延的影响 ，以提升电路的总体性能。 依据预估的拥塞程度布线 ，优先对较为拥塞的区域内的线网进行布线 并行 # 在串行方法中,路径是根据预定的顺序一次生成的。串行方法是非常快速的，但由于它们的串行性质会导致次优解。并发方法试图利用总体优化方法来解决问题。这些方法可以提供电路布线的总体视图,但需要相当长的时间。从计算复杂性的角度来看,所有网络的并发布线是一个**复杂的问题。使用整数线性规划是实现这一目标的方法之一。**事实上,总体布线问题的数学模型可以修改为 0-1整数规划问题。线性规划由一组约束和可选目标函数组成。这个函数根据约束判断是最大还是最小。约束和目标函数都必须是线性的。这些约束形成了一个线性方程和线性不等式的系统。整数线性规划是一种特殊的线性规划,其中每个变量只能取整数值且都是二进制的,故称为0-1整数线性规划。\n基于并发方法的总体布线器包括对布线区域拥塞的评估,产生了高质量的布线。另外,舍弃可能处于拥堵区域的路径,以减小整数线性规划的输入规模。\n多商品流(multi-commodity flow，MCF)算法将布线问题看作是一个多商品流问题回,并将其建模成整数线性规划(integerlinear programming,ILP)问题进行求解。\n两端线网与多端线网 # 两端线网 # 迷宫布线算法 # 及其变体 A*算法：一般通过设计开销函数来躲避拥塞。开销函数的值往往在边界上穿过的金属线数量接近及超过边容量时迅速增大[9]，迷宫布线类算法具备着极其强大的拥塞避免能力 ，可以对单个线网给出质量极高的布线结果 ，但即使通过开销函数定向减小搜索空间 ，迷宫布线类算法仍然会产生较高的时间开销\n模式布线 # 使用预先设计的模式对两端线网进行布线 ，常用的模式有 L 型（1 拐点）、Z 型（2拐点）[10]与 U 型（2 拐点 ，绕路连线） 由 于路径的搜索空间远小于迷宫布线 ，模式布线类算 法具备极快的布线速度 ，但其布线结果相对较差 。对于跨越 m × n 网格的两端线网 ，L 型模式仅在两种布线⽅式中选取代价较低的一种 ，而 Z 型模式会考虑 m + n 种不同的布线⽅式。因此 ，Z/U 型模式避免拥塞的灵活性要远大于 L 型算法 ，但相应地 ，其单个线网的布线时间复杂度更高\n单调布线 # 随布线问题复杂度的上升 ，L/Z/U 型模式布线已经不能满足问题的需求 。，其布线路径单调地向右上 （ 左 下 ）或 左 上（ 右 下 ）搜 索 ，可 以 搜 索 到 (m + n - 2)!/ (m - 1)!(n - 1)! 种布线⽅式 ，且时间复 杂度与 Z 型相同 ，为 O (mn)，但由于其走线拐点较 多，其布线通孔数会增加。\n三拐点布线（3-bend routing）， # 其路径支持最多 3 个拐点 ，且可以绕路布线。三拐点布线同样使用 O (mn)的时间复杂度 ，具备与迷宫布线相近的拥塞避免能力 ，且由于其最多使用 3 个拐点，极大地减少了通孔数\n多端线网 # 很难直接使用迷宫布线或模式布线进行求解，主流的解决⽅法是最小斯坦纳树\nsteiner最小树算法 # 给定平面上的点Steiner 最小树通过一些 Steiner 点将这些点连接起来,以获得最小的总长度。\nSteiner 最小树(Steiner Minimum Tree,SMT)作为超大规模集成电路物理设计的基本模型之一,可以应用于布图规划、布局和布线阶段。\n作为一个标准的计算机问题，业界一般将布线问题代为Steiner最小树问题\nSteiner最小树问题是一个NP难问题\nSteiner 最小树通常用于物理设计中非关键线网的初始拓扑创建。最小化线长不是时序关键线网优化的唯一日标。然而,大多数线网在布线阶段是不重要的，Steiner 最小树给出了这种线网最理想的布线形式。因此,在布局规划和布局期间,Steiner 最小树通常被用来精确评估拥塞和线长。\n对单个线网的布线,是物理设计中的一个基础问题。无论是总体布线还是详细布线,都会用到线网布线。线网布线又根据线网引脚的个数分为两引脚线网布线和多引脚线网布线。考虑到布线长度最小化,两引脚线网布线在布线图中就转换为最短路径问题,而多引脚线网布线转换为直角 Steiner 最小树(RectilinearSteiner Minimal Tree,RSMT)问题\n拥塞图与拆线重布（rip-up and reroute) # 随着问题复杂度的上升 ，全局布线的布线资源越来越紧张 ，直接进行布线会发生大量无法避免的溢出\nFastRoute[9]使用 FLUTE 算法生成的 RSMT 计算出拥塞图 ，并依据此拥塞图重新构建 RSMT\n在拥塞图的初始化阶段 ，对所有两端线网分别进行拥塞程度计算。若两端点在水平或竖直⽅向具有相同的坐标 ，则直接将拥塞图上两端点间所有的边的拥塞程度加 1.0 。 否则 ，对于两⽅向上坐标都不相同的线网 ，计算其两种可能的 L 型连接⽅式 ，并将两种可能的路径上的边的拥塞程度都加 0.5\n拥塞图的初始化阶段过后 ，由于所有 L 型连接⽅式都在拥塞程度上平均分配 ，在拥塞程度较大的区域 ，拥塞程度可能会超过其容量。为了更好地规划拥塞图的拥塞分布 ，使用一个快速的拆线重布 ，依次将各 L 型连接的两端线网提供的拥塞程度去除后 ，选择拥塞程度更小的一条路径 ，并将此路径的拥塞程度加 1.0。\n拆线重布（rip-up and reroute）策略在初次布线完成后 ，对发生溢出的拥塞区域的线网进行拆除 ，并迭代地调整线序多次重新布线 ，直到溢出不再减少 ，或达到运行时间限制为止。\n一般来讲 ，在初始布线时使用模式布线 ，这样在大量简单线网上拥有极快的布线速度 ，在拆线重布阶段 ，使用迷宫布线类算法 ，或时间复杂度较高的模式布线算法 ，以尽可能地提升重布线网的灵活性 ，并减少溢出次数 ，从而在整体的运行速度和布线质量间取得平衡\n优化目标 # 主要是以减小通孔数量，还要考虑时延问题\n随着器件尺寸迅速缩小,互连延迟对芯片性能产生了至关重要的作用。因此，最小化线路长度和延迟变得越来越重要。由于互连延迟已成为决定系统性能的主要因素,仅考虑拥塞已经不够。在布线过程中,加入时序约束和功耗约束更符合实际工业制造,无论是理论研究还是实际生产都具有重要意义。\n主要研究方向 # 减少拥塞数和溢出数 考虑延时、串扰、拥塞等优化目标 非曼哈顿结构 并行 总体布线器 # ISPD举行的 VLSI 总体布线算法竞赛中,涌现出了: [FGR]( https://web.eecs.umich.edu/~imarkov/pubs/conf/iccad07-fgr.pdf#:~:text=routing technologies and outperform the best), BoxRouter 2.0, [GRIP]( https://jlinderoth.github.io/papers/Wu-Davoodi-Linderoth-10-PP.pdf#:~:text=GRIP: Global Routing via Integer Programming), NCTU-GR2.0, [NTHU Route 2.0]( https://www.cs.nthu.edu.tw/~tcwang/nthuroute/#:~:text=NTHU-Route 2.0 is a fast and)\n到目前(2022.05)为止，性能最好的几款布线器分别是NTHU-Route20、FastKoute 4.NCTU-GR 2.0和 MGR。NCTU-GR2.0在所有学术布线器中性能最好,它使用两种有界迷宫布线算法(最优有界迷宫布线和启发式有界迷宫布线),这两种算法的布线速度比传统的迷宫布线算法快得多。此外,串行总体布线算法,在多核平台上开发了并行多线程总体布线器。MGR是一款多级3D布线器,运行速度比传统3D布线器快得多。近两年来,研究者们尝试采用基于机器学习的方法解决总体布线问题。\n时序驱动的总体布线器TIGER\nFastRoute 1.0 # 串行\n使用steiner结构避免迷宫路径\n实现过程 # # FastRoute 2.0 # 串行\n# FastRoute 3.0 # 串行\n详细布线 # 每个通道区中的最终布线将由详细布线来实现\n详细布线是在尽量遵守总体布线的结果导向的前提下寻找每个布线片段的具体轨道位置,并绕开拥挤区域,同时尽可能满足一些基础的布线设计规则\n在全局布线完成后 ，整个芯片的布线区域中较粗粒度的连接⽅式已经初步确定 ，但全局布线中GCell 之间的连接还不能直接表示成金属线 ，需要对GCell 之间的连接进行轨道分配 ，也是详细布线的前置步骤之一。此后 ，详细布线要在局部范围内满足线网连通率、设计规则违反等关键约束 ，并尽量降低线长和通孔数。\n现代 VLSI 主流的布线策略为区域布线 ，布线过程中依据全局布线网格将整个芯片的布线区域分割成多个详细布线窗口（detail routing window），每个详细 布 线 窗 口 可 由 m × n 的 GCell 组 成（ 一 般 取m = n），更大的详细布线窗口会导致更大的时间和内存开销，但可以改善布线的质量。\n详细布线的布线图 ，即寻路算法的搜索空间，主要有两种构建⽅式：基于网格的（grid-based）和无网格的（gridless） 。\n无网格布线允许金属线放置在布线区域的任意位置上 ，具备较高的布线灵活性。其在每个金属层上 ，使用树结构分割金属层上的几何形状[27]，随后使用瓦片结构[28]或连接图[29]构建路径搜索算法的搜索空间。 由于无网格布线算法会产生较大的时间开销 ，大部分布线算法都使用布线网格构建搜索空间。\n举例 # 算法 # 大多数是串行算法，为了弥补线网顺序对布线结果的影响,串行布线通常采用拆线重布的方式进一步精炼布线结果,可快速获得质量较好的布线方案\n详细布线算法在给定布线网格中找到一个合法的布线路径\n最短路径问题\n李氏算法 # 老旧\nA星算法 # 李氏算法的加速版本\nGDRouter # 提出一个结合总体布线方法和详细布线方法的布线器,从而获得包含总体布线和详细布线的完整布线结果。\nAlgorithms and Data Structures forFast and Good VLSl Routing # 一个详细布线器，包含快速网络和形状网络结构两种数据结构\nDetailed routing algorithms for advancedtechnology nodes # 最短路径算法未能寻找出合理的布线方案时,提出了一种多标签的最短路径算法，用于计算一些不违反设计规则的路径。\nMCFRoute\u0026amp; A_Multicommodity_Flow-Based_Detailed_Router_With_Efficient_Acceleration_Techniques # 设计了一种基于多商品流模型的并行详细布线算法,同时对多个线网进行布线。但是这类算法并未考虑到时延优化问题且时间复杂度高。\n轨道分配问题 # 是全局布线与详细布线的中间步骤\n全局布线生成的布线结果仅仅完成了 GCell 级的连接 ，连接的路径被称为线段（segment）。在轨道分配阶段中 ，segment 特指没有几何形状及位置信息的线段 ，只表示 GCell 间的连接关系。而轨道分配算法中考虑其实际几何形状 ，更贴 近详细布线中金属线的线段被称作 iroute\n在全局布线网格中 ，水平（ 竖直 ）⽅向的一行（列）GCell 共同构成一个面板（panel），其⽅向与对应布线层的优先走线⽅向一致，如图 4 所示。每个面板由多条布线**轨道（track）**构成 ，轨道的数量与全局布线边的容量相同。将所有线网的 iroute 都分配至轨道上 ，并保证一个面板内不同线网的各个 iroute 在同一轨道上没有重叠，是轨道分配⼯作的主要任务\n到最优的轨道分配策略被证明是NP难问题\n优化目标 # 最小重叠代价， 最小线长\n举例 # 参考 # Negotiation-based_track_assignment_considering_local_nets # TraPL # 难点与挑战 # 十几年来,物理设计是集成电路中发展速度最快和自动化程度最高的领域之一。随着集成电路的特征尺寸不断减小,超大规模集成电路的工艺和电路规模以摩尔定律经历了巨大的进步,电路设计中不断增长的复杂性进一步扩大了物理设计中自动化设计问题的难度,并同时迎来一系列新的挑战。\n在SRC发布的“Physical Design CAD Top10 Needs\u0026rsquo;”中指出的当前物理设计亟待解决的十大问题中，布线问题位居前列，在芯片尺寸和容量上，布线工作需要绕线的电路芯片规模达到成千上万个大模块和几百万个小模块，同时要求在合理可行的时间内完成布线工作。同时，VLSI物理设计中的其他一些需求，如定时和互连线分析，都对布线结果的质量有很高的要求。\n在电路规模变大，尺度减小，复杂度飙升的今天，决定边权成为了一个十分重要的问题，随着待优化指标的增多，准确算法的时间空间复杂度均逐渐来到了一个不可接受的地步（毕经这是一个NP-Hard问题），因此业界主流的发展方向是使用近似算法。关于Steiner最小树的研究非常多，目前的理论最优解是 Geosteiner 算法\n随着集成电路设计工艺的不断发展,允许绕线的布线层数随之增加,大幅度减少了互连线宽度和互连线间距,从而提高了集成电路的性能和密度。于是,多层总体布线应运而生\n在现在的 VLSI设计中,随着制程技术的发展,纳米等级CMOS电路的电晶体密度剧烈增加,电路时延问题越突出,时序收敛越困难,最终严重影响芯片的性能和产量。当前,互连线延迟超越门延迟变成影响电路性能的主要因素,并且总体布线结果直接影响芯片面积、速度、可制造性、功率和完成设计周期所需的迭代次数,因此其在决定电路性能方面起着重要作用\n较长的布线会导致明显的信号延迟并导致更大的动态功耗。**过多的通孔会降低芯片的可靠性。**电线间隔的差异会引起电短路或者断路而降低成品率。物理设计是人工设计中耗时最长和错误率最高的设计过程之一。它也是近年来电子设计自动化(Electronic Design Automation,EDA)工具中发展最快和自动化程度最高的领域之一。随着制造工艺的发展,它也是受到影响最大、面临的机遇和挑战最多的领域之一.\n特征尺寸进入纳米级后,器件的尺寸变得越来越小,互连线的线宽越来越细、密度越来越大。互连线变小速度赶不上器件,长度也迅速增加,互连线的延迟远超过门的延迟，占到线网总延迟的 60%~70%。\n集成度的增大使得互连线面积不断增加,约占芯片总面积的30%~40%。为了降低芯片大小,布线金属层的数量也在不断增加。目前最大布线层数已达到13层,预计 2028 年会达到 17 层。\n为了缩短开发周期,IP复用显得越来越重要。这使得布线区域的障碍数量不断增多,密度增大,形状也更加复杂。此外,利用障碍内资源布线可大大缩短互连线长度、减小布线面积和提高芯片性能。当线网障碍内部分较大时,导致输出端的电压转换速率过大,引发噪音和功率问题,并影响信号完整性。这使得在布线过程中需要进一步考虑绕障问题和信号完整性问题\n现代设计中互连结构和网格的高体积与复杂性对可布线性造成了严重的挑战。快速拥塞分析对于在设计的早期阶段解决可布线性问题变得至关重要,例如，在布局期与总体布线一起。在现代设计中,一些新的因素导致了布线拥塞,包括金属层之间明显不同的导线尺寸和间距、层间通孔的尺寸、各种形式的布线拥塞(例如,保留给电网、时钟线网或芯片系统中的JP块),由于引脚密度和总体单元内的布线导致的局部拥塞和位于较高金属层的虚拟引脚。然而,早期的评估技术都没有全面地捕捉到这些新的拥塞源。\n布线问题已经被证明是一个 NP 完全问题，因此 ，为布线问题寻找全局最优解不具备可行性 另外 ，布线过程受制造⼯艺制约 ，存在着很多约束和限制 ，这也令布线的复杂度进一步提升\nIn advanced technology nodes, detailed routing has to deal with complicated design rules and large problem sizes, making its performance more sensitive to the order of nets to be routed.\n迷宫布线（寻路算法） # 李氏算法（迷宫布线算法） # 该算法从源点开始 ，依次访问网格各⽅向上的相邻节点 ，并为该节点标记从源点到该点的已知布线代价。对每个访问到的节点重复相同的过程。这会在整个布线图中产生一个连续扩散的波 ，当这个波扩散到了目标点 ，即目标节点被他的相邻节点访问到时 ，就找到了这样一条路径连通源点与目标点。随后算法进入路径回溯阶段 ，从目标点开始 ，直到回溯到源点，此时就生成了一条最优路径\n这类方法都是每次从线网（nets)中选择一条拆成两端线网来进行布线，效果取决于布线顺序。另外，算法未考虑约束（可布性、拥塞、间距），而这些约束都有滞后性，需要线网全部布线完成后，才能体现。因此基于以上方法的工作更多在顺序布线（sequential routing)前期就考虑各种约束[1-5]。\nA*算法 # （对李氏算法的改进，加速了李氏算法收敛）\nBFS Dijkstra 线搜索算法 # Mikami 等在 1968年提出了第1个使用线段代替节点搜索的路径搜索算法\u0026ndash;线搜索算法。该算法以源点和目标点为基点,首先从两个基点各引出两条相互垂直的直线,当直线遇到障碍物或布线区域边界时,会在当前的直线上选取新的基点并沿垂直方向生成一条新的直线,直到从源点和目标点延伸出的多级直线发生相交,则找到了一条路径连通源点和目标点。由于其并没有遍历所有的搜索空间,所以线搜索算法并不能保证找到最优解。 Hetze1在 2002年提出的Hetze1算法将以线段代替节点进行搜索的思想与A算法结合,在保证找到最优解的情况下具备比A算法更快的求解速度。\n多源多汇迷宫布线 # 多源多汇迷宫布线将同一子树中的所有网格点视为源点,将另一个子树中的所有网格点视为汇点\n并行算法 # 多商品流算法(multi commodity flow, MCF)\n建模为整数线性规划（integer linear programming，ILP）\n由商品的源点和目标点以及商品流经的路径组成。随后将整个布线区域建模成一个三维的布线网格,网格点可以作为商品流的流经点,点与邻近点之间的线段称作边。 在ILP 问题的模型中,网格的点和边作为变量用边和点的流量表示线网对边和点的使用情况，容量代表边和点上同时流经的最大的线网数量(在详细布线中一般取1)。目标函数为边上所有线网的流量与其相应布线代价的积的累加和。在约束条件下最小化目标函数可以获得布线的最短线长。其约束主要包含各个线网在点或边上的流量之和不超过点或边的容量约束、基于流量守恒定律的连通性约束等。\n整数线性规划 # 这类方法可以直接对所有线网布线（Concurrent Approach），并考虑交叉、拥塞等约束。算法提前生成端点之间可能的走线方案，并用一0-1变量 xij 表示是否选择本方案。问题随后转化为带约束的线性整数规划问题\n特点 #  Standard techniques to solve IP.  No net ordering. Give global optimum.  Can be extremely slow, especially for large problems.  To make it faster, a fewer choices of routing trees for each net can be used. May make the problem infeasible or give a bad solution.  Determining a good set of choices of routing trees is a hard problem by itself.\nHierarchical Approach # Hierarchical Approach reduces global routing to routing problems on a 2x2 grid\n先将网格划分为粗网格，找到粗网格间的布线，然后将网格细化，对每个子模块递归求解，每次求解规模均极小\n基于Steiner的算法 # This technique can be used in global or detailed routing problems\n对于某些多端net, 一般都采用最小斯坦纳（steiner)生成树方法。比如遵守水平垂直走线的Rectilinear Steiner Minimal Tree.一般生成树算法算法非常多，比如Kruskal，prime, spanning-graph[7],edge-substitution. 另外考虑实际布线中允许45，60度走线，也有对应八向斯坦纳最小生成树（octilinear steiner)方法[8].\n定义 # Steiner Node :\nFor a multi-pin net, we can construct a spanning tree to connect all the pins together\nSteiner Tree: A tree connecting all pins and some additional nodes (Steiner nodes).\nGrid graph:\n优化算法 # 布线从数学的角度来看是一个有约束的最优化问题。线网是指具有相同电位的一组引脚，很显然，这些引脚需要被连接在一起，但电路板上有着各种约束，代表性的便是一系列的匹配规则（比如对一部分版图设计初学者来说堪称莫名其妙的插指结构或重心匹配和热匹配），因此这是一个十分典型的复杂最优化问题。\n优化指标 # 一般来说，最优化的主要指标是线长，但在RF设计中，线与器件的距离等其它因素将因为互感效应和一些非线性效应变得异常重要。VLSI总体布线问题最初以线长最小化为优化目标,但随着制造工艺的不断发展和芯片特征尺寸的不断缩小,互连线延迟对芯片性能的影响越来越大,因此,时延和串扰等优化目标也需要在总体布线问题中考虑。同时,影响到芯片的可布性和可制造性的因素,包括溢出数、拥挤度、通孔数等优化目标,也是当今总体布线工作需要优化的指标。\n线长：线长影响了芯片的制造成本 ，且线长越长 ，线网的时延与电容越大 ，这会使芯片的稳定性下降、功耗增高\n布通率：完成连线/实际连线数\n通孔数量：越少越好，via具有更大延时，还会增加芯片制造失败率\n串扰和时延：线网间的电容电感等现象会在线网间产生串扰 ，增大时延。因此布线算法要对时延敏感线网及关键线网做出特殊设计，以降低芯片的总时延，提高芯片稳定性\n术语 # (1)网表:N={N,N。,，…},其中每个线网N，是一个引线端的集合,属于同一个线网的引线端将由布线工具把它们连接在一起,这里的网表则是提供电路的互连信息。 (2)布线容量:指考虑设计规则、布线区域的大小和线网的宽度,布线区域内的最大走线数。 (3)拥挤度:需要的布线资源与可用的布线资源之间的比值。 (4)溢出边:若一条边的布线资源需求量大于可用的布线资源,则该边被称为溢出边。 (5)总体布线图(GRG):在进行总体布线之前,根据电路的几何特征和电路结构,用网格将整个芯片按行和列划分为若干称为总体布线单元的区域,并通过总体布线器指定GRC以连接线网。由网格线及其交点所构成的图的对偶图称为总体布线图。 (6)局部线网:若一个线网所需要连接的所有引脚均在同一个GRC中,则称该线网为局部线网。 (7)全局线网:若一个线网所需要连接的部分或全部引脚分布在不同GRC中,则称该线网为全局线网。 (8)设计规则约束:目前布线问题中存在一些基本设计规则约束(DesignRules Constraint,DRC)违反情况,包括开路、短路、相邻金属线的间距不足等。 (9)3D总体布线和2.5D总体布线:多层总体布线类型分为3D和 2.5D 总体布线两种。 ① 3D总体布线:对于多层布线,采用3D布线直接在立体的总体布线图进行布线,这样得到的总体布线方案虽然比2.5D来得更准确且能取得多个更好的性能指标,但会带来巨大的时间和空间复杂度。由于EDA设计的原则是简单、快速、合理,所以3D布线的研究不能令人十分满意。 ② 2.5D总体布线:是将多层布线中各层的布线资源、引脚等映射到平面上，将3D布线转化成平面布线,这样进行平面总体布线可减少时间空间复杂度,在平面上完成总体布线后,再通过层分配将布线结果还原到3D布线,同时维持平面布线获得的溢出数且优化通孔数。\n标准 # LEF # lefdefref.pdf (ispd.cc)\nTools # Glogal Router # CUGR # CUGR is a detailed routability-driven global router and its solution quality is solely determined by the final detailed routing results\nDAC paper\ngithub\nDetail Router # Tritonroute # from openRoad\nincluding pin access analysis, track assignment, initial detailed routing, search and repair, and a DRC engine.\ngithub\n当前研究方法 # 结合AI：比如使用AI模型预测拥塞率，在顺序布线早期阶段减少拥塞，降低时间。比如利用强化学习，自行学习走线过程。\n布线-拆线：有点类似对抗生成网络**(GAN)**思想。Alpha-PD-Router有两个玩家，布线器（router）和拆线器（cleaner）。布线器以总线长为目标布线，而拆线器则拆线重布，以使布线器布线更容易为目标，如此往复下去。\n相关竞赛 # [ISPD24 Contest: GPU/ML-Enhanced Large Scale Global Routing | ISPD24_contest (liangrj2014.github.io)]( https://liangrj2014.github.io/ISPD24_contest/#:~:text=Global routing is a critical component)\n[ISPD 2008 Global Routing Contest]( https://www.ispd.cc/contests/08/ispd08rc.html#:~:text=Continuing the tradition of spirited competition,)\n[ISPD 2007 Global Routing Contest]( https://ispd.cc/contests/07/contest.html#:~:text=Continuing the tradition of spirited competition,)\n[Initial Detailed Routing Contest at ISPD 2018]( https://www.ispd.cc/contests/18/#:~:text=This proposed contest focuses on the)\n[Initial Detailed Routing Contest at ISPD 2019]( https://ispd.cc/contests/19/#:~:text=Detailed routing can be divided into)\n评价标准 Connectivity constraints LEF routing rules Routing preference metrics 参考 # 大规模集成电路布线算法设计简介 - 知乎 (zhihu.com)\n超大规模集成电路布线算法综述 (sciengine.com)\n非曼哈顿结构下超大规模集成电路布线理论与算法-目录，第一章绪论\n非曼哈顿结构下超大规模集成电路布线理论与算法-第三章X结构Steiner最小树算法\n超大规模集成电路布线设计理论与算法-目录，第一章绪论\n超大规模集成电路布线设计理论与算法\n"},{"id":18,"href":"/zh/docs/Digtal/Routing/routing2/","title":"Routing2","section":"Physical design","content":" 简介 # GR \u0026amp; DR # Routing is a critical yet complex phase in the implementation process of integrated circuits (ICs), often necessitating considerable time and effort. Given its complexity, the routing process is typically divided into two stages: global routing and detailed routing. Global routing, the initial stage, establishes coarse-grained wire paths for signal nets, thereby providing valuable guidance for the subsequent detailed routing stage, enhancing its efficiency. Detailed routing, on the other hand, focuses on identifying valid physical paths, primarily within the routing guides set by global routing, while taking into account design rule constraints\nRouting is usually divided into global routing (GR) and detailed routing (DR) –cite–\u0026gt; C. J. Alpert, D. P. Mehta, and S. S. Sapatnekar, Handbook of Algorithms for Physical Design Automation. CRC press, 2008. Routing is usually divided into global routing (GR) and detailed routing (DR) [2]. Global routing serves as a fast routing planning to generate guidance for detailed routing to reduce the search space of each net. Detailed routing then takes the guidance as input and finishes the physical wiring to connect pins in each net. Global routing is also used for routability estimation at early design stages like placement [3–9]. With growing design scales and complexity, it becomes increasingly challenging for global routing to resolve routing overflow within a short time. Therefore, the quality and efficiency of global routing is critical to design closure, as it impacts both its proceeding and succeeding design stages.\nbackground # 输入 # 输出 # 优化指标 # 约束 # 线网连接正确性 布线障碍 版图设计规则 ：金属线的最小宽度（min-width）；金属线间及金属线与布线障碍间的最小线间距（min-spacing）；一条金属线的最小面积（min-area），当金属线的宽度固定为最小宽度时 ，最小面积约束也被称作最小长度约束 Global Router # 概念 # 甚至不需要考虑大部分几何级问题 ，其布线模型的建模较为简单 ，即使在具有数以万计的区域的芯片版图上布线，也只产生较低的时间开销\nroutes every net with only two pins under design constraints turns out to be an NP-complete problem –cite–\u0026gt; M. Kramer and J. Van Leeuwen. The complexity of wirerouting and finding minimum area layouts for arbitrary vlsi circuits. Adv. Comput. Res, 2:129–146, 1984 term # net order: 串行\nOF: over flow\nconjointly： 并行\nguide: 在GR中就是布线通路，GR最终的输出结果\npreferred routing direction : 比如第一层水平优先，第二层垂直优先\nchallenge # advance GR are GPU-Accelerate-based now，main challenge are:\nGPU memory is limited This requires memory-efficient solutions that can minimize CPU-GPU communication while maximizing GPU utilization large designs have more nets with bigger routing graphs, providing many new parallelization opportunities that are not yet explored 技术方向 # DP base-layer assignment\nCUGR, InstantGR start use GPU accelarate RL-based\nslow 理论上DRV会很小 generative model\nsuch as: CNN-based, PRNet, Hub Router Actually, global routing is a combinatorial problem and can be formulated as a 0-1 integer linear programming (0-1 ILP) problem it is still NP-complete 另一种分类：来自 HeLEM-GR\ngrid models\n2D\nMany routers such as FastRoute 4.0 [10], BoxRouter 2.0 [11], NCTU-GR 2.0 [12], and SPRoute 2.0 [13] are based on 2D grids (a.k.a 2D routers), which perform layer assignment after routing all nets on the 2D space\n3D\nOther routers such as FGR [14] and CUGR [15] try to directly route on 3D grids to simultaneously determine the routing paths and layers for each net\nhybrid\ngenerates initial routing results on 2D grids and then refines it on 3D grids. TritonRoute-WXL routing kernels\nLee’s algorithm [17] is the basic maze routing kernel in many routers, but it is very time-consuming. routing schemes\n问题建模 # 3d method:\n2D method:\ngcell 定义在.def 文件中\n输入\n输出\n约束\n优化指标\n全局布线要在给定布线资源的情况下 ，优化线长、通孔数及关键线网时延等目标函数\n线长、通孔数、溢出数量、运行时间\nFasterRoute4.1 in OpenROAD # 结构 # fastroute # FastRouteCore # vector\u0026lt;FrNet*\u0026gt; nets_; vector\u0026lt;StTree\u0026gt; sttrees_; // the Steiner trees run() gen_brk_RSMT() for (const int\u0026amp; netID : net_ids_) rsmt = stt_builder_-\u0026gt;makeSteinerTree(…) Tree tree = pdr::primDijkstra(x, y, drvr_index, alpha, logger_); flute_-\u0026gt;flutes(x, y, s, accuracy) steinerTreeVisualization getOverflow2Dmaze() getOverflow2Dmaze fluteNormal(rsmt) layerAssignment() StTreeVisualization()//2d or 3d getOverflow2D routeLAll convertToMazeroute // debug mode Rectilinear Steiner Tree before overflow iterations SteinerTreeBuilder # FrNet # odb::dbNet* db_net_;\nvector\u0026lt;int\u0026gt; pin_x_;\nvector\u0026lt;int\u0026gt; pin_y_;\nvector\u0026lt;int\u0026gt; pin_l_;//layer\nfloat slack_;\nstd::unique_ptr\u0026lt;std::vector\u0026lt;int\u0026gt;\u0026gt; edge_cost_per_layer_;\nvoid addPin(int x, int y, int layer)\nStTree # vector\u0026lt;TreeNode\u0026gt; nodes // The nodes (pin and Steiner nodes) in the tree. vector\u0026lt;TreeEdge\u0026gt; edges TreeNode # int16_t x, y; // position in the grid graph int nbr[3]; // three neighbors int edge[3]; // three adjacent edges TreeEdge # stt # Flute # initLUT（）\n主要是读取.dat文件 flute()\nflutes()\nflutes_RDP flutes_ALLD SteinerTreeBuilder # unique_ptr\u0026lt;flt::Flute\u0026gt; flute_ Tree # int deg; // degreeStTree int length; // total wirelength vector\u0026lt;Branch\u0026gt; branch; // array of tree branches void printTree(utl::Logger* logger) const; int branchCount() const { return branch.size(); } Branch # int x, y; // starting point of the branch int n; // index of neighbor odb # dbNet pdr # Tree primDijkstra(const vector\u0026amp; x,const vector\u0026amp; y, const int driver_index, const float alpha, Logger* logger) ListGraph graph get_nearest_neighbors buildSpanningTree steinerize makeTree makeTreeRecursive lemon # ListGraph # CUGR # cuhk-eda/cu-gr: CUGR, VLSI Global Routing Tool Developed by CUHK\ninstall # #还是在docker跑把，服务器上的boost版本总是搞不好。。。 apt update apt install git apt install vim apt install build-essential apt install -y build-essential gcc g++ apt install cmake apt install -y libboost-all-dev curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh #yes, opt/miniconda3, yes source ~/.bashrc git clone https://github.com/cuhk-eda/cu-gr cd cu-gr scripts/build.py -o release 报错：\nCMake Error at /usr/local/lib/cmake/Boost-1.80.0/BoostConfig.cmake:141 (find_package): Could not find a configuration file for package \u0026ldquo;boost_filesystem\u0026rdquo; that exactly matches requested version \u0026ldquo;1.80.0\u0026rdquo;.\nThe following configuration files were considered but not accepted:\n/usr/lib/x86_64-linux-gnu/cmake/boost_filesystem-1.74.0/boost_filesystem-config.cmake, version: 1.74.0 /lib/x86_64-linux-gnu/cmake/boost_filesystem-1.74.0/boost_filesystem-config.cmake, version: 1.74.0\nCall Stack (most recent call first): /usr/local/lib/cmake/Boost-1.80.0/BoostConfig.cmake:262 (boost_find_component) /usr/local/share/cmake-3.24/Modules/FindBoost.cmake:594 (find_package) CMakeLists.txt:39 (find_package)\nfix:\n可以使用以下命令来查看系统上安装的 Boost 版本：\ndpkg-query -s libboost-all-dev | grep Version # 对于 Debian/Ubuntu 系统\r#如果您已经安装了 Boost 1.74.0，则需要升级到 Boost 1.80.0 版本。\rtar -xvf boost_1_80_0.tar.bz2\rcd boost_1_80_0\r./bootstrap.sh\r./b2\rsudo ./b2 install\rcmake -DBOOST_ROOT =/usr/local/ 报错：\nCMake Error: Invalid value used with \u0026ndash;target Usage: cmake \u0026ndash;build [options] [\u0026ndash; [native-options]] cmake \u0026ndash;build \u0026ndash;preset [options] [\u0026ndash; [native-options]] Options:\n= Project binary directory to be built.\r--preset , --preset=\r= Specify a build preset.\r--list-presets\r= List available build presets.\r--parallel [], -j []\r= Build in parallel using the given number of jobs.\rIf is omitted the native build tool's\rdefault number is used.\rThe CMAKE_BUILD_PARALLEL_LEVEL environment variable\rspecifies a default parallel level when this option\ris not given.\r--target ..., -t ...\r= Build instead of default targets.\r--config = For multi-configuration tools, choose .\r--clean-first = Build target 'clean' first, then build.\r(To clean only, use --target 'clean'.)\r--resolve-package-references={on|only|off}\r= Restore/resolve package references during build.\r--verbose, -v = Enable verbose output - if supported - including\rthe build commands to be executed.\r-- = Pass remaining options to the native tool.\rcmake --build build --target -- -j 6\rfix:\nscripts/build.py -o release -t iccad19gr#cu-gr, github 写的有问题 scripts/build.py -o release -t route#cu-gr2 run # 按照他说的，不过要自己把iccad19的benchmark放到toys/iccad2019c/下\nFastRoute # install # #in a new ubuntu:22.04 container apt install build-essential apt install gcc apt install libboost-all-dev apt install cmake apt install tcl-dev apt install swig apt install git apt install bison apt install flex git clone --recursive https://github.com/The-OpenROAD-Project/FastRoute4-lefdef cd FastRoute/ cmake . make PARALLEL=nthreads debug # /root/FastRoute-master/third_party/OpenDB/include/opendb/ZInterface.h:38:10: fatal error: tcl.h: No such file or directory 38 | #include \u0026lt;tcl.h\u0026gt; | ^~~~~~~ compilation terminated.\n#cmake 中加上以下两句 include_directories(/usr/include/tcl8.6) link_directories(/usr/lib) CUGR 2.0 # InstantGR # model # database # layer db::net database_cuda # cudb::net flute.hpp # readLUT robin_hood.h # 一个高性能的哈希表实现库 开源 这个库在高性能计算场景（如本项目的集成电路布线）中特别有用，因为它能提供更快的查找和插入操作，同时保持较低的内存占用。 主要优势： 比标准库的 std::unordered_map 性能更好 内存使用更高效 缓存友好的设计 开放寻址法解决冲突 支持异构查找 flow # 开启时钟\nprogram_start = std::chrono::high_resolution_clock::now();\nread input files\nread()\n输入： cap_file_name[]: 容量文件的路径\nnet_file_name[]: 网络文件的路径\n输出： 代码将读取的数据存储在类的成员变量中：\nlayers[]: 存储每层的信息\ncapacity[][][]: 3D数组存储容量信息\nnets: 存储所有网络信息\n其他相关的网格和坐标映射信息\nreadLUT(\u0026quot;POWV9.dat\u0026quot;, \u0026quot;POST9.dat\u0026quot;)\nbuild_cuda_database() cuda相关变量初始化\n先处理单pin的net（有一些两个pin重叠，二维变成单个pin）\n设置两个核函数cuda共享内存大小\ncudaFuncSetAttribute\n具体有什么用？\n对非单Pin的net(nets2route)进行FLUTE建立MSRT\nFLUTE:\nnet.construct_rsmt() my_flute(unordered_set \u0026amp;pos)` flute::flute(cnt, x.data(), y.data(), 3); 最后处理得到水平和垂直segments\nsort, 对非单Pin的net(nets2route)进行根据hpwl从小到大排序\ngenerate_batches_rsmt(nets2route)\nsort, 对每个batch根据net数量从小到大排序 //这个有什么用？\n可以问问\n根据sort后的batches，重新对每个net依次排列到nets2route\nDFS获取DAG图：Routing DAG,\n得到一个segment排序\n对每一个batch, 开启L_shape\nLshape_route_cuda\u0026lt;\u0026lt;\u0026lt;BLOCK_NUM(batches[i].size()), THREAD_NUM\u0026gt;\u0026gt;\u0026gt; (batches[i].size(), batch_cnt_sum[i], node_cnt_sum, nodes, par_nodes, dist, from, layer_range, global_timestamp);\ninstall # compile directly\ndebug # contest # ISPD 07 # ISPD 08 # ICCAD 19 Contest Problem C: GR use Real world design and evaluate by DRouter # 2019 CAD Contest @ ICCAD\n也给了后端详细布线器DrCu,和用于评估结果的脚本\n用的 ISPD2018/19 的数据\n输入：\n输出：\nispd24的比赛是要via的\nevaluate:\nISPD’24 Contest: GPU/ML-Enhanced Large Scale Global Routing Contest # background:\ndata\nevaluate：\n和 ICCAD19 很像\nscale 越大权重越大\n限制：\n最好结果：\n越小越好\ndesign WL cost via cost overflow cost raw score runtime /s median runtime /s scaled score Ariane133_51 9335109 3060400 10369862 22765372 4 11 22100882 Ariane133_68 9443754 2981836 7825647 20251238 8 12 20014313 BlackParrot 58347098 19740536 35450029 113537664 27 70.5 110393434 Nvdla 21345766 4630872 23933347 49909986 4 20 47592238 MemPool-Tile 8407884 3425828 3569040 15402753 3 10 14867672 MemPool-Group 262817992 76146200 70345580 409309772 81 375 391210938 MemPool-Cluster 1094650057 268335040 300359611 1663344708 478 2048 1593513066 Tera-Cluster 12190406272 1542639724 6705414754 20438460750 4310 4584 20402113329 issue:\nISPD25 Contest: Performance-Driven Large Scale Global Routing # Background # ISPD2024 竞赛虽然简化的输入/输出格式和评估指标提高了来自不同背景的参与者对比赛的可访问性，但它们可能会在性能建模中引入不准确性。ISPD2024 竞赛中使用的输入文件 缺少时序和功率信息。仅基于带宽和路由溢出的指标不能准确地模拟定时性能和功耗。例如，最小化总长度并不一定会减少时间关键路径上的延迟。Wires on different metal layers exhibit varying resistance, resulting in different delays and power consumption. Additionally, the impact of vias on delays is difficult to model with simple metrics. Inter-wire coupling capacitance can also cause significant discrepancies between actual and nominal timing responses and power consumption\nProblem Formulation # In global routing, a 3D routing space is defined using global routing cells (GCells), created by a regular grid of horizontal and vertical lines. This configuration results in the formation of a grid graph where each GCell is treated as a vertex and edges connect adjacent GCells within the same layer (GCell edges) or between GCells in neighboring layers (via edges). The global router needs to establish a concrete path for each net within the grid graph and optimize the routability, timing and power.\nFor each testcase, the global router starts with a placed design, and generates a global routing solution. The global routing solution is evaluated by OpenROAD, which reports timing, power, and routing congestion. Additionally, the runtime and memory efficiency of the global router are critical factors.\n文件 # 输入\nFor each testcase, two sets of input files are provided: industry-standard files and simplified files.\nThe industry-standard files include DEF, LEF, LIB, and SDC files. The DEF file contains definitions for CORE, ROW, TRACKS, and GCELLGRID, along with placed COMPONENTS and unrouted NETS. Similar to the ICCAD2019 global routing contest, GCells are specified using the definition from the DEF GCELLGRID section. The LEF file includes MACRO definitions and technology information. The LIB files offer timing and power data for library cells, while the SDC files provide timing constraints. These files serve as the raw input, allowing contestants to perform the most accurate routing resource and performance modeling.\nFor each circuit, we also provide a set of simplified input files, which include a routing resource file (with a .cap extension) and a net information file (with a .net extension). The routing resource file follows the same format as used in the ISPD2024 contest, while the net information file is an extended version of the one used in ISPD2024. The routing resource file offers a detailed representation of the GCell grid graph and its available routing resources. The net information file provides the access points for all the pins within each net, along with the pin names and pre-routing stage slack estimates. These slack estimates provide a rough timing view of the circuit and enable contestants to perform net-based timing optimization. The simplified input files enable contestants to quickly engage with the contest and facilitate framing global routing challenges as mathematical optimization problems.\n输出 镜像使用：\ndocker run -it ispd25:latest /bin/bash\t#启动 Detail Router # 概念 # 问题建模 # Contest # ISPD-2018 # ISPD-2019 # 算法 # 最小树算法 # 矩 形 最 小 斯 坦 纳 树（rectilinear steiner minimal tree，RSMT） 一般会先基于 Pin 生成最小树，分解最小树为 2-Pin(两端口) wire 然后再进行后续处理\nRSMT 和 RMST 的区别\n在图论和计算几何中，RSMT（Rectilinear Steiner Minimum Tree）和 RMST（Rectilinear Minimum Spanning Tree）是两种不同的树结构，主要用于解决不同类型的最小树问题。以下是它们之间的主要区别：\n1. 定义 # RSMT（Rectilinear Steiner Minimum Tree） RSMT 是一种最小生成树，允许在树中添加额外的点（称为 Steiner 点），以减少连接给定终端（节点）所需的总边长。RSMT 的目标是最小化连接所有终端的总路径长度，使用的是矩形距离（L1 距离或曼哈顿距离）。 RMST（Rectilinear Minimum Spanning Tree） RMST 是一种最小生成树，连接给定的终端节点，但不允许添加额外的点。RMST 的目标是找到连接所有终端的最小边长树，同样使用矩形距离。 2. 额外点的使用 # RSMT 允许在树中添加额外的 Steiner 点，这些点可以帮助优化路径，减少总边长。 RMST 仅使用给定的终端节点，不允许添加额外的点，因此可能会导致较长的连接路径。 3. 应用场景 # RSMT 通常用于更复杂的网络设计问题，例如 VLSI 设计和电路布局，其中需要优化连接以减少布线长度和提高效率。 RMST 更常用于简单的网络连接问题，适用于需要在给定节点之间建立最小连接的场景。 4. 计算复杂性 # 计算 RSMT 通常比 RMST 更复杂，因为需要考虑如何有效地选择 Steiner 点以优化树的结构。 RMST 的计算相对简单，因为只需连接给定的终端节点。 相关文献\nFLUTE # 介绍 # 问题阐述\n一个常见的steiner tree算法 9端最快，9端一样也是次优解 基于查找表 诞生与2004 ICCAD, ISPD 05 和 TCAD 07 有相关优化 版本信息\n基本定义 # Degree\nDegree of a net is the number of pins in it\nHanan grid\n只考虑节点是4个方向\nWL\nPOWV\n使用WV的好处\nposition sequence\ny方向是1~4\nposition sequence从x=0开始数\nflow # POWVs Generation ： boundary compaction # Net Breaking for High degree Net\nFor nets with degree \u0026gt; D, recursively break net until degree \u0026lt;= D\n第一步\n查看满足1，3象限 或者2，4象限的情况\n还不能拆成9degree以下的话，使用Net Breaking Heuristic：\nA score for each direction and each pin：\nfor Pin_r in Net:\nS1:\nS2:\nS3:\nS4:\nAccuracy Control Scheme # 文件介绍 # flute.[ch]\n查找表\nPOWV9.dat \u0026ndash; The lookup-table of optimal POWVs up to degree 9. POST9.dat \u0026ndash; The lookup-table for optimal Steiner tree up to degree 9. (Note that it is formerly called PORT9.dat.) TCAD 07 有相关优化（net breaking and merging techniques）\nflute_mst.c \u0026ndash; The net breaking and merging techniques described in the VLSIDAT 08 paper. dist.[ch], dl.[ch], err.[ch], heap.[ch], mst2.[ch], neighbors.[ch], global.h \u0026ndash; Utility functions used by flute_mst.c evaluate\nflute-net.c – A program to evaluate the wirelength of a net. It takes input from stdin as a list of points. rand-pts.c \u0026ndash; A program to generate a list of random points. bookshelf\nflute-ckt.c \u0026ndash; A program to find FLUTE and half-perimeter wirelength of a circuit in bookshelf format. memAlloc.[ch] \u0026ndash; Functions for flute-ckt.c to allocate memory. ibm01/ibm01.* \u0026ndash; ibm01 bookshelf files that can be read by flute-ckt.c 实验结果 # 模型 # 输入\n结构\n输出\n参考 # pdfs.semanticscholar.org/01a6/716144fcd0b88f607e718b78c909bfca415e.pdf FLUTE 模式布线 # 单调\nFastRoute 4.0 的 3-bend Routing\n迷宫算法 # 概念 # 李氏算法 # 有点像 BFS\nA*算法 # 往往是串行的，慢\n往往需要多个 pin 的连线拆成一对一对，导致：\n线搜索算法 # Hetzel 算法\npattern + maze # 线序选择 # 对于串行布线算法, 布线顺序对最终布线质量的影响很大\n以上几种启发式的线序选择策略往往不能完全避免溢出。拆线重布（rip-up and reroute） 策略在初次布线完成后 ，对发生溢出的拥塞区域的线网进行拆除 ，并迭代地 调整线序多次重新布线 ，直到溢出不再减少 ，或达到运行时间限制为止。\n拆线重布 # rip-up and reroute\n层分配 # 并行布线算法 # 整数线性规划 # 线性规划 # 数据集 # 文件定义 # "},{"id":19,"href":"/zh/docs/Digtal/Synthesis/synthesis/","title":"Synthesis","section":"Physical design","content":" 基本概念 # 逻辑函数:二级逻辑和多级逻辑。二级逻辑又包含两种 规范式，分别称为与或两级规范形式(sum-of-products two-level form, SOP)和或 与两级规范形式(product-of-sums form, POS)[19]。其中或与形式的第一级均为或 项，第二级均为与项，而与或形式刚好相反。\nAIG\nAnd-Inverter Graphs)的文件格式的代称\nASCII格式的AIG文件第一行由字符串aag 开始，aag是ASCII AIG的缩写；然后是以空格分隔5个非负整数，分别由M, I, L, O, A 表示。\nM = 最大变量下标 maximum variable index I = 输入个数 number of inputs L = 锁存器个数 number of latches O = 输出个数 number of outputs A = 与门个数 number of AND gate\naag 3 2 0 1 1 2 input 0 4 input 1 6 output 0 6 2 4 AND gate 0 1\u0026amp;2\n相关文件格式 # .aiger # 逻辑综合步骤 # 第一步 (Translation)： # 转换过程，将RTL描述转换成为未优化的门级布尔描述(如与门，或门，触发器，锁存器等)。\n第二步 (Logic Optimization)： # 布尔优化过程，将一个非优化的布尔描述转化成一个优化的布尔描述的过程。\nNP完全问题, 常用启发式算法去求解, 通常计算机内实现的算法是Quine-McCluskey算法, 但是实际上还有许多表示形式如ESOP（E互斥或积之和表示式）和CDEC（条件解码器）\n对于这些多级的直接优化，用与非图AIG来描述组合逻辑电路，利用AIG的有向无环图的特性，一系列高效算法可以用于平衡、重写和重构这些AIG，从而最小化电路。基于AIG有一个主要的好处是，现在大多是的ASIC设计与FPGA设计，都是基于标准单元或者LUT实现的，往往有特定的输入输出引脚数目限制，AIG可以很好把这个限制反映在算法之中。\n时序逻辑优化（Sequential Logic Optimization）\n而考虑时序问题，逻辑综合中主要需要处理与寄存器、 状态机、时钟相关的问题。时序电路会有时钟频率限制，对组合逻辑的整体延时有最大最小值限制。重定时算法会移动寄存器在DAG网表的位置，将整个网表拆分成符合设计限制，合适的Retiming将有利于实现更加高频率的数字电路。有的Retiming算法侧重于缩短时钟周期，有的则侧重减少寄存器数目，如果变换寄存器的位置，会影响到部分控制逻辑，所以其实有一些约束条件的，这些约束条件大多可以转化为SAT（布尔可满足性）问题并且利用SAT专用求解器求解\n第三步 (Mapping)： # 门级映射过程，取出经优化的布尔描述，利用从工艺库中得到的逻辑和定时的信息生成门级网表，确保得到的门级网表能达到设计的性能和面积要求。\n标准单元库是一组相对完善的、符合某种生产或设计工艺标准的标准单元. 常见的标准单元有基本逻辑门（AND、OR、NOT、XOR\u0026hellip;）、Flip-Flop寄存器、MUX多路选择器加法器、时钟单元、延时缓冲（Delay Buffer）\n这样映射的目标通常是优化面积、延迟指标，实现这一目标通常是把问题转化为有向无环图覆盖问题。对于复杂的设计网表，这个问题同样是NP-hard\n如果模板和设计网表都是树，则该问题可以通过动态规划高效解决，所以一种解决方案就是把图动态划分成森林、同时结合基于树的算法，来解决相对复杂图的映射\n工具 # 开源 # Yosys\nYosys是Verilog RTL合成的综合，用作三个VTR前端之一，用于执行逻辑综合、细化和将Verilog硬件描述语言（HDL）的子集转换为BLIF网表。Yosys的设计是可扩展的，因此是实现专门任务的定制综合工具的良好基础。\n"},{"id":20,"href":"/zh/docs/Digtal/Verify/verify/","title":"Verify","section":"Physical design","content":" 背景 # 随着集成电路技术的迅速发展，电迁移（Electromigration, EM）和热迁移（Thermomigration, TM）已经成为影响现代集成电路互连线可靠性的两大主要问题。在电子设计自动化（Electronic Design Automation, EDA）的后端设计中，物理验证环节需要对EM和TM产生的应力进行评估，以确保电路符合可靠性规范。传统的应力计算方法依赖于复杂的偏微分方程（PDE）求解，不仅计算量大、耗时长，而且在处理大规模电路时往往难以保证精度。\n电迁移（Electromigration, EM） # 由于电子流动引起的现象 当导线中电子快速移动时，电子与金属原子间的动量交换会导致金属原子从阴极向阳极迁移。随着时间的推移，这种迁移会导致导线中的空洞（voids）或突起（hillocks），这种金属的分布不均导致了应力的产生。当应力达到一定阈值时，会导致导线断裂或短路，从而影响电路的可靠性，最终引发电路失效。 VLSI: 这种现象在小尺寸导线和高电流密度条件下尤为显著，特别是在纳米尺度的VLSI系统中。 热迁移（Thermomigration, TM） # 由导线中的温度梯度引起 当导线的不同区域存在温度差异时，高温区的金属原子会向低温区移动，这同样会导致导线中的应力积累和材料变形 VLSI: 随着半导体工艺的进步，集成电路的功率密度逐渐增大，热效应越来越严重，热迁移问题成为影响导线可靠性的重要因素。 相关研究 # EMGraph-First GNN-DAC-2021-GNN-University of California # background # 随着VLSI技术进入纳米级，EM已成为影响芯片可靠性的重要问题。电迁移主要通过应力来进行描述。传统的电迁移分析方法依赖于复杂的物理模型和数值求解，如有限元法，但这些方法计算成本高且难以扩展至大规模互连结构。 现有的生成对抗网络（GAN）在固定尺寸的图像上进行预测，但不能很好地适应复杂和动态变化的多段互连电路结构针对这一问题。EMGraph将多段互连电路结构建模成图结构，在节点和边上同时进行EM应力预测，有效地在多段互连结构上进行电迁移分析。 contribution # transferable knowledg first GNN in EM A novel graph convolution-decoder structure is employed Task # node-edge regression for EM stress\ndata # 数据由COMSOL,SPICE(生成电流密度)生成\nresulting dataset contains 2500 unique designs （2125/375）\nFeature\nnode：节点代表电路中的连接点 node_feature: 时间（什么时间？） edge: 导线段 edge_feature: 电流密度J、长度L、宽度W和时间t(老化时间) label is five sampling points’s stress\nmultisegment interconnect： 只有两两连接？\n有向图？\nchallenges # stress ranges from -2e+9 to 2e+9 Pa. Data rescale to -1 to 1 using min-max normalization method. impact the accuracy at the smaller ones as they may be considered noises by the model 然而，这种配置实际上有利于我们的目标，因为大应力点是可能导致可靠性问题的地方，需要更高的准确性 both node and edge features the accuracy of stress should be high. GCN is low model # 基于GraphSage\n其卷积由两部分组成\n将其邻域节点和连通边的信息聚合到一个节点中 将两个端节点的信息聚合到对应的边当中 整体框架\nNode and edge decoder ：\nnode2,3怎么实现聚合到1的？\nexperiment # env:\ndgl pytorch Linux server 2 Xeon E5-2699v4 2.2 GHz Nvidia Titan RTX GPU setting:\n5 layers with number of hidden features set to 8, 16, 32, 64 and 128 respectively. node and edge decoders: [128, 256, 1024, 256, 64, 1] and [128, 256, 1024, 256, 64, 5] Adam optimizer batch size is set to 32 learn rate = 10-4 cross validation technique root-mean-square error (RMSE) 与基于有限元法（SOTA）的传统解析方法和GAN方法相比 EMGraph预测的平均误差为1.5% EMGraph的推理速度极大提升。其推理时间为0.27毫秒，是GAN方法的14倍，传统数值方法的265倍。 可视化 大图知识迁移 question # 方向是怎么定的，怎么有多驱动的 -EM\u0026amp;TM+Attention-DATE-2024-SEU+CUHK # background # 随着VLSI技术的进步，EM问题变得越来越严重，而TM（由温度梯度引发的原子扩散）进一步加剧了EM应力的影响。传统方法如数值模拟（如COMSOL软件）计算复杂且耗时，因此论文提出一种基于图学习的解决方案。\nboundary junctions connect to standard cells.\nVertical branches are typically connected to boundary junctions at one end\nHorizontal branches are influenced by internal junction nodes at both ends\n温度梯度的引入改变了原子运动的状态。与仅考虑电磁效应相比，它在多段互连内带来了明显不同的应力分布.如(b)\nsoftware COMSOL predicts the hydrostatic stress in each segment by solving Korhonen’s PDE : 一个偏微分方程\nWhen employing traditional methods, the temperature term significantly escalates the overall solution’s complexity, especially when simulating stress in large-scale multi-segment interconnects.\ntask # node-edge regression for EM and TM stress\ncontribution # first TM\u0026amp;EM prediction use GNN an enhanced GAT: customized alternating aggregation method data # 构图方法与EMGraph中所描述方法相同\n相比上一篇EMGraph, 除了温度TE, 还多了CE, 和CN\n这里的图结构和EMGraph是有点不一样的，这里只有一条长水平线\nMin-Max normalization method to (0, 1) model # 整体还是和EMGraph一样的\nGAT based.节点特征的更新是通过一个注意力机制来完成的\n模型会计算每个节点与其邻居节点及相连边之间的注意力权重，根据这些权重来聚合邻居节点和边的特征，从而更新当前节点的嵌入表示。这样一来，节点不仅能够接收相邻节点的信息，还能融入连接边的特征，从而实现更精细的应力预测。\n设计了专门的边聚合机制: 双向交替聚合\nexperiment # env:\nan Intel Xeon CPU with 2.20GHz 4 NVIDIA Tesla V100 GPUs 精度对比实验 尤其是在200段以内的互连结构中，其平均误差率不到0.9%\n速度对比\n相比于COMSOL软件，本文模型在电迁移和热迁移应力的预测中实现了高达9037倍的速度提升。\n泛化能力 in VLSI\n为了进一步验证模型在VLSI上的适用性，论文使用了OpenRoad中的电源网格电路进行测试，最大电路包含10,807段导线。实验结果表明，在这些大规模电路中，本文模型依然能够保持不到**1.1%**的误差率，并且在应力预测速度上实现了9037倍的提升\n参考 # 专题解读 | GNN在EDA后端设计物理验证环节中验证应力的应用 "},{"id":21,"href":"/zh/docs/example/collapsed/3rd-level/4th-level/","title":"4th Level","section":"3rd Level","content":" 4th Level of Menu # Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":22,"href":"/zh/docs/example/collapsed/3rd-level/","title":"3rd Level","section":"Collapsed","content":" 3rd Level of Menu # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); "},{"id":23,"href":"/zh/docs/example/hidden/","title":"Hidden","section":"Example Site","content":" This page is hidden in menu # Quondam non pater est dignior ille Eurotas # Latent te facies # Lorem markdownum arma ignoscas vocavit quoque ille texit mandata mentis ultimus, frementes, qui in vel. Hippotades Peleus pennas conscia cuiquam Caeneus quas.\nPater demittere evincitque reddunt Maxime adhuc pressit huc Danaas quid freta Soror ego Luctus linguam saxa ultroque prior Tatiumque inquit Saepe liquitur subita superata dederat Anius sudor Cum honorum Latona # O fallor in sustinui iussorum equidem. Nymphae operi oris alii fronde parens dumque, in auro ait mox ingenti proxima iamdudum maius?\nreality(burnDocking(apache_nanometer), pad.property_data_programming.sectorBrowserPpga(dataMask, 37, recycleRup)); intellectualVaporwareUser += -5 * 4; traceroute_key_upnp /= lag_optical(android.smb(thyristorTftp)); surge_host_golden = mca_compact_device(dual_dpi_opengl, 33, commerce_add_ppc); if (lun_ipv) { verticalExtranet(1, thumbnail_ttl, 3); bar_graphics_jpeg(chipset - sector_xmp_beta); } Fronde cetera dextrae sequens pennis voce muneris # Acta cretus diem restet utque; move integer, oscula non inspirat, noctisque scelus! Nantemque in suas vobis quamvis, et labori!\nvar runtimeDiskCompiler = home - array_ad_software; if (internic \u0026gt; disk) { emoticonLockCron += 37 + bps - 4; wan_ansi_honeypot.cardGigaflops = artificialStorageCgi; simplex -= downloadAccess; } var volumeHardeningAndroid = pixel + tftp + onProcessorUnmount; sector(memory(firewire + interlaced, wired)); "},{"id":24,"href":"/zh/docs/mydocs/sub0/subsub0/hello/","title":"Hello","section":"Subsub0","content":"asdasd\ndsd\ns d s d s d\n"},{"id":25,"href":"/zh/docs/mydocs/sub0/subsub1/hello/","title":"Hello","section":"Subsub1","content":"ddddsaaaaaaa\n"},{"id":26,"href":"/zh/docs/mydocs/sub1/b/","title":"B","section":"Sub1","content":"bbb\n"}]